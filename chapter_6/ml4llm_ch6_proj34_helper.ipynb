{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Book:</h2>|<h1><a href=\"https://open.substack.com/pub/mikexcohen/p/llm-breakdown-16-tokenization-words\" target=\"_blank\">50 ML projects to understand LLMs</a></h1>|\n","|-|:-:|\n","|<h2>Project:</h2>|<h1><b>[34] QKV activation characteristics</b></h1>|\n","|<h2>Author:<h2>|<h1>Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h1>|\n","\n","<br>\n","\n","<i>Using the code without reading the book may lead to confusion or errors.</i>"],"metadata":{"id":"py_eibYAH3Q-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5BvQj17hzqwM"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","\n","import requests\n","\n","import torch\n","from transformers import AutoModelForCausalLM, GPT2Tokenizer\n","import torch.nn.functional as F"]},{"cell_type":"code","source":["### matplotlib adjustments (commented lines are for dark mode)\n","\n","# svg plots (higher-res)\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n","\n","plt.rcParams.update({\n","    # 'figure.facecolor': '#282a2c',\n","    # 'figure.edgecolor': '#282a2c',\n","    # 'axes.facecolor':   '#282a2c',\n","    # 'axes.edgecolor':   '#DDE2F4',\n","    # 'axes.labelcolor':  '#DDE2F4',\n","    # 'xtick.color':      '#DDE2F4',\n","    # 'ytick.color':      '#DDE2F4',\n","    # 'text.color':       '#DDE2F4',\n","    'axes.spines.right': False,\n","    'axes.spines.top':   False,\n","    'axes.titleweight': 'bold',\n","    'axes.labelweight': 'bold',\n","    'savefig.dpi':300\n","})"],"metadata":{"id":"dy4A-ah8kzZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DugL7dpykd_h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 1: Model, tokens, QKV activations**"],"metadata":{"id":"oGIKYsGKEEO-"}},{"cell_type":"code","source":["# load GPT2 model and tokenizer\n","model = AutoModelForCausalLM.from_pretrained('gpt2-large')\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","\n","model.eval()"],"metadata":{"id":"vEwYHoqWz0nB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"X1OVxEWuqKER"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# variable for the number of embedding dimensions\n","n_emb = model.\n","\n","# and the number of layers\n","n_layers ="],"metadata":{"id":"8o8PbxpACLOo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# GreatGatsby\n","url = 'https://www.gutenberg.org/cache/epub/64317/pg64317.txt'\n","text = requests.get(url).text\n","tokens = np.array( tokenizer.encode(text) )\n","\n","target_word =\n","\n","target_idx =\n","print(f'{len(target_idx)} instances of \"{target_word}\"')"],"metadata":{"id":"Kt_oqltNRaov"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# size of pre-target context (tokens)\n","contextwin =\n","\n","# remove any target indices that are <contextwin\n","print(f'Target count before filtering: {len(target_idx)}')\n","target_idx = target_idx[]\n","\n","print(f'Target count after filtering: {len(target_idx)}')"],"metadata":{"id":"07Hkkh5E_03q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create a batch\n","batch = torch.zeros((len(target_idx),contextwin+1),dtype=torch.long)\n","\n","for i in range(len(target_idx)):\n","  toks = tokens[]\n","  batch[i,:] =\n","\n","batch.shape"],"metadata":{"id":"C-ZmxOAXSb9K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# note the identical final token\n","batch"],"metadata":{"id":"BWNSYdBwq0xP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# a few examples\n","for i in range(5):\n","  print(tokenizer.decode())"],"metadata":{"id":"tyelESNSqKuM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a hook function to store QKV vectors\n","activations = {}\n","\n","def implant_hook(layer_number):\n","  def hook(module,input,output):\n","    activations[f'attn_{layer_number}_qkv'] = output.()\n","  return hook\n","\n","\n","# surgery ;)\n","handles = []\n","for i in range(n_layers):\n","  h = model...register_forward_hook(implant_hook(i))\n","  handles.append(h)"],"metadata":{"id":"Q3_iseD-1aG3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# push through the model\n","with torch.no_grad(): model(batch)\n","\n","for k,i in activations.items():\n","  print()"],"metadata":{"id":"GQ7EACxZxD9m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# concatenated activations from one layer\n","layeri = 6\n","\n","wide_acts = activations[]\n","\n","plt.figure(figsize=(10,3))\n","plt.imshow(,aspect='auto',vmin=-1,vmax=1,cmap='plasma')\n","plt.axvline(,linestyle='--',color='w')\n","plt.axvline(,linestyle='--',color='w')\n","plt.colorbar(pad=.01)\n","\n","plt.gca().set(xticks=[],ylabel='Batch sequences',\n","              xlabel='Queries dimensions         |           Keys dimensions             |           Values dimensions')\n","\n","\n","plt.tight_layout()\n","plt.savefig('ch6_proj34_part1.png')\n","plt.show()"],"metadata":{"id":"RY0Xw6nRcIzt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9Oy0nfHoB5qe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 2: Activation characteristics**"],"metadata":{"id":"xYnUh2ouB5nz"}},{"cell_type":"code","source":["# just one layer for now\n","layeri = 6\n","\n","# split into separate matrices\n","Q,K,V = torch.split(\n","Q.shape,K.shape,V.shape"],"metadata":{"id":"oMitNC6tUHAG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# target: means of means and variances\n","qMeans_t = torch.tensor([ torch.mean,\n","                          torch.mean,\n","                          torch.var ])\n","\n","# non-target: means of means and variances\n","qMeans_n = torch.tensor([  ])\n","\n","\n","plt.figure(figsize=(8,3))\n","plt.bar(np.arange(3)-.2,qMeans_t,width=.5,edgecolor='k',label='Target')\n","plt.bar(np.arange(3)+.2,qMeans_n,width=.5,edgecolor='k',label='Non-target')\n","plt.legend()\n","plt.gca().set(xticks=range(3),xticklabels=['Arithmetic mean','L1 mean','Variance'],ylabel='Descriptive values')\n","\n","plt.tight_layout()\n","plt.savefig('ch6_proj34_part2a.png')\n","plt.show()"],"metadata":{"id":"if9oub8_Y8UZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["edges = torch.linspace(-7,7,234)\n","\n","ytQ,_ = torch.histogram(Q[:,-1,:].flatten(),edges,density=)\n","ynQ,_ = torch.histogram()\n","ytK,_ = torch.histogram(\n","ynK,_ = torch.histogram(\n","ytV,_ = torch.histogram(\n","ynV,_ = torch.histogram(\n","\n","plt.figure(figsize=(10,3))\n","plt.plot(,label='Q target')\n","plt.plot(label='Q nontarget')\n","plt.plot(,label='K target')\n","plt.plot(,label='K nontarget')\n","plt.plot(,label='V target')\n","plt.plot(,label='V nontarget')\n","\n","plt.legend()\n","plt.gca().set(xlim=edges[[0,-1]],xlabel='Activation value',ylabel='Density',\n","              title=f'Attention matrices distributions from layer {layeri}')\n","\n","plt.tight_layout()\n","plt.savefig('ch6_proj34_part2b.png')\n","plt.show()"],"metadata":{"id":"P8Y8C0UzWwA_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pShpPGSUP1Rk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 3: Laminar trends in activation descriptives**"],"metadata":{"id":"YavRM7zOP1Oo"}},{"cell_type":"code","source":["# helper function\n","def meansAndVar(X):\n","\n","  # target\n","  t1 = torch...(X[:,-1,:],      # arithmetic mean\n","  t2 =  # L1 mean\n","  t3 =        # variance\n","\n","  # non-target\n","  n1 =       # arithmetic mean\n","  n2 =  # L1 mean\n","  n3 =        # variance\n","\n","  return\n","\n","# test\n","meansAndVar(Q)"],"metadata":{"id":"XrAg-9tGDMDe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# initialize: layers X matrix X feature X category\n","descriptives = torch.zeros((n_layers,3,3,2))\n","\n","for layeri in range(n_layers):\n","\n","  # split into separate matrices\n","  Q,K,V = torch.split(\n","\n","  # Q: get the descriptives\n","  T,N = meansAndVar(Q)\n","  descriptives[layeri,0,:,0] =\n","  descriptives[layeri,0,:,1] =\n","\n","  # K: get the descriptives\n","  T,N = meansAndVar(K)\n","  descriptives[\n","  descriptives[\n","\n","  # V: get the descriptives\n","  T,N = meansAndVar(V)\n","  descriptives[\n","  descriptives[\n","\n","\n","descriptives.shape"],"metadata":{"id":"2FcUE9kvk1_B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_,axs = plt.subplots(1,3,figsize=(12,3))\n","\n","feature = ['Arithmetic mean','L1 mean','Variance']\n","\n","for i in range(len(axs)):\n","  axs[i].plot(,'gs-',markerfacecolor=[.7,.9,.7,.7],label='Q')\n","  axs[i].plot(,'ro-',markerfacecolor=[.9,.7,.7,.7],label='K')\n","  axs[i].plot(,'b^-',markerfacecolor=[.7,.7,.9,.7],label='V')\n","  axs[i].legend()\n","  axs[i].set(xlabel='Transformer layer',xticks=range(0,n_layers,4),title=f'{feature[i]}')\n","\n","plt.tight_layout()\n","plt.savefig('ch6_proj34_part3a.png')\n","plt.show()"],"metadata":{"id":"_4U0NWS1HgBe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_,axs = plt.subplots(1,3,figsize=(12,3))\n","\n","for i in range(len(axs)):\n","  axs[i].axhline(0,linestyle='--',linewidth=.5,color=[.7,.7,.7])\n","  axs[i].plot(descriptives....diff(dim=-1),'gs-',markerfacecolor=[.7,.9,.7,.7],label='Q')\n","  axs[i].plot(,'ro-',markerfacecolor=[.9,.7,.7,.7],label='K')\n","  axs[i].plot(,'b^-',markerfacecolor=[.7,.7,.9,.7],label='V')\n","  axs[i].legend()\n","  axs[i].set(xlabel='Transformer layer',xticks=range(0,n_layers,4),title=f'{feature[i]}')\n","\n","plt.tight_layout()\n","plt.savefig('ch6_proj34_part3b.png')\n","plt.show()"],"metadata":{"id":"q25WN8x3k15i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uNRbBXFkqbPp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 4: Laminar trends in activation distributions**"],"metadata":{"id":"ArJB2M1gJGMj"}},{"cell_type":"code","source":["# helper function\n","edges = torch.linspace(-4,4,101)\n","\n","def calculateHists(X):\n","  yt,_ = torch.histogram()\n","  yn,_ = torch.histogram()\n","  return yt,yn"],"metadata":{"id":"jr5vqE0FJI8w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# initialize: layers X matrix X bins X category\n","histograms = torch.zeros((n_layers,3,len(edges)-1,2))\n","\n","for layeri in range(n_layers):\n","\n","  # split into separate matrices\n","  Q,K,V =\n","\n","  # get the histograms\n","  histograms[layeri,0,:,0],histograms[layeri,0,:,1] = calculateHists(\n","  histograms[layeri,1,:,0],histograms[layeri,1,:,1] =\n","  histograms[layeri,2,:,0],histograms[layeri,2,:,1] =\n","\n","histograms.shape"],"metadata":{"id":"zCoGuJcPJI4b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig,axs = plt.subplots(2,3,figsize=(12,6))\n","\n","for i in range(3):\n","  h = axs[0,i].imshow(,vmin=0,vmax=.4,aspect='auto',cmap='plasma',\n","                  extent=[edges[0],edges[-1],0,n_layers],origin='lower')\n","  axs[0,i].set(xticklabels=[],ylabel='Layer',yticks=range(0,n_layers,5),title=f\"Target {'QKV'[i]}\")\n","  fig.colorbar(h,ax=axs[0,i],pad=.03,orientation='horizontal')\n","\n","  axs[1,i].imshow(,vmin=0,vmax=.4,aspect='auto',cmap='plasma',\n","                  extent=[edges[0],edges[-1],0,n_layers],origin='lower')\n","  axs[1,i].set(xlabel='Activation value',ylabel='Layer',yticks=range(0,n_layers,5),title=f\"Non-target {'QKV'[i]}\")\n","\n","\n","plt.tight_layout()\n","plt.savefig('ch6_proj34_part4.png')\n","plt.show()"],"metadata":{"id":"8Rh5akbVk11i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vaUg-Au0k1vI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 5: Extracting and characterizing heads**"],"metadata":{"id":"LtwrQVNv-pOh"}},{"cell_type":"code","source":["n_heads = model.config.\n","head_dim ="],"metadata":{"id":"i36DqYz9-pLl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# extract Q\n","Q,K,V = torch.split(activations['attn_6_qkv'],n_emb,dim=-1)\n","\n","# and reshape to have a \"head\" dimension\n","Qh = Q.view\n","\n","print(f'Q is size {list(Q.shape)} and Qh is size {list(Qh.shape)}')"],"metadata":{"id":"ZmcYAg5M-pJA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualize\n","_,axs = plt.subplots(4,5,figsize=(12,6))\n","\n","for i,ax in enumerate(axs.flatten()):\n","  ax.pcolor(,cmap='plasma',vmin=-2,vmax=2)\n","  ax.text(contextwin-.5,head_dim-1,f'Qh{i}',fontsize=12,fontweight='bold',color='k',ha='right',va='top')\n","  ax.text(contextwin,head_dim-2,f'Qh{i}',fontsize=12,fontweight='bold',color='w',ha='right',va='top')\n","  ax.set(xticks=[],yticks=[])\n","\n","# finalize\n","axs[3,0].set(ylabel='Head dim',xlabel='Token position')\n","\n","plt.tight_layout()\n","plt.savefig('ch6_proj34_part5a.png')\n","plt.show()"],"metadata":{"id":"9rINhBv6_ywd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["head_stdevs = np.zeros((n_layers,3))\n","\n","for layeri in range(n_layers):\n","\n","  # split into Q, K, and V\n","  Q,K,V =\n","\n","  # reshape to have a heads dimension\n","  Qh = Q.view\n","  Kh =\n","  Vh =\n","\n","  # then get the standard deviation along the tokens\n","  head_stdevs[layeri,0] = Qh.\n","  head_stdevs[layeri,1] =\n","  head_stdevs[layeri,2] =\n","\n","\n","# and visualize\n","plt.figure(figsize=(10,3))\n","\n","plt.plot(head_stdevs[:,0],'gs-',markersize=9,markerfacecolor=[.7,.9,.7],label='Q')\n","plt.plot(head_stdevs[:,1],'ro-',markersize=9,markerfacecolor=[.9,.7,.7],label='K')\n","plt.plot(head_stdevs[:,2],'b^-',markersize=9,markerfacecolor=[.7,.7,.9],label='V')\n","\n","plt.legend()\n","plt.gca().set(xlabel='Transformer layer',ylabel='Average standard deviation')\n","\n","plt.tight_layout()\n","plt.savefig('ch6_proj34_part5b.png')\n","plt.show()"],"metadata":{"id":"AP7lHIwAWGGC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xlYJV5ACWGDM"},"execution_count":null,"outputs":[]}]}