{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["|<h2>Book:</h2>|<h1><a href=\"https://open.substack.com/pub/mikexcohen/p/llm-breakdown-16-tokenization-words\" target=\"_blank\">50 ML projects to understand LLMs</a></h1>|\n","|-|:-:|\n","|<h2>Project:</h2>|<h1><b>[40] Downstream impacts of head silencing</b></h1>|\n","|<h2>Author:<h2>|<h1>Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h1>|\n","\n","<br>\n","\n","<i>Using the code without reading the book may lead to confusion or errors.</i>"],"metadata":{"id":"py_eibYAH3Q-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5BvQj17hzqwM"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","from matplotlib.gridspec import GridSpec\n","\n","from tqdm import tqdm\n","\n","import torch\n","from transformers import AutoModelForCausalLM, GPT2Tokenizer\n","import torch.nn.functional as F"]},{"cell_type":"code","source":["### Run this cell only if you're using \"dark mode\"\n","\n","# svg plots (higher-res)\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n","\n","plt.rcParams.update({\n","    # 'figure.facecolor': '#282a2c',\n","    # 'figure.edgecolor': '#282a2c',\n","    # 'axes.facecolor':   '#282a2c',\n","    # 'axes.edgecolor':   '#DDE2F4',\n","    # 'axes.labelcolor':  '#DDE2F4',\n","    # 'xtick.color':      '#DDE2F4',\n","    # 'ytick.color':      '#DDE2F4',\n","    # 'text.color':       '#DDE2F4',\n","    'axes.spines.right': False,\n","    'axes.spines.top':   False,\n","    'axes.titleweight': 'bold',\n","    'axes.labelweight': 'bold',\n","    'savefig.dpi':300\n","})"],"metadata":{"id":"dy4A-ah8kzZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Eja6hB4TfIAU"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["# **Part 1: Hook all layers and get activations**"],"metadata":{"id":"oGIKYsGKEEO-"}},{"cell_type":"code","source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"O6f4yiY_El-h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = AutoModelForCausalLM.from_pretrained('gpt2-medium')\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\n","model.eval()\n","model = model.to(device)"],"metadata":{"id":"m5QXl5irtjBh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# some useful variables\n","n_heads = model.config.n_head\n","n_layers = model.config.n_layer\n","n_embd = model.config.n_embd\n","head_dim = n_embd // n_heads"],"metadata":{"id":"HZ6DyuqKtkyu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## hook to silence attention heads\n","\n","# initialize out-of-bounds variables\n","layer2silence = 1000\n","head2silence = 1000\n","\n","def implant_hook(layer_number):\n","  def hook4attn(module,input):\n","\n","    # modify the activation only for this layer\n","    if layer_number==layer2silence:\n","\n","      # reshape so we can index heads (number of batches and tokens extracted locally)\n","      nB,nT,_ = input[0].shape\n","      head_tensor = input[0].view(nB,nT,n_heads,head_dim)\n","\n","      # ablate\n","      head_tensor[:,:,head2silence,:] = 0\n","\n","      # reshape back to tensor\n","      head_tensor = head_tensor.view(nB,nT,n_embd)\n","\n","      # return a tuple matching the original\n","      input = (head_tensor,*input[1:])\n","\n","    return input\n","  return hook4attn\n","\n","\n","head_handles = []\n","for layeri in range(n_layers):\n","  h = model.transformer.h[layeri].attn.c_proj.register_forward_pre_hook(implant_hook(layeri))\n","  head_handles.append(h)"],"metadata":{"id":"Iy0kVnQztkvz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## hook to grab the hidden states\n","\n","hook_hs = {}\n","\n","def outerHook(layeri):\n","  def hook(module, input, output):\n","    hook_hs[f'layer_{layeri}'] = output[0].detach().cpu().numpy()\n","  return hook\n","\n","hs_handles = []\n","for layeri in range(model.config.n_layer):\n","  h = model.transformer.h[layeri].register_forward_hook(outerHook(layeri))\n","  hs_handles.append(h)"],"metadata":{"id":"8Qq2QwMFdPUJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# text and tokens (quote from Igor Stravinsky)\n","text = 'Look for the music on all things, and life will be a symphony of joy. My music is best understood by children and'\n","# (original quote ends with \" animals.\")\n","\n","# https://www.azquotes.com/quote/1459556\n","# https://en.wikiquote.org/wiki/Igor_Stravinsky\n","\n","tokens = tokenizer.encode(text,return_tensors='pt')\n","nbatches,ntokens = tokens.shape\n","\n","# move to GPU\n","tokens = tokens.to(device)\n","\n","print(f'There are {ntokens} tokens:')\n","for t in tokens[0]:\n","  print(f'{t:>5} is \"{tokenizer.decode(t)}\"')"],"metadata":{"id":"DlRKgwTvEZfJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["layer2silence = 1000\n","\n","with torch.no_grad():\n","  out_clean = model(tokens)\n","\n","# make a copy of the hidden states, b/c the variable will be overwritten in the next forward pass\n","hs_clean = hook_hs.copy()\n","logits_clean = out_clean.logits.cpu()"],"metadata":{"id":"aktYlZw3wrp7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Keys in hs_clean:\\n  ',hs_clean.keys())\n","print('\\nShape of hs vectors:\\n  ',hs_clean['layer_2'].shape)\n","print('\\nShape of output logits:\\n  ',logits_clean.shape)"],"metadata":{"id":"dsQ0AeZh7Ghm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"D0xaNJV8M3Vd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 2: Cosine similarity in the \"clean\" model**"],"metadata":{"id":"u-Dsdy1BM3Sr"}},{"cell_type":"code","source":["# how many unique tokens are in the CS matrix\n","uniqueCScount = int((ntokens-1)*(ntokens-2)/2)\n","\n","cs_clean = np.zeros((n_layers,uniqueCScount))\n","\n","for layeri in range(n_layers):\n","\n","  # cosine similarities\n","  H = hs_clean[f'layer_{layeri}'][0,1:,:]\n","  H = H / np.linalg.norm(H,axis=1,keepdims=True)\n","  csMat = H @ H.T\n","\n","  # and extract the unique elements\n","  cs_clean[layeri,:] = csMat[np.triu_indices(ntokens-1,1)]\n","\n","cs_clean.shape"],"metadata":{"id":"Xj2-jTNaqnlT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig,ax = plt.subplots(1,figsize=(10,4))\n","\n","Nbins = 31\n","binbounds = np.linspace(.6,1,Nbins+1)\n","Y = np.zeros((Nbins,n_layers))\n","\n","for layeri in range(n_layers):\n","\n","  # extract the histogram\n","  Y[:,layeri],_ = np.histogram(cs_clean[layeri],bins=binbounds)\n","\n","  # and plot\n","  ax.plot(layeri,cs_clean[layeri].mean(),'kh',markerfacecolor=[.7,.9,.9],markeredgewidth=1.5,markersize=12)\n","\n","\n","# and the histogram image underneath\n","bincenters = (binbounds[:-1]+binbounds[1:])/2\n","h = ax.pcolor(range(n_layers),bincenters,Y,vmin=0,vmax=Y.max()*.8,cmap='afmhot_r')\n","fig.colorbar(h,ax=ax,pad=.01,label='Count')\n","\n","ax.set(xlabel='Layer',xticks=range(0,n_layers),ylabel='Cosine similarity',\n","       title='Cosine similarity averages and distributions')\n","\n","plt.tight_layout()\n","plt.savefig('ch6_proj40_part2.png')\n","plt.show()"],"metadata":{"id":"vU2sc-FfutEb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"98ZUFGjlEZaY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 3: Downstream impact of silencing one head**"],"metadata":{"id":"OJI-4whmOduI"}},{"cell_type":"code","source":["layer2silence = 4\n","head2silence = 1\n","\n","with torch.no_grad():\n","  out_silence = model(tokens)\n","\n","hs_silence = hook_hs.copy()\n","logits_silence = out_silence.logits.cpu() # used in part 4"],"metadata":{"id":"0WAdStEthZLk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create a figure\n","fig = plt.figure(figsize=(11,3))\n","gs = GridSpec(1,3,figure=fig)\n","ax0 = fig.add_subplot(gs[:-1])\n","ax1 = fig.add_subplot(gs[-1])\n","\n","# for the colormap of the lines\n","norm = mpl.colors.Normalize(vmin=0,vmax=n_layers)\n","cmap = mpl.colormaps['plasma'].resampled(n_layers+1)\n","\n","\n","for layeri in range(n_layers):\n","\n","  # similarities in this layer\n","  H = hs_silence[f'layer_{layeri}'][0,1:,:]\n","  H = H / np.linalg.norm(H,axis=1,keepdims=True)\n","  csMat = H @ H.T\n","  cs_silence = csMat[np.triu_indices(ntokens-1,1)]\n","\n","  # differences and scatter plot of mean difference\n","  cs_diff = cs_clean[layeri] - cs_silence\n","  ax1.plot(layeri,cs_diff.mean(),'kh',markerfacecolor=cmap(norm(layeri)),markersize=10)\n","\n","  # histograms\n","  y,x = np.histogram(cs_diff,bins='fd')\n","  if layeri >= layer2silence:\n","    ax0.plot(x[:-1],y,'.-',markersize=8,linewidth=2,color=cmap(norm(layeri)))\n","\n","# and the color bar\n","sm = mpl.cm.ScalarMappable(cmap=cmap,norm=norm)\n","cbar = fig.colorbar(sm,ax=ax0,pad=.02)\n","cbar.set_label('Layer')\n","\n","ax0.axvline(0,linestyle='--',color='k',linewidth=.4)\n","ax0.set(xlabel='$\\\\Delta$ Cosine similarity',ylabel='Count',ylim=[0,None],\n","        title='A) Difference distributions')\n","\n","ax1.axvline(layer2silence,linestyle='--',color='k',zorder=-10,linewidth=.4)\n","ax1.axhline(0,linestyle='--',color='k',zorder=-10,linewidth=.4)\n","ax1.set(xlabel='Layer',xticks=range(0,n_layers,2),ylabel='Similarity differences',title='B) Average differences')\n","\n","plt.tight_layout()\n","plt.savefig('ch6_proj40_part3.png')\n","plt.show()"],"metadata":{"id":"vFIrMz7BOdrV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"fVsck9YKEZXj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Interlude: Copying data from the GPU to the CPU**"],"metadata":{"id":"VHtwjTy01Lj2"}},{"cell_type":"code","source":["#-- still on the GPU\n","# next_tok = torch.argmax(out_clean.logits[0,-1,:])\n","# print(next_tok.device)\n","\n","#-- explicitly move to the CPU\n","# next_tok = torch.argmax(out_clean.logits[0,-1,:]).cpu()\n","# print(next_tok.device)\n","\n","#-- move to CPU with .item()\n","# next_tok = torch.argmax(out_clean.logits[0,-1,:]).item()\n","# print(next_tok.device)\n","# print(torch.tensor(next_tok).device)\n","\n","#-- but item() is only for scalars\n","# lsm_logits = F.log_softmax(out_clean.logits[0,-1,:],dim=-1).item()"],"metadata":{"id":"cdRPS6hRbpdp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1Em_vJ7b1LDF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 4: Impact on output logits**"],"metadata":{"id":"3JRvSqaMnhLz"}},{"cell_type":"code","source":["print(f'Original text is \"{text}\"\\n')\n","\n","# from the clean model\n","# NOTE: variable 'new_tok_clean' is important! That's the target token in part 5\n","logsoftmax_clean = F.log_softmax(logits_clean[0,-1,:],dim=-1)\n","new_tok_clean = torch.argmax(logsoftmax_clean).item()\n","maxlsm_clean = logsoftmax_clean[new_tok_clean]\n","print(f'   CLEAN: Predicted next token is \"{tokenizer.decode(new_tok_clean)}\" with {torch.exp(maxlsm_clean):.3%}')\n","\n","# from the head-silenced model\n","logsoftmax_silence = F.log_softmax(logits_silence[0,-1,:],dim=-1)\n","next_tok = torch.argmax(logsoftmax_silence).item()\n","print(f'SILENCED: Predicted next token is \"{tokenizer.decode(next_tok)}\" with {torch.exp(logsoftmax_silence[next_tok]):.3%}')"],"metadata":{"id":"MRBZ5lZ7bpbE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Top 10 logits from CLEAN model:')\n","for t in torch.topk(logsoftmax_clean,10)[1]:\n","  print(f'\"{tokenizer.decode(t)}\", ',end='')\n","\n","print('\\n\\nTop 10 logits from SILENCED model:')\n","for t in torch.topk(logsoftmax_silence,10)[1]:\n","  print(f'\"{tokenizer.decode(t)}\", ',end='')"],"metadata":{"id":"Vj5wUbu6SUrX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# still only silencing one head\n","head2silence = 1\n","\n","plt.figure(figsize=(10,3))\n","for layer2silence in range(n_layers):\n","\n","  # rerun the model\n","  with torch.no_grad():\n","    out_silence = model(tokens,output_hidden_states=True)\n","\n","  lsm_logits = F.log_softmax(out_silence.logits[0,-1,:],dim=-1).cpu()\n","  next_tok = torch.argmax(lsm_logits).item()\n","  print(f'Next token is \"{tokenizer.decode(next_tok)}\" with {torch.exp(lsm_logits[next_tok]):.3%}  (silenced L{layer2silence}:H{head2silence})')\n","\n","  plt.plot(layer2silence,lsm_logits[next_tok],'kh',markersize=12,markerfacecolor=mpl.cm.plasma(layer2silence/n_layers))\n","\n","plt.axhline(maxlsm_clean,color='k',linestyle='--',linewidth=.5,zorder=-100)\n","plt.gca().set(xlabel='Manipulated layer',ylabel='Log softmax prob',title=f'Impact of silencing head #{head2silence} on max logit')\n","\n","plt.tight_layout()\n","plt.savefig('ch6_proj40_part4.png')\n","plt.show()"],"metadata":{"id":"Y-KVlHVVbpYR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"aq4qKhm3h8sS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 5: Silencing each head**"],"metadata":{"id":"tFUSOW30i3wu"}},{"cell_type":"code","source":["# initialize matrix of log-softmax values\n","lsm_vals = np.zeros((n_heads,n_layers,2))\n","\n","\n","# double loop over layers and heads per layer\n","for layer2silence in tqdm(range(n_layers)):\n","  for head2silence in range(n_heads):\n","\n","    # rerun the model\n","    with torch.no_grad():\n","      out_silence = model(tokens,output_hidden_states=True)\n","\n","    # get the log softmax\n","    lsm_logits = F.log_softmax(out_silence.logits[0,-1,:],dim=-1).cpu()\n","\n","    # softmax of target token\n","    lsm_vals[head2silence,layer2silence,0] = lsm_logits[new_tok_clean].item()\n","\n","    # and of the max token\n","    lsm_vals[head2silence,layer2silence,1] = torch.max(lsm_logits).item()"],"metadata":{"id":"hF8of-pCh8ov"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig,axs = plt.subplots(1,2,figsize=(12,4))\n","\n","for i in [0,1]:\n","\n","  # image data to show\n","  I = lsm_vals[:,:,i] - maxlsm_clean.item()\n","\n","  # find color limits based on L1-mean\n","  clim = abs(I).mean()*2\n","\n","  # create the image\n","  h = axs[i].pcolor(range(n_layers),range(n_heads),I,vmin=-clim,vmax=clim,cmap='RdBu_r')\n","  axs[i].set(xlabel='Transformer layer',ylabel='Attention head index')\n","  fig.colorbar(h,ax=axs[i],pad=.02)\n","  axs[i].spines.top.set_visible(True) # switched off by default, but I want them here\n","  axs[i].spines.right.set_visible(True)\n","\n","\n","axs[0].set(title='A) Target log-softmax')\n","axs[1].set(title='B) Max token log-softmax')\n","\n","plt.tight_layout()\n","plt.savefig('ch6_proj40_part5a.png')\n","plt.show()"],"metadata":{"id":"nnqmdoCPh8l0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(8,3))\n","\n","# plot the data for the target token\n","X = (lsm_vals[:,:,0]-maxlsm_clean.item())\n","plt.errorbar(np.arange(n_layers)-.05,X.mean(axis=0),X.std(axis=0),\n","             color='r',linestyle='none')\n","plt.plot(np.arange(n_layers)-.05,X.mean(axis=0),'rs',markersize=9,\n","         markerfacecolor=[.9,.7,.7],label='Target token')\n","\n","# and for the non-target token\n","X = (lsm_vals[:,:,1]-maxlsm_clean.item())\n","plt.errorbar(np.arange(n_layers)+.05,X.mean(axis=0),X.std(axis=0),\n","             color='g',linestyle='none')\n","plt.plot(np.arange(n_layers)+.05,X.mean(axis=0),'go',markersize=8,\n","         markerfacecolor=[.7,.9,.7],label='Maximum token')\n","\n","# draw the clean max/target logit\n","plt.axhline(0,color='k',linestyle='--',linewidth=.4)\n","\n","# axis adjustments\n","plt.gca().set(xlabel='Transformer block of attention silencing',ylabel='Log-softmax difference',\n","        xlim=[-.5,n_layers-.5],title='Average of single-head impacts')\n","plt.legend(loc='lower right')\n","\n","plt.tight_layout()\n","plt.savefig('ch6_proj40_part5b.png')\n","plt.show()"],"metadata":{"id":"Gn3rUnYYkatk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jc0KnpnIkarH"},"execution_count":null,"outputs":[]}]}