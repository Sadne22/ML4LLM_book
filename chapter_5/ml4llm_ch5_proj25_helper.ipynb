{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Book:</h2>|<h1><a href=\"https://open.substack.com/pub/mikexcohen/p/llm-breakdown-16-tokenization-words\" target=\"_blank\">50 ML projects to understand LLMs</a></h1>|\n","|-|:-:|\n","|<h2>Project:</h2>|<h1><b>[25] Category selectivity via cosine similarity</b></h1>|\n","|<h2>Author:<h2>|<h1>Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h1>|\n","\n","<br>\n","\n","<i>Using the code without reading the book may lead to confusion or errors.</i>"],"metadata":{"id":"py_eibYAH3Q-"}},{"cell_type":"code","source":[],"metadata":{"id":"R5SI-Iyy4dtm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn.functional as F\n","\n","from scipy.stats import ttest_ind\n","import requests\n","\n","from transformers import AutoModelForCausalLM, AutoTokenizer"],"metadata":{"id":"rn8Fcyf87EXx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### matplotlib adjustments (commented lines are for dark mode)\n","\n","# svg plots (higher-res)\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n","\n","plt.rcParams.update({\n","    # 'figure.facecolor': '#282a2c',\n","    # 'figure.edgecolor': '#282a2c',\n","    # 'axes.facecolor':   '#282a2c',\n","    # 'axes.edgecolor':   '#DDE2F4',\n","    # 'axes.labelcolor':  '#DDE2F4',\n","    # 'xtick.color':      '#DDE2F4',\n","    # 'ytick.color':      '#DDE2F4',\n","    # 'text.color':       '#DDE2F4',\n","    'axes.spines.right': False,\n","    'axes.spines.top':   False,\n","    'axes.titleweight': 'bold',\n","    'axes.labelweight': 'bold',\n","    'savefig.dpi':300\n","})"],"metadata":{"id":"dy4A-ah8kzZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nxqgPabM0FuN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 1: Model, tokens, hidden states**"],"metadata":{"id":"DA3zcyDTHsH7"}},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained('gpt2')\n","model = AutoModelForCausalLM.from_pretrained(\n","model.eval()"],"metadata":{"id":"v-DJGMfhlIiu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# list of words in three categories\n","words = [\n","    [1, 'galaxy'],\n","    [1, 'asteroid'],\n","    [1, 'comet'],\n","    [1, 'cosmos'],\n","    [1, 'space'],\n","    [1, 'sun'],\n","    [1, 'planet'],\n","    [1, 'moon'],\n","    [1, 'star'],\n","    [1, 'orbit'],\n","    [2, 'ceiling'],\n","    [2, 'sofa'],\n","    [2, 'couch'],\n","    [2, 'carpet'],\n","    [2, 'door'],\n","    [2, 'window'],\n","    [2, 'lamp'],\n","    [2, 'chair'],\n","    [2, 'table'],\n","    [2, 'rug'],\n","    [2, 'bed'],\n","    [2, 'floor'],\n","    [2, 'wall'],\n","    [3, 'pear'],\n","    [3, 'grape'],\n","    [3, 'banana'],\n","    [3, 'cherry'],\n","    [3, 'peach'],\n","    [3, 'apple'],\n","    [3, 'seed'],\n","    [3, 'jelly'],\n","    [3, 'orange'],\n","    [3, 'lime'],\n","    [3, 'fruit'],\n","]\n","\n","# confirm they're single-token words\n","for w in words:\n","  t = tokenizer.encode()\n","  print"],"metadata":{"id":"q8Fuw-ug1aBU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create a batch of tokens\n","batch = torch.zeros((,),dtype=)\n","\n","for i,w in enumerate(words):\n","  batch[i,:] = tokenizer.encode\n","\n","# push through the model\n","with torch.no_grad():\n","  outs = model(batch)\n","\n","# check shape of one hidden states (even though they're not toggled on in the above call!)\n","outs.hidden_states[3].shape"],"metadata":{"id":"iYx21qIa34uN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(8,3))\n","\n","for i in range(batch.shape[1]):\n","  hs = outs.hidden_states\n","  plt.plot(np.random.normal(i,.03,hs.shape[1]),hs.var(dim=0),'o',\n","           markeredgecolor='k',markersize=10,alpha=.3)\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj25_part1.png')\n","plt.show()"],"metadata":{"id":"Ct2NbuDAVw2I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Y5JawfSBAHi5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 2: Cosine similarities in one layer**"],"metadata":{"id":"xYnUh2ouB5nz"}},{"cell_type":"code","source":["# vector of word categories\n","labels =\n","print(labels.shape)\n","\n","# mask for cosine similarity matrix\n","cat_mask = np.triu( )\n","\n","# create a discrete colormap\n","N = cat_mask.max()\n","base = plt.get_cmap('rainbow')\n","cmapN = base.from_list(None,base(np.linspace(0,1,N)),N)\n","\n","plt.imshow(cat_mask,cmap=cmapN)\n","plt.gca().set(xlabel='Word indices',ylabel='Word indices')\n","plt.colorbar(ticks=np.unique(cat_mask),pad=.02)\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj25_part2a.png')\n","plt.show()"],"metadata":{"id":"irM7P7ryevM-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["layeri = 4\n","hs = outs.hidden_states[][]\n","hs /= torch.linalg.norm(\n","csMat =  @\n","\n","# extract the unique values\n","within = torch.concatenate((csMat[cat_mask==],csMat[cat_mask==],csMat[cat_mask==]))\n","across = torch.concatenate((csMat[cat_mask==],csMat[cat_mask==],csMat[cat_mask==]))\n","\n","# t-test\n","tval = ttest_ind(,).statistic\n","\n","# histograms\n","yWithin,xWithin = torch.histogram(,bins=20,density=True)\n","yAcross,xAcross = torch.histogram(,bins=20,density=True)\n","\n","_,axs = plt.subplots(1,2,figsize=(10,4))\n","h = axs[0].imshow(csMat,vmin=.5,vmax=.85)\n","plt.colorbar(h,ax=axs[0],pad=.01)\n","axs[0].set(xlabel='Word index',ylabel='Word index',title='A) Cosine similarity matrix')\n","\n","axs[1].plot(label='Within-category')\n","axs[1].plot(label='Across-category')\n","axs[1].set(ylim=[0,None],xlabel='Cosine similarity',ylabel='Density',\n","           title=f'B) Layer {layeri} distributions ($\\\\Delta$ = {within.mean()-across.mean():.2f}, t = {tval:.2f})')\n","axs[1].legend()\n","\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj25_part2b.png')\n","plt.show()"],"metadata":{"id":"38_IdC_7BSlj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"N5k-WQ7tE6fh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 3: Laminar profiles**"],"metadata":{"id":"04B09tGKMxSR"}},{"cell_type":"code","source":["num_hidden = len(outs.hidden_states)\n","# names of the layers, for the x-axis tick labels\n","layer_labels ="],"metadata":{"id":"-Ca75e1JDhQS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# initializations\n","dist_metrics = np.zeros((4,num_hidden))\n","\n","\n","for layeri in range(num_hidden):\n","\n","  # cosine similarity matrix\n","  hs = # extract\n","  hs /= # normalize\n","  csMat = # calculate\n","\n","  # extract the similarity values\n","  w =\n","  a =\n","\n","  # calculate the metrics\n","  dist_metrics[0,layeri] =\n","  dist_metrics[1,layeri] =\n","  dist_metrics[2,layeri] =\n","  dist_metrics[3,layeri] ="],"metadata":{"id":"6KTUCdaZ15y9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# show the results\n","_,axs = plt.subplots(2,2,figsize=(10,7))\n","axs[0,0].plot(,'kh',markerfacecolor=[.7,.9,.7],markersize=13,label='Within')\n","axs[0,0].plot(,'ko',markerfacecolor=[.9,.7,.7],markersize=12,label='Across')\n","\n","# thin connecting lines representing \\Delta\n","for i in range(1,num_hidden): # plot 0 separately for the legend\n","  axs[0,0].plot([i,i],dist_metrics[:2,i],'k:',linewidth=.3,zorder=-10)\n","axs[0,0].plot([0,0],dist_metrics[:2,0],'k:',linewidth=.3,zorder=-10,label='$\\\\Delta$')\n","\n","\n","axs[0,1].scatter(range(num_hidden),,s=150,edgecolor='k',\n","            c=plt.cm.plasma(np.linspace(0,1,num_hidden)),alpha=.7)\n","axs[0,1].set(xlabel='Hidden state layer',xticks=range(len(layer_labels)),xticklabels=layer_labels,\n","           ylabel='$\\\\mathbf{\\\\Delta}$',title='B) Similarity mean differences')\n","\n","axs[1,0].scatter(,,s=150,edgecolor='k',\n","            c=plt.cm.plasma(np.linspace(0,1,num_hidden)),alpha=.7)\n","axs[1,0].set(xlabel='Hidden state layer',xticks=range(len(layer_labels)),xticklabels=layer_labels,\n","           ylabel='T-value',title='C) T-values')\n","\n","axs[1,1].scatter(,,s=150,edgecolor='k',\n","            c=plt.cm.plasma(np.linspace(0,1,num_hidden)),alpha=.7)\n","axs[1,1].set(xlabel='$\\\\mathbf{\\\\Delta}$',ylabel='T-value',title='D) Impact of normalization')\n","\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj25_part3.png')\n","plt.show()"],"metadata":{"id":"itGGklJXsBzE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for seqi in range(len(words)):\n","\n","  # find max token\n","  maxtok = torch.argmax\n","\n","  # build and print the sentence\n","  sentence = f'{}{}'\n","  print(sentence)"],"metadata":{"id":"Ncn1Zl04P994"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"K1ADpiUDfrP4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 4: Same words, different contexts**"],"metadata":{"id":"zKK3yYj0frNT"}},{"cell_type":"code","source":["# Note: Some variables here overwrite variables defined in earlier parts."],"metadata":{"id":"hIxAJ489clKY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# GreatGatsby\n","url = 'https://www.gutenberg.org/cache/epub/64317/pg64317.txt'\n","text = requests.get(url).text\n","tokens = np.array( tokenizer.encode(text) )\n","print(f'There are {len(tokens):,} tokens, {len(set(tokens))} of which are unique.')"],"metadata":{"id":"hDn0ElF9frKR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["targets = [' years',' garage', ' lawn']\n","\n","for i,w in enumerate(targets):\n","\n","  # this token index\n","  t = tokenizer.\n","\n","  # find all the matches\n","  matches =\n","  labels =\n","  together =\n","\n","  # stitch together\n","\n","\n","  # print count and confirm single-token words\n","  print(f'{w:>10} is token {t} and appears {} times.')"],"metadata":{"id":"dZ70Cm0UfrHF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["contextwin = 50\n","\n","# create a batch\n","batch = torch.zeros((target_idxs.shape[0],contextwin+1),dtype=torch.long)\n","\n","\n","for i in range(target_idxs.shape[0]):\n","  toks = tokens[:]\n","  batch[i,:] = torch.tensor(toks)\n","\n","batch.shape"],"metadata":{"id":"VJtCfQzNAHdS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# show last few tokens in each sentence\n","for b in batch:\n","  print(tokenizer.decode(b[-5:]))"],"metadata":{"id":"z67kyE87AHaR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ntxEdoam4DEu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 5: Within- and across-word similarities**"],"metadata":{"id":"GKs8f9GP4DCJ"}},{"cell_type":"code","source":["# forward pass (~25 sec on CPU)\n","with torch.no_grad():\n","  outs = model\n","\n","outs.hidden_states[3].shape"],"metadata":{"id":"-yI7abS6kGAL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# extract embeddings vectors for final token\n","activations = outs.hidden_states\n","\n","# mask for cosine similarity matrix\n","cat_mask = np.triu( )\n","\n","plt.imshow(cat_mask)\n","plt.gca().set(xlabel='Sequence index',ylabel='Sequence index')\n","plt.colorbar(pad=.02)\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj25_part5a.png')\n","plt.show()"],"metadata":{"id":"ftmHcJLvlLPL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# cosine similarity matrix for one layer\n","layeri = 4\n","hs = outs.hidden_states[][,,]\n","hs /= (hs,axis=1,keepdims=True)\n","csMat = hs @ hs.T\n","\n","# extract the block-wise data\n","within =\n","acros1 =\n","acros2 =\n","\n","# distributions\n","yWithin,xWithin = torch.histogram(within,bins=30,density=True)\n","yAcros1,xAcros1 = torch.histogram(acros1,bins=30,density=True)\n","yAcros2,xAcros2 = torch.histogram(acros2,bins=30,density=True)\n","\n","\n","# show the similarity matrix\n","_,axs = plt.subplots(1,2,figsize=(10,4))\n","h = axs[0].imshow(csMat,vmin=.5,vmax=1)\n","plt.colorbar(h,ax=axs[0],pad=.01)\n","axs[0].set(xlabel='Word index',ylabel='Word index',title='Cosine similarity matrix')\n","\n","# and the distributions\n","axs[1].plot(xWithin[:-1],yWithin,linewidth=2,label='Within-category')\n","axs[1].plot(xAcros1[:-1],yAcros1,linewidth=2,label='<years,garage/lawn>')\n","axs[1].plot(xAcros2[:-1],yAcros2,linewidth=2,label='<garage,lawn>')\n","axs[1].set(ylim=[0,None],xlabel='Cosine similarity',ylabel='Density',\n","           title=f'Layer {layeri} distributions')\n","axs[1].legend()\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj25_part5b.png')\n","plt.show()"],"metadata":{"id":"NPILgfI7lLGF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"HVCy82WNlK9_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 6: Laminar profiles of similarity distributions**"],"metadata":{"id":"Qut4B7wNlK6u"}},{"cell_type":"code","source":["# common histogram bins for all distributions\n","binedges = torch.linspace(.4,1,35)\n","dx = binedges[1]-binedges[0]\n","\n","# initialize: grouping X layer X bin\n","cs_dists = torch.zeros((3,num_hidden, ))\n","\n","# loop over layers\n","for layeri in range():\n","\n","  # calculate the similarity matrix\n","  hs = outs.hidden_states[layeri][:,-1,:]\n","  hs /= torch.linalg.norm(hs\n","  csMat =\n","\n","  # extract the category elements\n","  within = torch.concatenate((csMat[cat_mask==1],csMat[cat_mask==4],csMat[cat_mask==9]))\n","  acros1 = torch.concatenate((csMat[cat_mask==2],csMat[cat_mask==3]))\n","  acros2 = csMat[cat_mask==6]\n","\n","  # calculate the histograms\n","  cs_dists[0,layeri,:],_ = torch.histogram()\n","  cs_dists[1,layeri,:],_ = torch.histogram\n","  cs_dists[2,layeri,:],_ = torch.\n","\n","\n","# transform from density to probability/dx\n"],"metadata":{"id":"BM5zQDcXlK36"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# the tornado plots :D\n","_,axs = plt.subplots(1,3,figsize=(12,4))\n","\n","titles = [ 'Within','<years,garage/lawn>','<lawn,garage>' ]\n","\n","# generate the plots\n","for i in range(3):\n","  h = axs[i].imshow(cs_dists[i,:,:],vmin=0,vmax=.25,aspect='auto',origin='lower',\n","                extent=[binedges[0],binedges[-1],0,num_hidden],cmap='magma')\n","  plt.colorbar(h,ax=axs[i]\n","  axs[i].set(xlabel='Cosine similarity',ylabel='Hidden layer')\n","  axs[i].set_title()\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj25_part6.png')\n","plt.show()"],"metadata":{"id":"B5LVFya5lKyK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YnC2_TzgGiCW"},"execution_count":null,"outputs":[]}]}