{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["|<h2>Book:</h2>|<h1><a href=\"https://open.substack.com/pub/mikexcohen/p/llm-breakdown-16-tokenization-words\" target=\"_blank\">50 ML projects to understand LLMs</a></h1>|\n","|-|:-:|\n","|<h2>Project:</h2>|<h1><b>[30] Sentiment analysis with decision trees</b></h1>|\n","|<h2>Author:<h2>|<h1>Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h1>|\n","\n","<br>\n","\n","<i>Using the code without reading the book may lead to confusion or errors.</i>"],"metadata":{"id":"py_eibYAH3Q-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OxmEbIoa-yv0"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","\n","from tqdm import tqdm\n","from scipy.stats import ttest_ind\n","\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.decomposition import PCA\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","\n","from transformers import BertTokenizer, BertModel\n","from datasets import load_dataset"]},{"cell_type":"code","source":[],"metadata":{"id":"R5SI-Iyy4dtm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### matplotlib adjustments (commented lines are for dark mode)\n","\n","# svg plots (higher-res)\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n","\n","plt.rcParams.update({\n","    # 'figure.facecolor': '#282a2c',\n","    # 'figure.edgecolor': '#282a2c',\n","    # 'axes.facecolor':   '#282a2c',\n","    # 'axes.edgecolor':   '#DDE2F4',\n","    # 'axes.labelcolor':  '#DDE2F4',\n","    # 'xtick.color':      '#DDE2F4',\n","    # 'ytick.color':      '#DDE2F4',\n","    # 'text.color':       '#DDE2F4',\n","    'axes.spines.right': False,\n","    'axes.spines.top':   False,\n","    'axes.titleweight': 'bold',\n","    'axes.labelweight': 'bold',\n","    'savefig.dpi':300\n","})"],"metadata":{"id":"dy4A-ah8kzZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qilMvpnHGqDb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 1: Import BERT and dataset**"],"metadata":{"id":"pc_8Bl8XGqAi"}},{"cell_type":"code","source":["# load BERT tokenizer and model\n","tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n","model = BertModel.from_pretrained('bert-large-uncased', output_hidden_states=True)\n","model.eval()"],"metadata":{"id":"APaaXsHI-4bB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# move the model to the GPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device);"],"metadata":{"id":"43gNqb7r_0UO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load a subset (5%) of sst-2 sentiment dataset\n","dataset = load_dataset('glue','sst2',split='train[:5%]')\n","\n","dataset"],"metadata":{"id":"qj5QoIec-8jo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset[123]"],"metadata":{"id":"ZSt4fK97HGml"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# extract and count the labels\n","labels = [sample['label'] ]\n","\n","num_samples =\n","\n","uniq,counts = np.unique(labels,return_counts=True)\n","for u,c in zip(uniq,counts):\n","  print"],"metadata":{"id":"Vv5UkkRxHKxZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gQp1N3DAHKrR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 2: Create batches**"],"metadata":{"id":"rDA6vxswIYlV"}},{"cell_type":"code","source":["batchsize = 32\n","num_batch =\n","sample_size =\n","\n","print(f'There are {} batches of size {}, leading to {} total samples.')"],"metadata":{"id":"nEfzMrp1IYif"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["allbatches = []\n","alllabels = []\n","\n","for batchi in range(num_batch):\n","\n","  # start and end indices\n","  startidx =\n","  endidx =\n","\n","  # append texts\n","  tmp_texts = []\n","  tmp_labels = []\n","  for samplei in range(startidx,endidx):\n","    tmp_texts.append(\n","    tmp_labels.append(\n","\n","  # tokenize\n","  tokens = tokenizer(tmp_texts,return_tensors='pt',padding=True)\n","  allbatches.append(\n","  alllabels.append("],"metadata":{"id":"dLyaDnboInrN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(alllabels), len(allbatches)"],"metadata":{"id":"PFsWUPGrKVK3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(alllabels[10]), allbatches[10], allbatches[10]['input_ids'].shape"],"metadata":{"id":"RRe1B90jKaZ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# lengths of different batches\n","seqlens = [allbatches[i]['input_ids'].shape[1] for i in ]\n","numseqs =\n","\n","plt.figure(figsize=(8,3))\n","plt.plot(label='Number of sequences')\n","plt.plot(label='Number of tokens')\n","plt.gca().set(xlabel='Batch number',ylabel='Counts',ylim=[10,70])\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj30_part2.png')\n","plt.show()"],"metadata":{"id":"hBJhrGHB8NJD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# just one batch to confirm shapes\n","outputs = model(\n","outputs.hidden_states[4].shape"],"metadata":{"id":"KMmWkoAmHKoe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JGlxzvmaHKlq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 3: Get the [CLS] hidden state activations from one layer**"],"metadata":{"id":"dpXODZelKt34"}},{"cell_type":"code","source":["# this code block takes a very long time on a standard CPU, ~5 mins on a high-power CPU, and a few seconds on a GPU\n","cls_activations = []\n","\n","for batchi in tqdm(range(num_batch)):\n","\n","  # run the model\n","  outputs = model(\n","\n","  # extract the CLS activation from the hidden states\n","  cls_batch =\n","\n","  # append to a list\n","  cls_activations.append(\n","\n","# and convert to numpy\n","cls_activations = np.vstack()\n","labels = np.hstack()\n","\n","cls_activations.shape, labels.shape"],"metadata":{"id":"Zbra0tR6Kyl1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# extract average activations\n","acts0 = cls_activations\n","acts1 =\n","\n","# t-test\n","t = ttest_ind(,)\n","\n","# the violin plot\n","plt.figure(figsize=(8,5))\n","v = plt.violinplot\n","\n","# change the colors\n","v['bodies'][0].set_facecolor([.9,.7,.7])\n","v['bodies'][1].set_facecolor([.7,.9,.7])\n","v['cbars'].set_edgecolor('k')\n","v['cmins'].set_edgecolor('k')\n","v['cmaxes'].set_edgecolor('k')\n","\n","# draw all the dots\n","plt.plot(,'.',color=[.9,.7,.7,.3])\n","plt.plot(,'.',color=[.7,.9,.7,.3])\n","\n","# and finishing touches\n","plt.axhline(0,linestyle='--',linewidth=.2,color='k')\n","plt.gca().set(xticks=[1,2],xticklabels=['Negative','Positive'],ylabel='Mean [CLS] Activation',xlim=[.5,2.5])\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj30_part3.png')\n","plt.show()"],"metadata":{"id":"gZkZb_G2NWVO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mRVn5Xq7KtxP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 4: Single-layer decision-tree classifier**"],"metadata":{"id":"JBm5slnkSqMY"}},{"cell_type":"code","source":["# dimension reduction with pca\n","pca = PCA(\n","act_reduced = pca.fit_transform(\n","\n","print(f'Kept {} components explaining {} variance.\\n')\n","print(f'Original data size is {}')\n","print(f' Reduced data size is {}\\n')\n","print(f'Observations:features ratio is {}:{} = {}')"],"metadata":{"id":"tvcGLX6r_ADA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# split the data into train and test\n","X_train,X_test, y_train,y_test = train_test_split(,,test_size=.2,)\n","dectree = DecisionTreeClassifier(\n","dectree.fit\n","\n","# train and test accuracy\n","train_acc = (dectree.predict(X_train) == ).mean()\n","test_acc  =\n","\n","print(f'Accuracies: Train {train_acc:.2%}, Test: {test_acc:.2%}')"],"metadata":{"id":"BHfbPZ1XQ0w3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# how many times to repeat the random data split\n","num_reps = 20\n","\n","# re-initialize as arrays\n","train_acc = np.zeros(num_reps)\n","test_acc = np.zeros(num_reps)\n","\n","# loop over reps\n","for i in\n","\n","  # run the analysis\n","  X_train,X_test,y_train,y_test = train_test_split\n","  dectree =\n","  dectree.fit(\n","\n","  # calculate and store accuracies\n","  train_acc[i] =\n","  test_acc[i]  =\n"],"metadata":{"id":"JPA4NnUdRoIA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10,4))\n","\n","plt.plot(,label='Train')\n","plt.plot(,label='Test')\n","\n","plt.axhline(,linestyle='--',color=[.7,.7,.9])\n","plt.axhline(,linestyle='--',color=[.9,.7,.7])\n","\n","\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj30_part4a.png')\n","plt.show()"],"metadata":{"id":"BcNgJYzVSgvX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# feature importances (of final run from previous cell)\n","importances = dectree.feature_importances_\n","indices = np.argsort(\n","\n","plt.figure(figsize=(10,3))\n","plt.title(\"Feature Importances (Top 10 PCs)\")\n","for i in range(10):\n","  imp_val = importances[indices[i]]\n","  plt.bar(,,color=plt.cm.plasma(imp_val/importances.max()),edgecolor='k')\n","plt.xticks(range(10), [f\"PC{indices[i]+1}\" for i in range(10)], rotation=45)\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj30_part4b.png')\n","plt.show()"],"metadata":{"id":"goQNXkxJ_HYu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# FYI (not part of the exercise)\n","# The tree plot shows which features were used in each leaf split.\n","# However, this plot isn't really interpretable for PCA data.\n","import sklearn.tree\n","plt.figure(figsize=(14,10))\n","sklearn.tree.plot_tree(dectree,fontsize=10);"],"metadata":{"id":"dQxYkpwKTP2o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"GLNzuDVBAN_5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 5: Collect [CLS] activations from all layers**"],"metadata":{"id":"H7YrMYmUQ0tl"}},{"cell_type":"code","source":["# the number of hidden-states from the model output (transformers + 1)\n","num_layers = model.config.num_hidden_layers + 1\n","\n","# list to store all the activations\n","hs_acts = [np.zeros((sample_size,model.config.hidden_size)) for _ in range(num_layers)]\n","\n","# loop over all batches\n","idx = 0\n","for batchi in tqdm(range(num_batch)):\n","\n","  # run the model\n","  outputs = model\n","\n","  # extract the CLS activation from the hidden states\n","  for hsi,hs in enumerate(outputs.hidden_states):\n","    hs_acts[hsi][:+] =\n","  idx += batchsize\n"],"metadata":{"id":"snrHaz6LQ0qs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(hs_acts), hs_acts[hsi].shape"],"metadata":{"id":"Oa2Ipc7uBYcv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualize the vector averages\n","plt.figure(figsize=(10,4))\n","\n","for hsi in range(len(hs_acts)):\n","  plt.plot(,,'ko',markerfacecolor=[.9,.7,.7,.3],linewidth=0)\n","  plt.plot(,,'ks',markerfacecolor=[.7,.9,.7,.3],linewidth=.1)\n","\n","\n","plt.gca().set(xlabel='Hidden layer',ylabel='CLS activation (mean)')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj30_part5a.png')\n","plt.show()"],"metadata":{"id":"FHfujiay6dkX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XDLOEkjC8q_B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 6: Laminar profile of classification accuracy**"],"metadata":{"id":"9u0ivKf58q8F"}},{"cell_type":"code","source":["# main analysis\n","\n","# initializations\n","accuracies = np.zeros((num_layers,2))\n","\n","num_reps = 5\n","train_acc = np.zeros(num_reps)\n","test_acc = np.zeros(num_reps)\n","\n","\n","# loop over layers\n","for layeri in range(num_layers):\n","\n","\n","  # loop over repetitions for stability\n","  for i in range(num_reps):\n","\n","    # 1) split the data\n","    X_train,X_test,y_train,y_test =\n","\n","    # 2) fit the PCA on the train data\n","    pca =\n","    X_train_pca =\n","\n","    # 3) apply the PCA transform to the test set\n","    X_test_pca  =\n","\n","    # 4) fit the decision-tree model\n","    dectree =\n","    dectree.fit\n","\n","    # train accuracy\n","    train_acc[i] =\n","    test_acc[i]  =\n","\n","  # average accuracies for this layer\n","  accuracies[layeri,0] =\n","  accuracies[layeri,1] =\n","\n","  print(f'Finished layer {}/{} with {} test accuracy.')"],"metadata":{"id":"0e4_tO-CSkJM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10,4))\n","plt.plot(,'ks-',linewidth=.2,markerfacecolor=[.7,.9,.7],markersize=12,label='Train')\n","plt.plot(,'ko-',linewidth=.2,markerfacecolor=[.7,.7,.9],markersize=12,label='Test')\n","\n","plt.legend()\n","plt.gca().set(xlabel='Hidden state layer',ylabel='Accuracy')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj30_part5b.png')\n","plt.show()"],"metadata":{"id":"pOEadxFQSkGY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8l8TZ9QbXQxg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 7: Performance benefit per transformer**"],"metadata":{"id":"jv71O5YqXQud"}},{"cell_type":"code","source":["# create the predictor variable (IV)\n","predictor = np.arange(1,num_layers\n","\n","# fit the model\n","reg = LinearRegression(\n","print(f'beta_0: {:6.3%}')\n","print(f'beta_1: {:7.3%}')\n","\n","# calculate predicted accuracies\n","yHat = reg.predict()"],"metadata":{"id":"R62HgIrmVtTt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# and visualize\n","plt.figure(figsize=(10,4))\n","plt.plot(,,'k',label='Linear fit')\n","plt.plot(,,'ko-',linewidth=.2,markerfacecolor=[.7,.7,.9],markersize=12,label='Data')\n","\n","plt.gca().set(xlabel='Number of transformers',ylabel='Accuracy',\n","              title=f'Increase of {reg.coef_[0]:.2%} accuracy per transformer')\n","plt.legend(loc='upper left')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj30_part6.png')\n","plt.show()"],"metadata":{"id":"yLwsFLi-Z2ID"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'Regression-predicted boost per transformer  : {:.4%}')\n","print(f'Empirically calculated boost per transformer: {}')"],"metadata":{"id":"NwldPR3HSkDs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-0Rq3-76YZx2"},"execution_count":null,"outputs":[]}]}