{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Book:</h2>|<h1><a href=\"https://open.substack.com/pub/mikexcohen/p/llm-breakdown-16-tokenization-words\" target=\"_blank\">50 ML projects to understand LLMs</a></h1>|\n","|-|:-:|\n","|<h2>Project:</h2>|<h1><b>[26] Current layer = previous layer + adjustments</b></h1>|\n","|<h2>Author:<h2>|<h1>Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h1>|\n","\n","<br>\n","\n","<i>Using the code without reading the book may lead to confusion or errors.</i>"],"metadata":{"id":"py_eibYAH3Q-"}},{"cell_type":"code","source":[],"metadata":{"id":"R5SI-Iyy4dtm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from scipy.stats import pearsonr,spearmanr\n","\n","import torch\n","\n","from transformers import AutoModelForCausalLM, AutoTokenizer"],"metadata":{"id":"rn8Fcyf87EXx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### matplotlib adjustments (commented lines are for dark mode)\n","\n","# svg plots (higher-res)\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n","\n","plt.rcParams.update({\n","    # 'figure.facecolor': '#282a2c',\n","    # 'figure.edgecolor': '#282a2c',\n","    # 'axes.facecolor':   '#282a2c',\n","    # 'axes.edgecolor':   '#DDE2F4',\n","    # 'axes.labelcolor':  '#DDE2F4',\n","    # 'xtick.color':      '#DDE2F4',\n","    # 'ytick.color':      '#DDE2F4',\n","    # 'text.color':       '#DDE2F4',\n","    'axes.spines.right': False,\n","    'axes.spines.top':   False,\n","    'axes.titleweight': 'bold',\n","    'axes.labelweight': 'bold',\n","    'savefig.dpi':300\n","})"],"metadata":{"id":"dy4A-ah8kzZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nxqgPabM0FuN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 1: Hooks and hidden states**"],"metadata":{"id":"DA3zcyDTHsH7"}},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained('gpt2')\n","model = AutoModelForCausalLM.from_pretrained('gpt2',output_hidden_states=True)\n","model.eval()"],"metadata":{"id":"v-DJGMfhlIiu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"GojwUPbUMscF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# initialize the dictionary containing data\n","transf_out = {}\n","\n","# the hook function\n","def hook(module, input, output):\n","  # module: the layer the hook is attached to\n","  # input : inputs passed into that layer during the forward pass\n","  # output: output of that layer\n","  transf_out['data'] = output[0].detach()\n","\n","# implant the hook\n","layi = 5\n","handle = model.transformer.h[layi].register_forward_hook(hook)"],"metadata":{"id":"-WRep4v2jqu4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text = \"Plants make fantastic pets because they don't leave a mess after you feed them.\"\n","tokens = tokenizer.encode(text,return_tensors='pt')\n","\n","# forward pass to trigger the hook\n","with torch.no_grad():\n","  outputs = model(tokens)\n","\n","# remove the hook\n","handle.remove()"],"metadata":{"id":"hVgUv_F8luyl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('     Hidden states is size:',outputs.hidden_states[layi+1].shape)\n","print('Transformer output is size:',transf_out['data'].shape)"],"metadata":{"id":"Nze8b2U4mPzc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10,4))\n","\n","dimnum = 123\n","\n","plt.plot(outputs.hidden_states[layi+1][0,:,dimnum],'o-',markeredgecolor='k',\n","         color=[.7,.7,.9],markerfacecolor=[.7,.7,.9],markersize=10,label='Hidden state')\n","plt.plot(transf_out['data'][0,:,dimnum],'r+',markersize=14,markeredgewidth=2,label='Transformer output')\n","\n","plt.gca().set(xlabel='Token position',ylabel='Activation value',title=f'Hidden state vs. transformer output from dimension {dimnum}')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj26_part1.png')\n","plt.show()"],"metadata":{"id":"9jVRrv4tlxhX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# differences are zeros\n","outputs.hidden_states[layi+1] - transf_out['data']"],"metadata":{"id":"-3xZYRvPlxac"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"t3HYqSBGlxRc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 2: Final hidden layer normalization**"],"metadata":{"id":"C-NRd_RAoE63"}},{"cell_type":"code","source":["n_layers = model.config.n_layer"],"metadata":{"id":"2_w45RdYporn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# hook all hidden layers\n","transf_out = {}\n","\n","def outerHook(layeri):\n","  def hook(module, input, output):\n","    transf_out[f'layer_{layeri}'] = output[0].detach()\n","  return hook\n","\n","handles = []\n","for layeri in range(model.config.n_layer):\n","  modname = model.transformer.h[layeri]\n","  h = modname.register_forward_hook(outerHook(layeri))\n","  handles.append(h)"],"metadata":{"id":"nUdvwlm2oGy3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# forward pass to trigger the hook\n","with torch.no_grad():\n","  outputs = model(tokens)\n","\n","# remove the hooks\n","for h in handles:\n","  h.remove()"],"metadata":{"id":"GMeoTRTDoE3U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Here are the keys in transf_out:\\n ',transf_out.keys(),'\\n')\n","print(\"transf_out['layer_3'] has size:\\n \",transf_out['layer_3'].shape)"],"metadata":{"id":"UwKlNU1PBjcc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# initialize\n","norms = torch.zeros(n_layers)\n","\n","# loop over layers\n","for i in range(n_layers):\n","  diffmat = outputs.hidden_states[i+1] - transf_out[f'layer_{i}']\n","  norms[i] = torch.norm(diffmat)"],"metadata":{"id":"5ntys_1IoE0L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(8,3))\n","plt.plot(norms,'kh',markerfacecolor=[.9,.7,.7],markersize=14)\n","plt.gca().set(xlabel='Hidden layer',ylabel='Norm of difference',\n","              title='Differences between hidden_state and hook output')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj26_part2.png')\n","plt.show()"],"metadata":{"id":"IR6IpnzQlxV4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lastL = model.config.n_layer - 1\n","\n","layerNorm_final = model.transformer.ln_f( transf_out[f'layer_{lastL}'] )\n","outputs.hidden_states[lastL+1] - layerNorm_final"],"metadata":{"id":"t-Q7qv95j0hd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5PDga8kvjqsI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 3: Hooking attention and MLP adjustments**"],"metadata":{"id":"tBDJCOHIjqpk"}},{"cell_type":"code","source":["# re-initialize activations dictionary\n","activations = {}\n","\n","# into attention projections\n","def hook_att(module, input, output):\n","  activations['attn'] = output.detach()\n","\n","# and into mlp projections\n","def hook_mlp(module, input, output):\n","  activations['mlp'] = output.detach()\n","\n","\n","# implant hooks into projection layers\n","layer2hook = 10\n","\n","model.transformer.h[layer2hook].attn.c_proj.register_forward_hook(hook_att)\n","model.transformer.h[layer2hook].mlp.c_proj.register_forward_hook(hook_mlp)"],"metadata":{"id":"HS30s7Zojqmw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# forward pass to trigger the hook\n","with torch.no_grad():\n","  outputs = model(tokens)\n","\n","print('Here are the keys in \"activations\":\\n ',activations.keys(),'\\n')\n","print(\"activations['attn'] has size:\\n \",activations['attn'].shape,'\\n')\n","print(\"activations['mlp'] has size:\\n \",activations['mlp'].shape)"],"metadata":{"id":"7ql3TAtPjqkL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_,axs = plt.subplots(1,2,figsize=(10,4))\n","\n","\n","# loop over tokens\n","for toki in range(len(tokens[0])):\n","\n","  # extract vectors\n","  a = activations['attn'][0,toki,:]\n","  m = activations['mlp'][0,toki,:]\n","\n","  # correlate them\n","  r_p = pearsonr(a,m).statistic\n","  r_s = spearmanr(a,m).statistic\n","\n","  # plot them\n","  axs[0].plot(toki,r_p,'ks',markerfacecolor=[.9,.7,.7],markersize=10)\n","  axs[0].plot(toki,r_s,'ko',markerfacecolor=[.7,.9,.7],markersize=10)\n","  axs[0].plot([toki,toki],[r_p,r_s],'--',color=[.3,.3,.3],linewidth=.7,zorder=-10)\n","\n","\n","axs[0].legend(['Pearson','Spearman'])\n","axs[0].axhline(0,linestyle=':',color=[.7,.7,.7],zorder=-20)\n","axs[0].set(xlabel='Token index',ylabel='Correlation (r)',\n","           title='A) Attention vs. MLP adjustments')\n","\n","\n","axs[1].plot(a,m,'kh',markerfacecolor=[.7,.7,.9,.7],markersize=10)\n","axs[1].grid(linestyle='--',color=[.7,.7,.7],linewidth=.7)\n","axs[1].set(xlabel='Attention output',ylabel='MLP output',\n","           title=f'B) Data from token #{toki}')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj26_part3.png')\n","plt.show()"],"metadata":{"id":"KbUe60ijvrwE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EwEBl8jkwmLE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 4: Reconstructing hidden state L from L-1**"],"metadata":{"id":"y7FFLNPAvm6F"}},{"cell_type":"code","source":["hs_pre = outputs.hidden_states[layer2hook]\n","hs_pst = outputs.hidden_states[layer2hook+1]\n","\n","# reconstruct one layer from the previous\n","recon = hs_pre + activations['attn'] + activations['mlp']\n","\n","print('  Attention size:', activations['attn'].shape)\n","print('        MLP size:', activations['mlp'].shape)\n","print('Hidden state pre:', hs_pre.shape)\n","print('Hidden state pst:', hs_pst.shape)"],"metadata":{"id":"U7-AS7sYkpmH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# demonstrate the reconstruction accuracy\n","recon-hs_pst, torch.norm(recon-hs_pst)"],"metadata":{"id":"D9GGgOGuUGHM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# common axis limits\n","ax_lim = max( torch.max(torch.abs(hs_pre[0,1:,:])).item(),\n","              torch.max(torch.abs(hs_pst[0,1:,:])).item() )\n","\n","# increase a bit for marker size\n","ax_lim *= 1.1"],"metadata":{"id":"U5Dd8_2FtcR7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_,axs = plt.subplots(1,3,figsize=(12,3.5))\n","\n","axs[0].plot(hs_pre[0,1:,:].flatten(),hs_pst[0,1:,:].flatten(),'ko',markerfacecolor=[.9,.7,.7,.5],markersize=8)\n","axs[0].set(xlabel=f'Hidden layer {layer2hook}',ylabel=f'Hidden layer {layer2hook+1}',\n","           title='A) Hidden state activations',xlim=[-ax_lim,ax_lim],ylim=[-ax_lim,ax_lim])\n","\n","axs[1].plot(activations['attn'][0,1:,:].flatten(),activations['mlp'][0,1:,:].flatten(),'ks',markerfacecolor=[.7,.7,.9,.5],markersize=8)\n","axs[1].set(xlabel=f'B) Attention layer {layer2hook}',ylabel=f'MLP layer {layer2hook}',title='B) Adjustments',\n","           xlim=[-ax_lim,ax_lim],ylim=[-ax_lim,ax_lim])\n","\n","axs[2].plot(hs_pst[0,1:,:].flatten(),recon[0,1:,:].flatten(),'kh',markerfacecolor=[.7,.9,.7,.5],markersize=8)\n","axs[2].set(xlabel=f'Hidden layer {layer2hook+1}',ylabel=f'HL({layer2hook}) + attn + mlp',title='C) Reconstructed',\n","           xlim=[-ax_lim,ax_lim],ylim=[-ax_lim,ax_lim])\n","\n","for a in axs:\n","  a.grid(linestyle='--',color=[.3,.3,.3],linewidth=.5)\n","\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj26_part4.png')\n","plt.show()"],"metadata":{"id":"QvubUM0QkpdZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xBOIKI2-rx3H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 5: Overwriting hooked activations**"],"metadata":{"id":"tB3b4_3tkpav"}},{"cell_type":"code","source":["activations['attn'].shape"],"metadata":{"id":"dTzqwbI9yRwq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model(tokenizer.encode('I like corn',return_tensors='pt'))\n","activations['attn'].shape"],"metadata":{"id":"X5IfkiIOyT2_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# no handles to remove, must reimport :(\n","model = AutoModelForCausalLM.from_pretrained('gpt2',output_hidden_states=True)\n","model.eval();"],"metadata":{"id":"iAnTSyBAykIS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["activations = []\n","def mlp_hook(module, inp, out):\n","  activations.append(out)\n","\n","# hook the MLP in layer 4\n","handle = model.transformer.h[4].mlp.c_proj.register_forward_hook(mlp_hook)"],"metadata":{"id":"uzJs01bKykDI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# run some text through the model\n","model( tokenizer.encode('I like chocolate.',return_tensors='pt') );"],"metadata":{"id":"xZlmeftsQeV4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# note: just a list, not a dictionary!\n","activations"],"metadata":{"id":"6bPYmHtSQeSy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'\"activations\" is a {type(activations)} that contains {len(activations)} elements \\n')\n","for i in range(len(activations)):\n","  print(f'Element {i} has shape {activations[i].shape}')"],"metadata":{"id":"fESbxeIBQePg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# run the model three more times\n","model( tokenizer.encode('I still like chocolate.',return_tensors='pt') )\n","model( tokenizer.encode('You know the shape my breath will take before I let it out.',return_tensors='pt') )\n","model( tokenizer.encode('Four score and seven years ago.',return_tensors='pt') );"],"metadata":{"id":"No81t-UoRUj5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'\"activations\" is a {type(activations)} that contains {len(activations)} elements \\n')\n","for i in range(len(activations)):\n","  print(f'Element {i} has shape {activations[i].shape}')"],"metadata":{"id":"iQnPfW1pkpX9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8Q8f_53byj8V"},"execution_count":null,"outputs":[]}]}