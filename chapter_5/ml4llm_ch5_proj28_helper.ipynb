{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"L4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["|<h2>Book:</h2>|<h1><a href=\"https://open.substack.com/pub/mikexcohen/p/llm-breakdown-16-tokenization-words\" target=\"_blank\">50 ML projects to understand LLMs</a></h1>|\n","|-|:-:|\n","|<h2>Project:</h2>|<h1><b>[28] Effective dimensionality of hidden layers</b></h1>|\n","|<h2>Author:<h2>|<h1>Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h1>|\n","\n","<br>\n","\n","<i>Using the code without reading the book may lead to confusion or errors.</i>"],"metadata":{"id":"py_eibYAH3Q-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OxmEbIoa-yv0"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","\n","import requests\n","\n","import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer"]},{"cell_type":"code","source":["### matplotlib adjustments (commented lines are for dark mode)\n","\n","# svg plots (higher-res)\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n","\n","plt.rcParams.update({\n","    # 'figure.facecolor': '#282a2c',\n","    # 'figure.edgecolor': '#282a2c',\n","    # 'axes.facecolor':   '#282a2c',\n","    # 'axes.edgecolor':   '#DDE2F4',\n","    # 'axes.labelcolor':  '#DDE2F4',\n","    # 'xtick.color':      '#DDE2F4',\n","    # 'ytick.color':      '#DDE2F4',\n","    # 'text.color':       '#DDE2F4',\n","    'axes.spines.right': False,\n","    'axes.spines.top':   False,\n","    'axes.titleweight': 'bold',\n","    'axes.labelweight': 'bold',\n","    'savefig.dpi':300\n","})"],"metadata":{"id":"dy4A-ah8kzZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SDtqs90O2uGL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Concept of effective dimensionality**"],"metadata":{"id":"gLhUL-hM9o9E"}},{"cell_type":"code","source":["# a bit of data\n","x = np.random.uniform(low=0,high=5,size=50)\n","y = np.random.normal(loc=0,scale=.07,size=len(x))\n","\n","_,axs = plt.subplots(1,2,figsize=(9,3.5))\n","axs[0].plot(x,x,'ko',markerfacecolor=[.9,.7,.7,.5],markersize=10)\n","axs[1].plot(x,x+y,'ko',markerfacecolor=[.7,.9,.9,.5],markersize=10)\n","\n","for a in axs:\n","  a.axis('square')\n","  a.plot([0,5],[0,5],color='gray',zorder=-2)\n","\n","axs[0].set(xlabel='x',ylabel='y',title='A) 1-dimensional data')\n","axs[1].set(xlabel='x',ylabel='y',title='B) 1 effective dimension')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj28_part0.png')\n","plt.show()"],"metadata":{"id":"vP8XWGCB9p6p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"aHUQN2609o6L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 1: Logits from real and shuffled token sequences**"],"metadata":{"id":"uZo9uw2k2uDm"}},{"cell_type":"code","source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"1Cno6-hj2uAi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load GPT2 model and tokenizer\n","model = AutoModelForCausalLM.from_pretrained('gpt2-xl')\n","tokenizer = AutoTokenizer.from_pretrained('gpt2-xl')\n","\n","max_seq_len =\n","\n","model.to(device)\n","model.eval()"],"metadata":{"id":"Fs5uYfMAOeL3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### use this cell for Part 4\n","# from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","# tokenizer = AutoTokenizer.from_pretrained('EleutherAI/pythia-2.8b')\n","# model = AutoModelForCausalLM.from_pretrained('EleutherAI/pythia-2.8b')\n","\n","# max_seq_len =\n","\n","# model.to(device)\n","# model.eval()"],"metadata":{"id":"a8QL76qpNSCq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Through the looking glass (Alice in Wonderland)\n","text = requests.get('https://www.gutenberg.org/cache/epub/11/pg11.txt').text\n","\n","# for Part 6\n","# text = requests.get('https://www.gutenberg.org/').text\n","\n","\n","allTokens =\n","\n","# get context-length from middle of the book\n","start_idx =\n","end_idx =\n","\n","tokens = allTokens[]\n","\n","print(tokenizer.decode(tokens[0]))"],"metadata":{"id":"1QCtJSG8LRVO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokensShuffle = tokens[]\n","print(tokenizer.decode(tokensShuffle[0]))"],"metadata":{"id":"_KEpro9XLRDg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# push through the model (~3 mins with gpt2-xl on standard CPU, or <1s on GPU, lol)\n","with torch.no_grad():\n","  outputs_real = model(\n","  outputs_shuf = model(\n","\n","outputs_real.hidden_states[0].shape"],"metadata":{"id":"DfiAwJNxLRSe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# calculate log-softmax of logits (note the method instead of function)\n","log_sm_real = outputs_real.logits.log_softmax\n","log_sm_shuf = outputs_shuf.logits.log_softmax\n","\n","# find the indices of the max log-sm values\n","maxidx = torch.argmax(log_sm_real,\n","\n","# then find the actual log-sm values from those indices\n","maxvals = []\n","\n","# and calculate the histogram\n","yReal,xReal = np.histogram(\n","\n","\n","### repeat for shuffled\n","maxidx =\n","maxvals =\n","yShuf,xShuf =\n","\n","\n","# visualize\n","plt.figure(figsize=(9,3))\n","plt.plot(xReal[:-1],yReal,'bs-',markerfacecolor=[.7,.7,.9],markersize=12,linewidth=2,label='Real')\n","plt.plot(label='Shuffled')\n","\n","plt.gca().set(xlabel='Max log softmax',ylabel='Density',title='Maximum token probabilities')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj28_part1.png')\n","plt.show()"],"metadata":{"id":"XBiOIK-S2t9Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"v6M3uj_R-fpU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 2: Effective dimensionality in one layer (numpy)**"],"metadata":{"id":"GfJhg4lk-fme"}},{"cell_type":"code","source":["layeri = 10\n","\n","# extract all the activations from this layer\n","acts = outputs_real.\n","\n","# mean-center the activations\n","acts -=\n","\n","# get singular values\n","s = np.linalg.svd\n","\n","# percent explained (and cumulative)\n","pctExplained =\n","cumVarExplained =\n","\n","\n","_,axs = plt.subplots(1,2,figsize=(10,3))\n","\n","axs[0].plot(pctExplained,'ks',markersize=10,markerfacecolor=[.7,.9,.7,.7])\n","axs[0].set(xlim=[-2,60],xlabel='Component number',ylabel='Percent variance explained',\n","           title='A) Singular values spectrum')\n","\n","axs[1].plot(cumVarExplained,'ks',markersize=10,markerfacecolor=[.7,.7,.9,.7])\n","\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj28_part2.png')\n","plt.show()"],"metadata":{"id":"vluVtJ_l-fj5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["threshold = 95\n","\n","# count the components until 95% variance is explained\n","effectiveCompCount =\n","print(f'{} (out of {}) components explains {} variability')"],"metadata":{"id":"7-B2A7Ob27Ox"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6Ns9hwCU2t53"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 3: Laminar profile of effective dimensionality (PyTorch)**"],"metadata":{"id":"R5SI-Iyy4dtm"}},{"cell_type":"code","source":["numHidden = len(outputs_real.hidden_states)\n","numHidden"],"metadata":{"id":"ns3fdePRDnGH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# redefine threshold\n","threshold = 95\n","\n","# initialize\n","effectiveCompCount = torch.zeros((,),dtype=)\n","hs_ranks = torch.zeros((,),dtype=)\n","\n","\n","# loop over layers\n","for layeri in tqdm(range(numHidden)):\n","\n","  # extract all the activations from this layer (assuming no batches!)\n","  acts = outputs_real.\n","\n","  # mean-center the activations and calcuate rank\n","  acts -=\n","  hs_ranks[layeri,0] = torch.linalg.\n","\n","  # get singular values\n","  s = torch.linalg.\n","\n","  # percent explained (cumulative)\n","  pctExplained =\n","  cumVarExplained =\n","\n","  # count the components until 95% variance is explained\n","  compcount =\n","  effectiveCompCount[layeri,0] =\n","\n","\n","\n","  ### repeat for shuffled tokens\n","  acts =\n","  hs_ranks[layeri,1] =\n","  s = # get singular values\n","  pctExplained =\n","  cumVarExplained =\n","  effectiveCompCount[layeri,1] =\n"],"metadata":{"id":"54gA1dd1HXEm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for reference with the scatter plot\n","print(f'There are {} out of {} unique tokens.')"],"metadata":{"id":"CDqGWOeXWuWs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_,ax = plt.subplots(1,figsize=(10,3))\n","\n","## plot the \"effective subspace dimensionality\" of each layer\n","ax.plot(,'ks',markerfacecolor=[.9,.7,.7,.5],markersize=12,label='Shuffled tokens')\n","ax.plot(,label='Real tokens')\n","ax.legend()\n","ax.set(xlabel='Hidden layer',ylabel='Number of dimensions',title='Maximum possible dimensionality',xlim=[-1,numHidden])\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj28_part3a.png')\n","plt.show()"],"metadata":{"id":"-Madfi1ZTgHS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hs_ranks"],"metadata":{"id":"Fs4eFErPkfcE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_,ax = plt.subplots(1,figsize=(12,4))\n","\n","## plot the \"effective subspace dimensionality\" of each layer\n","ax.plot(label='Shuffled tokens')\n","ax.plot(label='Real tokens')\n","\n","ax2 = ax.twinx()\n","a = 100*effectiveCompCount[:,1] /\n","b =\n","ax2.plot(a,linewidth=2,color=[.9,.7,.7])\n","ax2.plot(b,linewidth=2,color=[.7,.9,.7])\n","ax2.set(ylabel='% max dimensionality')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj28_part3b.png')\n","plt.show()"],"metadata":{"id":"vpOplVxoPKVE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"PtIoa3avDsrR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 4: Repeat with Pythia-2.8b**"],"metadata":{"id":"GwhrdMr0DsoQ"}},{"cell_type":"code","source":[],"metadata":{"id":"Wk2KST6QMsp6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 5: Repeat with html code**"],"metadata":{"id":"cBad1athDsOe"}},{"cell_type":"code","source":[],"metadata":{"id":"NB1xDNnU3Z7F"},"execution_count":null,"outputs":[]}]}