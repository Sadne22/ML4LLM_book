{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"L4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["|<h2>Book:</h2>|<h1><a href=\"https://open.substack.com/pub/mikexcohen/p/llm-breakdown-16-tokenization-words\" target=\"_blank\">50 ML projects to understand LLMs</a></h1>|\n","|-|:-:|\n","|<h2>Project:</h2>|<h1><b>[27] Impact of layer-specific noise and scaling</b></h1>|\n","|<h2>Author:<h2>|<h1>Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h1>|\n","\n","<br>\n","\n","<i>Using the code without reading the book may lead to confusion or errors.</i>"],"metadata":{"id":"py_eibYAH3Q-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OxmEbIoa-yv0"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","\n","from transformers import AutoModelForCausalLM, AutoTokenizer"]},{"cell_type":"code","source":[],"metadata":{"id":"R5SI-Iyy4dtm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### matplotlib adjustments (commented lines are for dark mode)\n","\n","# svg plots (higher-res)\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n","\n","plt.rcParams.update({\n","    # 'figure.facecolor': '#282a2c',\n","    # 'figure.edgecolor': '#282a2c',\n","    # 'axes.facecolor':   '#282a2c',\n","    # 'axes.edgecolor':   '#DDE2F4',\n","    # 'axes.labelcolor':  '#DDE2F4',\n","    # 'xtick.color':      '#DDE2F4',\n","    # 'ytick.color':      '#DDE2F4',\n","    # 'text.color':       '#DDE2F4',\n","    'axes.spines.right': False,\n","    'axes.spines.top':   False,\n","    'axes.titleweight': 'bold',\n","    'axes.labelweight': 'bold',\n","    'savefig.dpi':300\n","})"],"metadata":{"id":"dy4A-ah8kzZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Z5tNq57P0eBn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 1: Model, tokens, and clean activations**"],"metadata":{"id":"6c5Ox7bF8QfB"}},{"cell_type":"code","source":["# load in GPT2-large and its tokenizer\n","tokenizer = AutoTokenizer.from_pretrained('gpt2')\n","model = AutoModelForCausalLM.from_pretrained('gpt2-large',output_hidden_states=True)\n","model.eval()"],"metadata":{"id":"mkIgNVHF0eR6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# move to the gpu\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device);"],"metadata":{"id":"hgAfdi936S12"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'This LLM has {} transformer layers.')"],"metadata":{"id":"fJfyguGUoObZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text = 'Pay no attention to that man behind the'\n","tokens =\n","target_token =\n","\n","for t in tokens[0]:\n","  print"],"metadata":{"id":"0i2FPAc10ePQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with torch.no_grad(): # ~8s on CPU, <1s on GPU\n","  outputs_clean = model(tokens\n","\n","outputs_clean.hidden_states[0].shape"],"metadata":{"id":"r4A3Q27t12aM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# log softmax\n","logsm =\n","log_sm_target_clean =\n","\n","nextword_clean = torch.argmax\n","print(f'Next word is \"{}\" (token index {}) with {} probability.')"],"metadata":{"id":"7HKZ8kxI12Vy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10,3))\n","\n","plt.axhline(,color='g',linestyle='--',linewidth=.5)\n","plt.axvline(,color='g',linestyle='--',linewidth=.5)\n","\n","plt.plot(,'kh',markerfacecolor=[.7,.9,.7,.3],markersize=4)\n","plt.gca().set(xlabel='Token index',ylabel='log-softmax prob',\n","              title='log-softmax of final token',xlim=[-150,tokenizer.vocab_size+150])\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj27_part1.png')\n","plt.show()"],"metadata":{"id":"RG6AHWC5BrI4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YJI8pgt512Rg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 2: Hook to inject noise**"],"metadata":{"id":"QzahTS938fuu"}},{"cell_type":"code","source":["# hooking functions\n","def implant_noise_hook(layer_number):\n","  def noise_hook(module,input,output):\n","\n","    # only change one layer\n","    if layer_number == layer2noise:\n","\n","      # unpack tuple\n","      hidden, *rest = output\n","\n","      # generate a matrix of noise\n","      h_std =\n","      noise =\n","\n","      # add that noise to the hidden states\n","      hidden +=\n","      # print(f'Changed layer {layer_number} with noise')\n","\n","      # reconstruct output\n","      output = tuple([hidden]+rest)\n","\n","    return output\n","  return noise_hook\n","\n","\n","# loop over layers and do surgery\n","handles = []\n","for layeri in range(model.config.n_layer):\n","  baselayer =\n","  h = baselayer.register_forward_hook(implant_noise_hook(layeri))\n","  handles.append(h)"],"metadata":{"id":"Yq7invM00eMh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test with one layer\n","layer2noise = 15\n","\n","with torch.no_grad():\n","  outputs_noise = model(tokens.to(device))\n","\n","outputs_noise.hidden_states[0].shape"],"metadata":{"id":"aTIRXQu80eHB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# initialize\n","diffnorms = torch.zeros()\n","\n","# loop over layers\n","for layeri in range():\n","\n","  # extract hidden states for this layer\n","  hs_c = outputs_clean.\n","  hs_n = outputs_noise.\n","\n","  # norm of difference matrix\n","  diffnorms[layeri] =\n","\n","# and plot\n","plt.figure(figsize=(10,3))\n","plt.plot(diffnorms,'kh',markerfacecolor=[.9,.7,.7],markersize=12)\n","plt.axvline(layer2noise+1,color='k',linestyle='--',zorder=-10)\n","plt.axhline(0,color='k',linestyle=':',zorder=-10)\n","plt.gca().set(xlabel='Layer',ylabel='Norm of difference')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj27_part2.png')\n","plt.show()"],"metadata":{"id":"k7zjkLxx88Jc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# predicted next token and its probability\n","max_logit = torch.argmax(\n","log_sm = outputs_noise.\n","\n","print(f' Clean model: next token is \"{}\" with {} probability.')\n","print(f'Noised model: next token is \"{}\" with {} probability.')"],"metadata":{"id":"7_malGNQ88G_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EDDgr__NDYo0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 3: Impacts of layer-specific noising**"],"metadata":{"id":"sLgHNpPS88Eh"}},{"cell_type":"code","source":["# initializations\n","log_sm_targets = torch.zeros((,))\n","\n","# loop over layers\n","for layer2noise in range():\n","\n","  # run the model\n","  with torch.no_grad():\n","    outputs_noise = model\n","\n","  # log-softmax the final token logits\n","  logsm = outputs_noise.logits...\n","\n","  # get the target (\" curtain\") value\n","  log_sm_targets[layer2noise,0] =\n","\n","  # get the max value\n","  maxtok = torch.argmax\n","  log_sm_targets[layer2noise,1] = logsm[\n","\n","  # print the completed text\n","  print(f'L{}: {}\"{}\"')"],"metadata":{"id":"7ayL72r7-Lsd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_,axs = plt.subplots(1,2,figsize=(12,3.5))\n","\n","# plot the impact of the perturbations\n","axs[0].axhline(,label='Clean')\n","axs[0].plot(,label='Noisified')\n","axs[0].legend()\n","axs[0].set(xlabel='Layer',ylabel='log-softmax prob',)\n","\n","# and the max logit\n","axs[1].axhline(,label='Clean')\n","axs[1].plot()\n","axs[1].set(xlabel='Layer',ylabel='log-softmax prob',ylim=axs[0].get_ylim(),)\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj27_part3.png')\n","plt.show()"],"metadata":{"id":"DIM5NyA0-Lpo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# remove handles\n","for h in handles:\n","  h.remove()"],"metadata":{"id":"E7YE5pEIBU4z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pBRUyjjF88B8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 4: Layer-specific scalar dampening**"],"metadata":{"id":"Bg7OfEQ20eJ-"}},{"cell_type":"code","source":["# hooking functions\n","def implant_scale_hook(layer_number):\n","  def scale_hook(module, input, output):\n","\n","    # only change one layer\n","    if layer_number == layer2scale:\n","\n","      # unpack tuple\n","\n","\n","      # in-place method to scale down the hidden states\n","\n","\n","      # reconstruct output\n","\n","\n","    return output\n","  return scale_hook\n","\n","\n","# loop over layers and do surgery\n","handles = []\n","for layeri in range(model.config.n_layer):\n","  baselayer = model.transformer.h[layeri]\n","  h = baselayer.\n","  handles.append(h)"],"metadata":{"id":"wmxYlUoREAh3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test with one layer\n","layer2scale = 15\n","\n","with torch.no_grad():\n","  outputs_scale = model(tokens.to(device))\n","\n","outputs_scale.hidden_states[0].shape"],"metadata":{"id":"RZGq28bcEAh4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# initialize\n","diffnorms = torch.zeros(model.config.n_layer)\n","\n","# loop over layers\n","for layeri in range(model.config.n_layer):\n","\n","  # extract hidden states for this layer\n","  hs_c =\n","  hs_n =\n","\n","  # norm of difference matrix\n","  diffnorms[layeri] =\n","\n","# and plot\n","plt.figure(figsize=(10,3))\n","plt.plot(diffnorms)\n","plt.gca().set(xlabel='Layer',ylabel='Norm of difference')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj27_part4a.png')\n","plt.show()"],"metadata":{"id":"uFkTnmdQEAh4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# initializations\n","log_sm_targets = torch.zeros((model.config.n_layer,2))\n","\n","# loop over layers\n","for layer2scale in\n","\n","  # run the model\n","\n","\n","  # log-softmax the final token logits\n","  logsm =\n","\n","  # get the target (\" curtain\") value\n","  log_sm_targets[layer2scale,0] =\n","\n","  # get the max value\n","  maxtok = torch.argmax\n","  log_sm_targets[layer2scale,1] =\n","\n","  # print the completed text\n","  print"],"metadata":{"id":"JGvKgKTPFPPT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_,axs = plt.subplots(1,2,figsize=(12,3.5))\n","\n","# plot the impact of the perturbations\n","axs[0].axhline(label='Clean')\n","axs[0].plot(label='Scaled')\n","axs[0].set(xlabel='Layer',ylabel='log-softmax prob',\n","              title=)\n","\n","# and the max logit\n","axs[1].axhline(label='Clean')\n","axs[1].plot(\n","axs[1].set(xlabel='Layer',ylabel='log-softmax prob',ylim=axs[0].get_ylim(),\n","              title='Impact of down-scaling on log-softmax of max logit')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj27_part4b.png')\n","plt.show()"],"metadata":{"id":"VVDHEiVAFPPU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WagH1MfBD5Eq"},"execution_count":null,"outputs":[]}]}