{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Book:</h2>|<h1><a href=\"https://open.substack.com/pub/mikexcohen/p/llm-breakdown-16-tokenization-words\" target=\"_blank\">50 ML projects to understand LLMs</a></h1>|\n","|-|:-:|\n","|<h2>Project:</h2>|<h1><b>[29] Hidden state dimensionality reduction</b></h1>|\n","|<h2>Author:<h2>|<h1>Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h1>|\n","\n","<br>\n","\n","<i>Using the code without reading the book may lead to confusion or errors.</i>"],"metadata":{"id":"py_eibYAH3Q-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OxmEbIoa-yv0"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","from matplotlib.gridspec import GridSpec\n","\n","# for part 1\n","from PIL import Image\n","import requests\n","from io import BytesIO\n","\n","import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer"]},{"cell_type":"code","source":["### matplotlib adjustments (commented lines are for dark mode)\n","\n","# svg plots (higher-res)\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n","\n","plt.rcParams.update({\n","    # 'figure.facecolor': '#282a2c',\n","    # 'figure.edgecolor': '#282a2c',\n","    # 'axes.facecolor':   '#282a2c',\n","    # 'axes.edgecolor':   '#DDE2F4',\n","    # 'axes.labelcolor':  '#DDE2F4',\n","    # 'xtick.color':      '#DDE2F4',\n","    # 'ytick.color':      '#DDE2F4',\n","    # 'text.color':       '#DDE2F4',\n","    'axes.spines.right': False,\n","    'axes.spines.top':   False,\n","    'axes.titleweight': 'bold',\n","    'axes.labelweight': 'bold',\n","    'savefig.dpi':300\n","})"],"metadata":{"id":"dy4A-ah8kzZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SDtqs90O2uGL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 1: Reducing dimensions while preserving shape**"],"metadata":{"id":"uZo9uw2k2uDm"}},{"cell_type":"code","source":["url = 'https://upload.wikimedia.org/wikipedia/commons/6/61/De_nieuwe_vleugel_van_het_Stedelijk_Museum_Amsterdam.jpg'\n","\n","response = requests.get(url,headers={'User-Agent':'Mozilla/5.0 (compatible; ImageLoader/1.0)'})\n","img = Image.open(BytesIO(response.content))\n","\n","# convert to grayscale and numpy\n","img = np.array( img.convert('L') ,dtype=float)\n","img = img[::2,::2] # downsample\n","\n","plt.imshow(img,cmap='gray')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj29_part1a.png')\n","plt.show()"],"metadata":{"id":"XBpS-8y8XXuN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SVD\n","U,s,Vh = np.linalg.svd(img)\n","\n","\n","# visualize\n","fig = plt.figure(figsize=(8,5))\n","gs = GridSpec(2,3,figure=fig)\n","ax1 = fig.add_subplot(gs[0,0])\n","ax2 = fig.add_subplot(gs[0,1])\n","ax3 = fig.add_subplot(gs[0,2])\n","ax4 = fig.add_subplot(gs[1,:])\n","\n","ax1.imshow(U,vmin=-.01,vmax=.01,cmap='plasma')\n","ax1.set(title='U')\n","\n","ax2.imshow(np.diag(s),vmin=0,vmax=200)\n","ax2.set(title='$\\\\mathbf{\\\\Sigma}$')\n","\n","ax3.imshow(Vh,vmin=-.01,vmax=.01,cmap='plasma')\n","ax3.set(title='V$^{\\\\top}$')\n","\n","ax4.plot(s,'ks-',markerfacecolor=[.9,.7,.7],markersize=8)\n","ax4.set(xlabel='Singular values (index)',ylabel='$\\\\sigma$')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj29_part1b.png')\n","plt.show()"],"metadata":{"id":"KhH5EJGkXRCW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# convert to cumulative percent\n","pct = 100*s**2/np.sum(s**2)\n","cum_pct = np.cumsum(pct)\n","\n","\n","# components to keep\n","comps2keep = 50\n","S = np.zeros_like(img)\n","for i in range(comps2keep):\n","  S[i,i] = s[i]\n","\n","# reconstruct the matrix\n","recon_img1 = U@S@Vh\n","\n","\n","_,axs = plt.subplots(1,2,figsize=(10,4))\n","axs[0].imshow(img,cmap='gray')\n","axs[0].set(title='Original image')\n","\n","axs[1].imshow(recon_img1,cmap='gray')\n","axs[1].set(title=f'Recon. with {comps2keep}/{len(s)} components ({cum_pct[comps2keep]:.2f}% var.)')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj29_part1c.png')\n","plt.show()"],"metadata":{"id":"HVtHdoOTXQ_p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# percent variance to keep\n","thresh = 98\n","r = np.where(cum_pct>thresh)[0][0]\n","\n","# loopless method\n","S = np.zeros_like(img)\n","S[:r,:r] = np.diag(s[:r])\n","\n","# reconstruction\n","recon_img2 = U@S@Vh\n","\n","_,axs = plt.subplots(1,2,figsize=(10,4))\n","axs[0].imshow(img,cmap='gray')\n","axs[0].set(title='Original image')\n","\n","axs[1].imshow(recon_img2,cmap='gray')\n","axs[1].set(title=f'Recon. with {cum_pct[r]:.2f}% variance ({r} comps)')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj29_part1d.png')\n","plt.show()"],"metadata":{"id":"Z4nT5KukK-Ue"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'Rank of original matrix: {np.linalg.matrix_rank(img)}')\n","print(f'Rank of r = 50 matrix  : {np.linalg.matrix_rank(recon_img1)}')\n","print(f'Rank of p = {thresh}% matrix : {np.linalg.matrix_rank(recon_img2)}')"],"metadata":{"id":"88WshUEJmJ5Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YT0IIHRBXQ82"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 2: Dimension-reduce one hidden state**"],"metadata":{"id":"oICIB_qrm7Tj"}},{"cell_type":"code","source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"eWIcSqqFxsnQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Eleuther's tokenizer\n","tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-1.3b')\n","model = AutoModelForCausalLM.from_pretrained('EleutherAI/gpt-neo-1.3b') # can use '125m' instead of '1.3b'\n","model.eval()\n","model.to(device)"],"metadata":{"id":"Fs5uYfMAOeL3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://en.wikipedia.org/wiki/Stedelijk_Museum_Amsterdam\n","\n","text = 'The Stedelijk Museum Amsterdam (Dutch pronunciation: [ˈsteːdələk myˈzeːjʏm ˌɑmstərˈdɑm]; Municipal Museum Amsterdam), colloquially known as the Stedelijk, is a museum for modern art, contemporary art, and design located in Amsterdam, Netherlands.[6] The 19th-century building was designed by Adriaan Willem Weissman. The connecting 21st-century wing, which houses the current entrance, was designed by Benthem Crouwel Architects. The museum is located at the Museum Square in the borough Amsterdam South,[2] where it is close to the Van Gogh Museum, the Rijksmuseum, and the Concertgebouw.'\n","tokens = tokenizer.encode(text,return_tensors='pt').to(device)\n","\n","# clean run\n","layer2reduce = 4000\n","with torch.no_grad():\n","  outs_clean = model(tokens,output_hidden_states=True)\n","\n","outs_clean.hidden_states[0].shape"],"metadata":{"id":"TkK_ucIUnBmG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hs = outs_clean.hidden_states[4][0,:,:].cpu()\n","\n","# SVD of mean-centered data\n","vectmeans0 = hs.mean(dim=0,keepdims=True)\n","vectmeans1 = hs.mean(dim=1,keepdims=True)\n","globalmean = hs.mean()\n","hs_demean = hs - vectmeans0 - vectmeans1 + globalmean\n","U,s,Vh = torch.linalg.svd(hs_demean)\n","\n","fig = plt.figure(figsize=(8,5))\n","gs = GridSpec(2,3,figure=fig)\n","ax1 = fig.add_subplot(gs[0,0])\n","ax2 = fig.add_subplot(gs[0,1])\n","ax3 = fig.add_subplot(gs[0,2])\n","ax4 = fig.add_subplot(gs[1,:])\n","\n","ax1.imshow(U,vmin=-.1,vmax=.1,cmap='plasma')\n","ax1.set(title='U')\n","\n","ax2.imshow(torch.diag(s),vmin=0,vmax=100)\n","ax2.set(title='$\\\\mathbf{\\\\Sigma}$')\n","\n","ax3.imshow(Vh,vmin=-.01,vmax=.01,cmap='plasma')\n","ax3.set(title='V$^{\\\\top}$')\n","\n","ax4.plot(s,'ks-',markerfacecolor=[.9,.7,.7],markersize=8)\n","ax4.set(xlabel='Singular values (index)',ylabel='$\\\\sigma$')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj29_part2a.png')\n","plt.show()"],"metadata":{"id":"cjlmdGMZnROw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# reduction threshold\n","svd_thresh = 95\n","\n","# find number of components to threshold\n","cum_pct = torch.cumsum(100*s**2/torch.sum(s**2),dim=-1)\n","r = torch.where(cum_pct>svd_thresh)[0][0]\n","\n","# create a new Sigma matrix\n","S = torch.zeros(hs.shape)\n","S[:r,:r] = torch.diag(s[:r])\n","\n","# reconstruct data (with means added back)\n","hs_R = U@S@Vh + vectmeans0 + vectmeans1 - globalmean\n","\n","print('hidden state shape:\\n ',hs.shape,'\\n')\n","print('reconstruction shape:\\n ',hs_R.shape)"],"metadata":{"id":"S7VF8nZPRiT7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualize\n","_,axs = plt.subplots(2,2,figsize=(12,8))\n","\n","axs[0,0].imshow(hs,aspect='auto',vmin=-2,vmax=2,cmap='rainbow')\n","axs[0,0].set(xlabel='Embeddings indices',ylabel='Token position',title='Original HS')\n","\n","axs[0,1].imshow(hs_R,aspect='auto',vmin=-2,vmax=2,cmap='rainbow')\n","axs[0,1].set(xlabel='Embeddings indices',ylabel='Token position',title=f'Reconstruction (r={r}, {svd_thresh}% var.)')\n","\n","axs[1,0].imshow(hs-hs_R,aspect='auto',vmin=-2,vmax=2,cmap='rainbow')\n","axs[1,0].set(xlabel='Embeddings indices',ylabel='Token position',title='Difference')\n","\n","axs[1,1].plot(hs.flatten()[::10],hs_R.flatten()[::10],'ko',markersize=8,markerfacecolor=[.7,.9,.7,.3])\n","axs[1,1].set(xlabel='Original HS',ylabel='Reconstructed HS',\n","              title=f'r = {np.corrcoef(hs.flatten(),hs_R.flatten())[0,1]:.5f}')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj29_part2b.png')\n","plt.show()"],"metadata":{"id":"jleYsO_CSXpQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'Rank of original hidden-state matrix: {torch.linalg.matrix_rank(hs)}')\n","print(f'Rank of reduced hidden-state matrix : {torch.linalg.matrix_rank(hs_R):3}')"],"metadata":{"id":"jm-TNePvptJJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"J3WPquFoUdV5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 3: A hook to reduce hidden state dimensionality**"],"metadata":{"id":"HEhcs2gVXQ6J"}},{"cell_type":"code","source":["svd_thresh = 99 # %\n","layer2reduce = 4\n","compsCount = []\n","\n","# hooking functions\n","def implant_hook(layer_number):\n","  def hook(module, input, output):\n","\n","    # only change one layer\n","    if layer_number == layer2reduce:\n","\n","      # unpack tuple\n","      hidden, *rest = output\n","\n","      # extract hidden state and numpyify\n","      hs = hidden[0,:,:].detach()\n","      vectmeans0 = hs.mean(dim=0,keepdims=True)\n","      vectmeans1 = hs.mean(dim=1,keepdims=True)\n","      globalmean = hs.mean()\n","      hs_demean = hs - vectmeans0 - vectmeans1 + globalmean\n","\n","      # SVD\n","      U,s,Vh = torch.linalg.svd(hs_demean)\n","\n","      # find number of components to threshold\n","      cum_pct = torch.cumsum(100*s**2/torch.sum(s**2),dim=-1)\n","      r = torch.where(cum_pct>svd_thresh)[0][0]\n","      compsCount.append(r.item()) # update count (back on the cpu)\n","\n","      # create a new Sigma matrix\n","      S = torch.zeros(hidden.shape[1:],device=hs.device)\n","      S[:r,:r] = torch.diag(s[:r])\n","\n","      # print some info\n","      print(f'Changed layer {layer_number:2} with {cum_pct[r]:.2f}% variance ({r:2}/{len(s)} comps)')\n","\n","      # reconstruct data (with means added back)\n","      hidden_copy = hidden.clone() # make a copy\n","      hidden_copy[0,:,:] = U@S@Vh + vectmeans0 + vectmeans1 - globalmean\n","      output = tuple([hidden_copy]+rest)\n","\n","    return output\n","  return hook\n","\n","\n","# loop over layers and do surgery\n","handles = []\n","for layeri in range(model.config.num_layers):\n","  baselayer = model.transformer.h[layeri]\n","  h = baselayer.register_forward_hook(implant_hook(layeri))\n","  handles.append(h)"],"metadata":{"id":"Ej8ms0j7XJmG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# with reduction\n","layer2reduce = 4\n","with torch.no_grad():\n","  outs_reduced = model(tokens,output_hidden_states=True)\n","\n","outs_reduced.hidden_states[0].shape"],"metadata":{"id":"tB09vlkrQH4K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# initialize\n","diffnorms = torch.zeros(model.config.num_layers)\n","\n","# loop over layers\n","for layeri in range(model.config.num_layers):\n","\n","  # extract hidden states for this layer\n","  hs_c = outs_clean.hidden_states[layeri+1]\n","  hs_n = outs_reduced.hidden_states[layeri+1]\n","\n","  # norm of difference matrix\n","  diffnorms[layeri] = torch.norm(hs_c-hs_n).cpu()\n","\n","# and plot\n","plt.figure(figsize=(10,3))\n","plt.plot(diffnorms,'kh',markerfacecolor=[.9,.7,.7],markersize=12)\n","plt.axvline(layer2reduce,color='k',linestyle='--',zorder=-3)\n","plt.axhline(0,color='k',linestyle=':',zorder=-10)\n","plt.gca().set(xlabel='Layer',ylabel='Norm of difference')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj29_part3.png')\n","plt.show()"],"metadata":{"id":"hq-C582yQH1Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Coj4sIAIr6-g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 4: Laminar-sweep reduction experiment**"],"metadata":{"id":"xiXsZR7ur67V"}},{"cell_type":"code","source":["# clean run (again)\n","layer2reduce = 4000\n","with torch.no_grad():\n","  outs_clean = model(tokens,output_hidden_states=True,labels=tokens)"],"metadata":{"id":"7JO-VgRCsl8E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# initializations\n","diffnorms = np.zeros((2,model.config.num_layers))\n","pertoken_diff = np.zeros((model.config.num_layers,tokens.shape[1]))\n","losses = np.zeros(model.config.num_layers)\n","\n","# threshold (was 99% in part 3)\n","svd_thresh = 95\n","\n","\n","# reset\n","compsCount = []\n","\n","logits_clean = outs_clean.logits[0].detach().cpu().numpy()\n","\n","# loop over layers\n","for layer2reduce in range(model.config.num_layers):\n","\n","  # run the model\n","  with torch.no_grad():\n","    outs_reduced = model(tokens,output_hidden_states=True,labels=tokens)\n","\n","  # extract hidden states for this layer\n","  hs_clean = outs_clean.hidden_states[layer2reduce+1].detach().cpu().numpy()\n","  hs_compr = outs_reduced.hidden_states[layer2reduce+1].detach().cpu().numpy()\n","\n","  # norm of hidden-state differences across the entire hidden state matrix\n","  diffnorms[0,layer2reduce] = np.linalg.norm(hs_clean-hs_compr)\n","\n","  # per-token difference analysis\n","  pertoken_diff[layer2reduce,:] = np.linalg.norm(hs_clean-hs_compr,axis=-1)\n","\n","  # norm of logit differences\n","  logits_compr = outs_reduced.logits[0].detach().cpu().numpy()\n","  diffnorms[1,layer2reduce] = np.linalg.norm(logits_compr-logits_clean)\n","\n","  # loss\n","  losses[layer2reduce] = outs_reduced.loss.item()\n"],"metadata":{"id":"yNfLfq7VQHvX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_,axs = plt.subplots(2,2,figsize=(10,6))\n","\n","# plot the impact of the perturbations\n","axs[0,0].plot(compsCount,'kh-',markerfacecolor=[.9,.7,.7],linewidth=.5,markersize=12,label='Noisified')\n","axs[0,0].set(xlabel='Layer',ylabel='Count',title=f'A) Components to achieve {svd_thresh}% variance')\n","\n","# and the max logit\n","axs[0,1].plot(diffnorms[0,:]/max(diffnorms[0,:]),'bs-',linewidth=.5,markerfacecolor=[.7,.7,.9,.7],markersize=12,label='Hidden states')\n","axs[0,1].plot(diffnorms[1,:]/max(diffnorms[1,:]),'ro-',linewidth=.5,markerfacecolor=[.9,.7,.7,.7],markersize=12,label='Logits')\n","axs[0,1].set(xlabel='Layer',ylabel='Diff norm (max-val scaled)',\n","              title='B) Impact on logits and hidden states')\n","axs[0,1].legend()\n","\n","axs[1,0].plot(losses,'kp-',linewidth=.5,markerfacecolor=[.7,.9,.7],markersize=12)\n","axs[1,0].set(xlabel='Layer',ylabel='Loss',title='C) Impact of reduction on loss')\n","\n","\n","\n","\n","# normalization function for mapping layer index onto color\n","norm = mpl.colors.Normalize(vmin=0,vmax=model.config.num_layers)\n","hs_dim = 100*np.array(compsCount)/min(hs_compr.shape[1:])\n","axs[1,1].scatter(hs_dim,losses,color=plt.cm.CMRmap(norm(np.arange(model.config.num_layers))),\n","                 alpha=.8,s=150,edgecolor='k')\n","\n","sm = mpl.cm.ScalarMappable(cmap=mpl.cm.CMRmap,norm=norm)\n","cbar = plt.colorbar(sm,ax=axs[1,1],pad=.02)\n","cbar.set_label(r'Hidden layer')\n","\n","\n","axs[1,1].set(ylabel='Loss',xlabel='Hidden state dimensionality (% total)',title='D) Reduction vs. loss')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj29_part4a.png')\n","plt.show()"],"metadata":{"id":"yPm1_zqCQHsj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(11,4))\n","\n","plt.imshow(pertoken_diff,aspect='auto',origin='lower',cmap='magma',vmin=20,vmax=120)\n","plt.gca().set(ylabel='Layer',xlabel='Token index',title='Impact of reduction on hidden states')\n","plt.colorbar(pad=.01)\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj29_part4b.png')\n","plt.show()"],"metadata":{"id":"aWwRV-j4Us82"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"L3mr7zjE9Ow1"},"execution_count":null,"outputs":[]}]}