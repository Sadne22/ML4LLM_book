{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Book:</h2>|<h1>50 ML projects to understand LLMs</h1>|\n","|-|:-:|\n","|<h2>Project:</h2>|<h1><b>[24] Cosine similarities within and across layers</b></h1>|\n","|<h2>Author:<h2>|<h1>Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h1>|\n","\n","<br>\n","\n","<i>Using the code without reading the book may lead to confusion or errors.</i>"],"metadata":{"id":"py_eibYAH3Q-"}},{"cell_type":"code","source":[],"metadata":{"id":"R5SI-Iyy4dtm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","\n","import requests\n","\n","import torch\n","import torch.nn.functional as F\n","\n","from transformers import AutoModelForCausalLM, AutoTokenizer"],"metadata":{"id":"rn8Fcyf87EXx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### matplotlib adjustments (commented lines are for dark mode)\n","\n","# svg plots (higher-res)\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n","\n","plt.rcParams.update({\n","    # 'figure.facecolor': '#282a2c',\n","    # 'figure.edgecolor': '#282a2c',\n","    # 'axes.facecolor':   '#282a2c',\n","    # 'axes.edgecolor':   '#DDE2F4',\n","    # 'axes.labelcolor':  '#DDE2F4',\n","    # 'xtick.color':      '#DDE2F4',\n","    # 'ytick.color':      '#DDE2F4',\n","    # 'text.color':       '#DDE2F4',\n","    'axes.spines.right': False,\n","    'axes.spines.top':   False,\n","    'axes.titleweight': 'bold',\n","    'axes.labelweight': 'bold',\n","    'savefig.dpi':300\n","})"],"metadata":{"id":"dy4A-ah8kzZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZSBKncvnY1He"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 1: Extract hidden states**"],"metadata":{"id":"YxeqcdQ3uf6E"}},{"cell_type":"code","source":["# GPT2 model and its tokenizer\n","model = AutoModelForCausalLM.from_pretrained('gpt2-medium')\n","tokenizer = AutoTokenizer.from_pretrained('gpt2')\n","\n","# toggle model into \"evaluation\" mode\n","model.eval()"],"metadata":{"id":"GVzKcCtLnuAr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.config"],"metadata":{"id":"_4CEqBgdPXdP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# some tokens\n","txt = 'A wise man once said: Penguins are cute.'\n","tokens = tokenizer(txt,return_tensors='pt')\n","num_tokens = len(tokens['input_ids'][0])\n","\n","for key,item in tokens.items():\n","  print(f'\"{key}\" contains:\\n  {item}\\n')"],"metadata":{"id":"-oZjkaVSMEWj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# forward pass and inspect output sizes\n","with torch.no_grad():\n","  outputs = model(**tokens,output_hidden_states=True)\n","\n","print('Keys in \"outputs\":\\n  ',outputs.keys())\n","print('\\nSize of outputs.logits:\\n  ',outputs.logits.shape)\n","print('\\nNumber of hidden states:\\n  ',len(outputs.hidden_states))\n","print('\\nSize of each hidden state:\\n  ',outputs.hidden_states[0].shape)"],"metadata":{"id":"1WsYQW-cMETx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cmeLnjGEUoHF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 2: Inspect hidden states**"],"metadata":{"id":"QJcldlw6UoCD"}},{"cell_type":"code","source":["# some convenience variables\n","hs = outputs.hidden_states\n","num_hidden = len(hs)\n","hidden_dim = model.config.n_embd"],"metadata":{"id":"oqc8TU0IPRvw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# all hidden-states for one token\n","whichToken = 8\n","\n","# initialize stdev matrix\n","token_stds = torch.zeros((num_hidden,num_tokens))\n","\n","# setup the figure\n","_,axs = plt.subplots(1,3,figsize=(12,3.5))\n","\n","# loop over layers\n","for layeri in range(num_hidden):\n","\n","  # extract the activations from this layer and this token\n","  acts = hs[layeri][0,whichToken,:]\n","\n","  # plot all the activations\n","  axs[0].plot(np.random.normal(layeri,.05,hidden_dim),acts,'ko',markersize=8,\n","           markerfacecolor=plt.cm.plasma((layeri+1)/num_hidden),alpha=.4)\n","\n","  axs[1].plot(layeri,acts.mean(),'kh',markersize=12,\n","           markerfacecolor=plt.cm.plasma((layeri+1)/num_hidden))\n","\n","  # plot the variance of the activations\n","  axs[2].plot(layeri,acts.var(),'ks',markersize=12,\n","           markerfacecolor=plt.cm.plasma((layeri+1)/num_hidden))\n","\n","  # standard deviation for all tokens\n","  token_stds[layeri,:] = hs[layeri][0,:,:].std(dim=-1)\n","\n","# names of the layers, for the x-axis tick labels\n","layer_labels = ['Emb'] + [f'L{i}' for i in range(num_hidden-1)]\n","\n","# adjust the axes\n","axs[0].set(xticks=range(0,num_hidden,2),xticklabels=layer_labels[::2],xlabel='Hidden layer (model depth)',\n","           ylabel='Activation value',title=f'A) Hidden state activations for token \"{tokenizer.decode(tokens['input_ids'][0,whichToken])}\"')\n","\n","axs[1].set(xticks=range(1,num_hidden,2),xticklabels=layer_labels[1::2],xlabel='Hidden layer (model depth)',\n","           ylabel='Vector mean',title=f'B) Activation means for token \"{tokenizer.decode(tokens['input_ids'][0,whichToken])}\"')\n","\n","axs[2].set(xticks=range(1,num_hidden,2),xticklabels=layer_labels[1::2],xlabel='Hidden layer (model depth)',\n","           ylabel='Vector variance',title=f'C) Activation variances for token \"{tokenizer.decode(tokens['input_ids'][0,whichToken])}\"')\n","\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj24_part2a.png')\n","plt.show()"],"metadata":{"id":"uH8k2NSRMERN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(8,5))\n","plt.imshow(token_stds,aspect='auto',origin='lower',\n","           vmin=0,vmax=15,cmap='magma')\n","plt.gca().set(ylabel='Layer',xticks=range(num_tokens),title='Hidden-states variability',\n","              xticklabels=[tokenizer.decode(t) for t in tokens['input_ids'][0]],\n","              yticks=range(num_hidden),yticklabels=layer_labels)\n","ch = plt.colorbar(pad=.01)\n","ch.set_label('Standard deviation')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj24_part2b.png')\n","plt.show()"],"metadata":{"id":"BLupxrL9SATU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"TN_Lz89ySAMU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 3: Cosine similarities across layers**"],"metadata":{"id":"VWjFLXAB8hCl"}},{"cell_type":"code","source":["# pick 4 evenly spaced tokens including the first and final\n","tokens2analyze = np.linspace(0,len(tokens['input_ids'][0])-1,4,dtype=int)\n","\n","fig,axs = plt.subplots(1,4,layout='constrained',figsize=(12,3))\n","\n","cos_sims = []\n","\n","# loop over selected tokens\n","for toki in range(len(tokens2analyze)):\n","\n","  # extract the hidden-state activations from this token into a matrix\n","  all_hiddens = torch.zeros((num_hidden,hidden_dim))\n","  for layeri in range(num_hidden):\n","    all_hiddens[layeri,:] = hs[layeri][0,tokens2analyze[toki],:]\n","\n","  # and calculate the cosine similarity matrix on all pairs of layers\n","  M = F.cosine_similarity(all_hiddens.unsqueeze(0),all_hiddens.unsqueeze(1),dim=-1)\n","  cos_sims.append(M)\n","\n","  # show the matrix\n","  h = axs[toki].imshow(M,cmap='plasma',vmin=.8,vmax=1,origin='lower')\n","  axs[toki].set(xticks=range(0,num_hidden,3),yticks=range(1,num_hidden,3),\n","                title=f'CS matrix for \"{tokenizer.decode(tokens[\"input_ids\"][0,tokens2analyze[toki]])}\"')\n","\n","# adjustments\n","axs[0].set(xlabel='Hidden layer (model depth)',ylabel='Hidden layer (model depth)')\n","fig.colorbar(h,ax=axs[-1],label='Cosine similarity',pad=.02,shrink=.97)\n","\n","plt.savefig('ch5_proj24_part3a.png')\n","plt.show()"],"metadata":{"id":"KQB1b1rF42Zn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create a distance matrix\n","l = np.arange(num_hidden).reshape(1,-1)\n","D = abs(l.T-l)\n","\n","plt.imshow(D,origin='lower',cmap='magma')\n","plt.colorbar(pad=.02)\n","plt.gca().set(title='Inter-layer distances',ylabel='Layer index',xlabel='Layer index')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj24_part3b.png')\n","plt.show()"],"metadata":{"id":"hYUj7K7MHcGD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# show the relationships\n","_,axs = plt.subplots(1,4,figsize=(12,3))\n","\n","# non-redundant rows and columns\n","rows,cols = np.nonzero(np.triu(D,1))\n","\n","for toki in range(len(tokens2analyze)):\n","\n","  for i in range(num_hidden):\n","    x = D[rows[cols==i],cols[cols==i]]\n","    y = cos_sims[toki][rows[cols==i],cols[cols==i]]\n","    axs[toki].plot(x,y,'h',markeredgecolor='k',markeredgewidth=.3)\n","\n","  axs[toki].set(xlabel='Inter-layer distance',ylabel='Cosine similarity',\n","                title=f'\"{tokenizer.decode(tokens[\"input_ids\"][0,tokens2analyze[toki]])}\"')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj24_part3c.png')\n","plt.show()"],"metadata":{"id":"yRcNtPa6CsxT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"TWu-8oNlVMsg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 4: Cosine similarities across tokens**"],"metadata":{"id":"HIU37hKxVSeW"}},{"cell_type":"code","source":["# convert tokens into a list for axis labeling\n","toks_list = [tokenizer.decode(tokens['input_ids'][0,i]) for i in range(num_tokens)]\n","\n","# 4 evenly spaced layers\n","layers2analyze = np.linspace(0,num_hidden-1,4,dtype=int)\n","\n","fig,axs = plt.subplots(1,4, layout='constrained',figsize=(12,3))\n","\n","# loop over layers\n","for layeri in range(len(layers2analyze)):\n","\n","  # cosine similarity matrix over all token pairs for this layer\n","  cos_sim = F.cosine_similarity(hs[layers2analyze[layeri]][0,:,:].unsqueeze(0),\n","                                hs[layers2analyze[layeri]][0,:,:].unsqueeze(1),\n","                                dim=-1)\n","\n","  # show the matrix\n","  h = axs[layeri].imshow(cos_sim,cmap='plasma',vmin=.7,vmax=1,origin='lower')\n","  axs[layeri].set(xticks=range(num_tokens),yticks=range(num_tokens),yticklabels=toks_list,\n","                title=f'CS matrix for layer {layers2analyze[layeri]}')\n","  axs[layeri].set_xticklabels(toks_list,rotation=90)\n","\n","fig.colorbar(h,ax=axs[-1],label='Cosine similarity',pad=.02,shrink=.96)\n","\n","plt.savefig('ch5_proj24_part4a.png')\n","plt.show()"],"metadata":{"id":"FR6sHyIZ42VW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10,4))\n","\n","for layeri in range(num_hidden):\n","\n","  # similarities across all tokens, excluding the first\n","  cos_sim = F.cosine_similarity(hs[layeri][0,1:,:].unsqueeze(0),hs[layeri][0,1:,:].unsqueeze(1),dim=-1)\n","  unique_sim = torch.unique(torch.triu(cos_sim,1))[1:]\n","\n","  # and plot all the dots\n","  plt.plot(np.random.normal(layeri,.05,len(unique_sim)),unique_sim,'ko',markersize=8,\n","           markerfacecolor=plt.cm.plasma((layeri+1)/num_hidden),alpha=.4)\n","\n","# adjust the axis properties\n","plt.gca().set(xticks=range(num_hidden),xticklabels=layer_labels,\n","              xlabel='Hidden layer (model depth)',ylabel='Cosine similarity',\n","              title=f'Laminar profile of inter-token cosine similarities')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj24_part4b.png')\n","plt.show()"],"metadata":{"id":"fndflAQ_42R2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gtKt42hBffdo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 5: Descriptives in a larger dataset**"],"metadata":{"id":"0MR584kCRNep"}},{"cell_type":"code","source":["url = 'https://www.gutenberg.org/cache/epub/64317/pg64317.txt'\n","text = requests.get(url).text\n","tokens = np.array( tokenizer.encode(text) )\n","print(f'There are {len(tokens):,} tokens, {len(set(tokens))} of which are unique.')\n","\n","# get some data\n","batch = torch.zeros((2,model.config.n_ctx),dtype=torch.long)\n","batch[0,:] = torch.tensor(tokens[10000:10000+model.config.n_ctx])\n","batch[1,:] = torch.tensor(tokens[20000:20000+model.config.n_ctx])\n","\n","with torch.no_grad():\n","  outs = model(batch,output_hidden_states=True)\n","\n","# check the shape\n","outs.hidden_states[4].shape"],"metadata":{"id":"WktAeXXuWvTk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_,axs = plt.subplots(2,2,figsize=(10,5))\n","\n","# normalization function for mapping layer index onto color\n","norm = mpl.colors.Normalize(vmin=0,vmax=num_hidden)\n","\n","\n","for layeri in range(num_hidden):\n","\n","  # extract means and stdevs of hidden state vectors\n","  mAbs = abs(outs.hidden_states[layeri][:,1:,:]).mean(dim=-1).flatten()\n","  m = outs.hidden_states[layeri][:,1:,:].mean(dim=-1).flatten()\n","  s = outs.hidden_states[layeri][:,1:,:].std(dim=-1).flatten()\n","\n","  # plot the individual characteristics\n","  axs[0,0].plot(np.random.normal(layeri,.05,len(m)),m,'ko',markersize=3,alpha=.3,\n","                markeredgewidth=.4,markerfacecolor=plt.cm.rainbow(layeri/num_hidden))\n","  axs[0,1].plot(np.random.normal(layeri,.05,len(m)),mAbs,'ko',markersize=3,alpha=.3,\n","                markeredgewidth=.4,markerfacecolor=plt.cm.rainbow(layeri/num_hidden))\n","\n","  axs[1,0].plot(np.random.normal(layeri,.05,len(s)),s,'ks',markersize=3,alpha=.3,\n","              markeredgewidth=.4,markerfacecolor=plt.cm.rainbow(layeri/num_hidden))\n","\n","  # and their relationships\n","  axs[1,1].plot(m,s,'.',alpha=.3,markersize=3,color=mpl.cm.rainbow(norm(layeri)))\n","\n","\n","# final adjustments\n","axs[0,0].axhline(0,color='k',linestyle='--',linewidth=.8,zorder=-1000)\n","axs[0,0].set(xlabel='Hidden layer',ylabel='Arithmetic mean',title='A) Hidden-state arithmetic means')\n","axs[0,1].set(xlabel='Hidden layer',ylabel='L1 mean',title='B) Hidden-state L1 means')\n","axs[1,0].set(xlabel='Hidden layer',ylabel='Standard deviation',title='C) Vector stdevs')\n","axs[1,1].set(xlabel='Arithmetic mean',ylabel='Standard deviation',title='D) Relationships')\n","\n","\n","# add colorbars\n","sm = mpl.cm.ScalarMappable(cmap=mpl.cm.rainbow,norm=norm)\n","cbar = plt.colorbar(sm,ax=axs[1,1])\n","cbar.set_label('Hidden layer')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj24_part5.png')\n","plt.show()"],"metadata":{"id":"gaie3isuWvQQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mmhBYcbqfeS_"},"execution_count":null,"outputs":[]}]}