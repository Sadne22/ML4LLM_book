{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Book:</h2>|<h1><a href=\"https://open.substack.com/pub/mikexcohen/p/llm-breakdown-16-tokenization-words\" target=\"_blank\">50 ML projects to understand LLMs</a></h1>|\n","|-|:-:|\n","|<h2>Project:</h2>|<h1><b>[32] Patching hidden states in indirect object identification</b></h1>|\n","|<h2>Author:<h2>|<h1>Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h1>|\n","\n","<br>\n","\n","<i>Using the code without reading the book may lead to confusion or errors.</i>"],"metadata":{"id":"py_eibYAH3Q-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OxmEbIoa-yv0"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.gridspec import GridSpec\n","\n","from scipy.optimize import curve_fit\n","\n","from tqdm import tqdm\n","\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","import torch"]},{"cell_type":"code","source":["### matplotlib adjustments (commented lines are for dark mode)\n","\n","# svg plots (higher-res)\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n","\n","plt.rcParams.update({\n","    # 'figure.facecolor': '#282a2c',\n","    # 'figure.edgecolor': '#282a2c',\n","    # 'axes.facecolor':   '#282a2c',\n","    # 'axes.edgecolor':   '#DDE2F4',\n","    # 'axes.labelcolor':  '#DDE2F4',\n","    # 'xtick.color':      '#DDE2F4',\n","    # 'ytick.color':      '#DDE2F4',\n","    # 'text.color':       '#DDE2F4',\n","    'axes.spines.right': False,\n","    'axes.spines.top':   False,\n","    'axes.titleweight': 'bold',\n","    'axes.labelweight': 'bold',\n","    'savefig.dpi':300\n","})"],"metadata":{"id":"dy4A-ah8kzZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0JaacnaV4Bu6"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["# **Part 1: The IOI task**"],"metadata":{"id":"ny-nH3gniySB"}},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","model = GPT2LMHeadModel.from_pretrained('gpt2-xl').to(device)\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","\n","n_layers = model.config.n_layer\n","model.eval()"],"metadata":{"id":"pFyxDs3UaDiw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text_ME = 'When Mike and Emma went to the cafe, Mike gave a coffee to'\n","text_EM = 'When Mike and Emma went to the cafe, Emma gave a coffee to'\n","\n","target_M = tokenizer.\n","target_E = tokenizer.\n","\n","tokensME = tokenizer.\n","tokensEM = tokenizer."],"metadata":{"id":"iKaNCGyPunU1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with torch.no_grad():\n","  outME = model(\n","  outEM = model(\n","\n","hs_ME = outME.hidden_states\n","outME.keys(), outME.hidden_states[3].shape"],"metadata":{"id":"xjEr-A4M4i6I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# predicted next words\n","nextword_ME = torch.argmax(\n","nextword_EM = torch.argmax(\n","\n","print(f'{text_ME}\"{tokenizer.decode(nextword_ME)}\"')\n","print(f'{text_EM}\"{tokenizer.decode(nextword_EM)}\"')"],"metadata":{"id":"r03kmOx24l4T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["logits_ME = outME.logits\n","logits_EM =\n","\n","\n","# setup the figure\n","fig = plt.figure(figsize=(12,3))\n","gs = GridSpec(1,5,figure=fig)\n","ax1 = fig.add_subplot(gs[:2])\n","ax2 = fig.add_subplot(gs[2:4])\n","ax3 = fig.add_subplot(gs[-1])\n","\n","# plot log-sm from \"EM\" sentence\n","ax1.plot('go',label='\"Mike\"')\n","ax1.plot('rs',label='\"Emma\"')\n","ax1.plot(,'k.',alpha=.2)\n","ax1.legend(fontsize=8)\n","ax1.set(xlabel='Vocab index',ylabel='Logit value',\n","           title='A) '+text_EM[-21:]+'...',xlim=[-100,tokenizer.vocab_size+100])\n","\n","# plot log-sm from \"ME\" sentence\n","ax2.plot(,'go',label='\"Mike\"')\n","ax2.plot(,'rs',label='\"Emma\"')\n","ax2.plot(,'k.',alpha=.2)\n","ax2.legend(fontsize=8)\n","ax2.set(xlabel='Vocab index',ylabel='Logit value',\n","           xlim=[-100,tokenizer.vocab_size+100],title='B) '+text_ME[-21:]+'...')\n","\n","# how they relate to each other\n","ax3.plot(,,'k.',alpha=.3)\n","ax3.set(xlabel='ME logits',ylabel='EM logits',title='C) ME vs. EM')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj32_part1.png')\n","plt.show()"],"metadata":{"id":"hGp6mBtf4l0F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["IOI_score_ME = outME... - outME...\n","IOI_score_EM = outEM... - outEM...\n","\n","print(f'IOI score for text \"ME\": {IOI_score_ME:6.3f}')\n","print(f'IOI score for text \"EM\": {IOI_score_EM:6.3f}')"],"metadata":{"id":"kNJ73slf4lwz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LEfxuTOf4ltw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 2: IOI with hidden-state patching**"],"metadata":{"id":"zXg402tF67cr"}},{"cell_type":"code","source":["# pick one layer\n","layeri =\n","\n","# patch this layer\n","def hookfun(module, input, output):\n","  hs = output[0].clone() # make a copy\n","  hs[0,-1,:] =  # index +1!\n","  output = (hs,*output[1:])\n","  return output\n","\n","# implant the hook\n","handle = model.transformer.h[layeri].register_forward_hook(hookfun)\n","\n","# forward pass with hook\n","with torch.no_grad():\n","  outEM_patch = model(\n","\n","# remove the hook\n","handle.remove()\n","\n","# now for the IOI score test\n","IOI_score ="],"metadata":{"id":"vJiqOkhm74Xo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'  Clean IOI score: {IOI_score_EM:6.3f}')\n","print(f'Patched IOI score: {IOI_score:6.3f}')"],"metadata":{"id":"d6QvJCIZ74Us"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["logits_EM_patch = outEM_patch.\n","\n","# setup the figure\n","fig,axs = plt.subplots(1,3,figsize=(12,3))\n","\n","# plot log-sm from \"EM\" sentence from the clean model\n","axs[0].plot(,'k.',alpha=.2)\n","axs[0].plot(,'go',label='\"Mike\"')\n","axs[0].plot(,'rs',label='\"Emma\"')\n","axs[0].legend(fontsize=8)\n","axs[0].set(xlabel='Vocab index',ylabel='Logit value',\n","           title='A) Clean model',xlim=[-100,tokenizer.vocab_size+100])\n","\n","# plot log-sm from \"EM\" sentence from the patched model\n","axs[1].plot(,'k.',alpha=.2)\n","axs[1].plot(,'go',label='\"Mike\"')\n","axs[1].plot(,'rs',label='\"Emma\"')\n","axs[1].legend(fontsize=8)\n","axs[1].set(xlabel='Vocab index',ylabel='Logit value',\n","           title='B) Patched model',xlim=[-100,tokenizer.vocab_size+100])\n","\n","# impact of patching on all token probs\n","logits_diff =\n","axs[2].plot(,'k.',alpha=.3)\n","axs[2].plot(,'go',label='\"Mike\"')\n","axs[2].plot(label='\"Emma\"')\n","axs[2].legend(fontsize=8)\n","axs[2].set(xlabel='Vocab index',ylabel='<-- boost ---- suppress -->',ylim=[-6,6],\n","           title='C) Manipulation effect',xlim=[-100,tokenizer.vocab_size+100])\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj32_part2.png')\n","plt.show()"],"metadata":{"id":"UVgujgvZOaln"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bigFX = torch.topk(\n","for t in bigFX[1]:\n","  print(f'Î” (C-P) = {:6.3f} for \"{}\"')"],"metadata":{"id":"oYKuy3VkX7z3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"v-r5SKXe67WW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 3: IOI experiment over layers**"],"metadata":{"id":"5eMS9_iAjcje"}},{"cell_type":"code","source":["# initializations\n","confirmManipulation = np.zeros((n_layers,2))\n","IOI_scores = np.zeros(n_layers)\n","\n","# loop over layers\n","for layeri in tqdm(range(n_layers)):\n","\n","  # patch this layer\n","  def hookfun(module,input,output):\n","    hs = output[0].clone()\n","    hs[0,-1,:]\n","    output = (hs,*output[1:])\n","    return output\n","\n","  # implant the hook\n","  handle = model.transformer.h[layeri].register_forward_hook(hookfun)\n","\n","  # forward pass with hook\n","  with torch.no_grad():\n","    outEM = model\n","  hs_EM = outEM.hidden_states\n","\n","  # remove the hook\n","  handle.remove()\n","\n","  # confirmation: first element should be zero, second non-zero\n","  confirmManipulation[layeri,0] = torch.norm(\n","  confirmManipulation[layeri,1] = torch.norm(\n","\n","  # now for the IOI score\n","  IOI_scores[layeri] ="],"metadata":{"id":"giaEdthGum8d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sanity check :)\n","confirmManipulation"],"metadata":{"id":"IiJowgurc5lm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualization\n","plt.figure(figsize=(11,4))\n","\n","# plot the logit differences for the \"clean\" runs (no patching)\n","plt.axhline(label='Clean \"EM\"')\n","plt.axhline(label='Clean \"ME\"')\n","\n","# then for the experiment results\n","plt.plot(,'ko',markerfacecolor=[.9,.7,.9],markersize=10)\n","plt.plot(\n","\n","# the dividing line\n","plt.axhline(0,linestyle='--',color='gray',linewidth=.5)\n","plt.text(0,.1,'Prefer \"Mike\"',fontsize=12,va='bottom')\n","plt.text(0,-.1,'Prefer \"Emma\"',fontsize=12,va='top')\n","\n","plt.gca().set(xlabel='Transformer layer (index)',ylabel='IOI score',title='Laminar profile of patch manipulation')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj32_part3.png')\n","plt.show()"],"metadata":{"id":"vjZdxt4sa2jf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DTGyCtic4lq0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 4: Curve-fitting with scipy**"],"metadata":{"id":"qxCvzTB54i20"}},{"cell_type":"code","source":["# sigmoid function\n","def sigmoid_fun(x,A,x0,k,b):\n","  # params:\n","  #   A: maximum value\n","  #  x0: x-value of midpoint\n","  #   k: curve steepness\n","  #   b: minimum value\n","  return\n","\n","# create some data\n","x = np.linspace\n","y = sigmoid_fun\n","y += np.random.randn(len(x))\n","\n","# visualize them\n","plt.figure(figsize=(11,4))\n","plt.plot(x,y,'ko',markerfacecolor=[.9,.7,.9],markersize=10)\n","plt.gca().set(xlabel='x',ylabel='y',title='Simulated data')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj32_part4a.png')\n","plt.show()"],"metadata":{"id":"-D67zjhL4iw3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# initial parameter guesses [A, x0, k, b]\n","p0 = []\n","\n","# fit the sigmoid function to data\n","est_params,pcov =\n","\n","print('    Truth | Estim.')\n","print('---+------+--------')\n","print(f' A |  10  | {}')\n","print(f'x0 |   0  | {}')\n","print(f' k |   1  | {}')\n","print(f' b |   2  | {}')"],"metadata":{"id":"yTzfdj1O4its"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# high-res model predictions\n","yHat = sigmoid_fun\n","\n","# visualization\n","plt.figure(figsize=(11,4))\n","\n","plt.plot(x,y,'ko',markerfacecolor=[.9,.7,.9],markersize=10,label='Data')\n","plt.plot(label='Model')\n","plt.axvline(x=,color='m',linestyle='--',label='x0')\n","\n","plt.legend()\n","plt.gca().set(xlabel='x',ylabel='y',title=f'Sigmoid fit to data')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj32_part4b.png')\n","plt.show()"],"metadata":{"id":"g89WPdn18L6Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"P4Q_m73mOqRg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 5: Curve-fitting IOI scores**"],"metadata":{"id":"6J03ZXrJOqOl"}},{"cell_type":"code","source":["# remove the final score\n"],"metadata":{"id":"wGO0BywZncwN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### now for the real data\n","x = np.arange\n","\n","# initial parameter guess\n","p0 = []\n","\n","# fit function to data\n","est_params,pcov = curve_fit\n","\n","# high-res model predictions\n","yHat = sigmoid_fun("],"metadata":{"id":"UevBbNxbP-Hk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualization\n","plt.figure(figsize=(11,4))\n","\n","# plot the logit differences for the \"clean\" runs (no patching)\n","plt.axhline(IOI_score_EM.cpu(),color='b',label='Clean \"EM\"')\n","plt.axhline(IOI_score_ME.cpu(),color='r',label='Clean \"ME\"')\n","\n","# then for the experiment results\n","plt.plot(label='Experiment results')\n","\n","plt.plot(label='Model')\n","plt.axvline(x=,color='m',linestyle='--',label=f'x0 (L{est_params[1]})')\n","\n","# the dividing line\n","plt.axhline(0,linestyle='--',color='gray',linewidth=.5)\n","plt.text(0,.1,'Prefer \"Mike\"',fontsize=12,va='bottom')\n","plt.text(0,-.1,'Prefer \"Emma\"',fontsize=12,va='top')\n","\n","plt.gca().set(xlabel='Transformer layer (index)',ylabel='IOI score',title=f'Data and sigmoid fit')\n","\n","plt.tight_layout()\n","plt.savefig('ch5_proj32_part5.png')\n","plt.show()"],"metadata":{"id":"sba1iiRF4i0A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xk-sMP4JIAX3"},"execution_count":null,"outputs":[]}]}