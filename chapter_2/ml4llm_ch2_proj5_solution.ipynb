{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1VzcoQf-ibdxiWXJicQ6tYGckXhp5Teyz","timestamp":1761435301383}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Book:</h2>|<h1><a href=\"https://open.substack.com/pub/mikexcohen/p/llm-breakdown-16-tokenization-words\" target=\"_blank\">50 ML projects to understand LLMs</a></h1>|\n","|-|:-:|\n","|<h2>Project:</h2>|<h1><b>[5] Is tokenization compression?</b></h1>|\n","|<h2>Author:<h2>|<h1>Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h1>|\n","\n","<br>\n","\n","<i>Using the code without reading the book may lead to confusion or errors.</i>"],"metadata":{"id":"py_eibYAH3Q-"}},{"cell_type":"code","source":[],"metadata":{"id":"R5SI-Iyy4dtm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import requests"],"metadata":{"id":"rn8Fcyf87EXx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UGHCakBb7EUl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 1: Text compression in English books**"],"metadata":{"id":"-E2P_Se-7EYc"}},{"cell_type":"code","source":["# GPT2 tokenizer\n","from transformers import AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained('gpt2')"],"metadata":{"id":"wcRoGJQ5-Ytp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# all books have the same url format;\n","# they are unique by numerical code\n","baseurl = 'https://www.gutenberg.org/cache/epub/'\n","\n","bookurls = [\n","    # code       title\n","    ['84',    'Frankenstein'    ],\n","    ['64317', 'GreatGatsby'     ],\n","    ['11',    'AliceWonderland' ],\n","    ['1513',  'RomeoJuliet'     ],\n","    ['76',    'HuckFinn'        ],\n","    ['219',   'HeartDarkness'   ],\n","    ['2591',  'GrimmsTales'     ],\n","    ['2148',  'EdgarAllenPoe'   ],\n","    ['36',    'WarOfTheWorlds'  ],\n","    ['829',   'GulliversTravels']\n","]"],"metadata":{"id":"RhMT5o9ttAFC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('  Book title     |  Chars  |  Words  |  Tokens |  Compress')\n","print('-----------------+---------+---------+---------+-----------')\n","\n","compression = np.zeros((len(bookurls),2))\n","i = 0\n","\n","for code,title in bookurls:\n","\n","  # get the text\n","  fullurl = baseurl + code + '/pg' + code + '.txt'\n","  text = requests.get(fullurl).text\n","\n","  # counts\n","  num_chars  = len(text)\n","  num_words  = len(text.split())\n","  num_tokens = len(tokenizer.encode(text))\n","\n","  # compression ratios\n","  compression[i,0] = 100*num_tokens/num_chars\n","  compression[i,1] = 100*num_tokens/num_words\n","\n","  print(f'{title:16} | {num_chars:>7,d} | {num_words:>7,d} | {num_tokens:>7,d} | {compression[i,0]:>3.0f} / {compression[i,1]:>3.0f}')\n","  i += 1\n"],"metadata":{"id":"eEQYu1l_s-hM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3X9O1OMxs-aw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 2: Compression in websites**"],"metadata":{"id":"JZ5ArZWr7BJd"}},{"cell_type":"code","source":["weburls = [\n","    'https://python.org/',\n","    'https://pytorch.org/',\n","    'https://duckduckgo.com/',\n","    'https://sudoku.com/',\n","    'https://oreilly.com/',\n","    'https://visiteurope.com/en/',\n","    'https://sincxpress.com/',\n","    'https://openai.com/',\n","    'https://theuselessweb.com/',\n","    'https://maps.google.com/',\n","    'https://pigeonsarentreal.co.uk/',\n","]"],"metadata":{"id":"KOTAgq4PXMVc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["requests.get('https://python.org/').text"],"metadata":{"id":"DgEqX0-5_ZI3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NDHUlgFO_ZGH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('    Website      |  Chars  |  Bytes  |  Tokens |  Compression (%)')\n","print('-----------------+---------+---------+---------+-----------------')\n","\n","\n","compression = np.zeros((len(weburls),2))\n","urlnames = []\n","\n","for i,url in enumerate(weburls):\n","\n","  # get the text\n","  text = requests.get(url).text\n","\n","  # count characters, bytes, tokens\n","  num_chars  = len(text)\n","  num_bytes  = len(text.encode('utf-8'))\n","  num_tokens = len(tokenizer.encode(text))\n","\n","  # compression ratio\n","  compression[i,0] = 100*num_tokens/num_chars\n","  compression[i,1] = 100*num_tokens/num_bytes\n","\n","  # url name\n","  name = weburls[i][8:]\n","  urlnames.append(name[:name.index('.')])\n","\n","  print(f'{urlnames[i]:>16} | {num_chars:>7,d} | {num_bytes:>7,d} | {num_tokens:>7,d} |  {compression[i,0]:>3.2f} / {compression[i,1]:>3.2f}')\n"],"metadata":{"id":"hC7ZulNxRg5K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xka_woYEzcgR"},"execution_count":null,"outputs":[]}]}