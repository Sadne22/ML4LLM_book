{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1l5ikbX4s9fUwuFcCkMhHMsk6pXLaU_Yi","timestamp":1765837032825}],"private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Book:</h2>|<h1><a href=\"https://open.substack.com/pub/mikexcohen/p/llm-breakdown-16-tokenization-words\" target=\"_blank\">50 ML projects to understand LLMs</a></h1>|\n","|-|:-:|\n","|<h2>Project:</h2>|<h1><b>[42] MLP weights and activations characteristics</b></h1>|\n","|<h2>Author:<h2>|<h1>Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h1>|\n","\n","<br>\n","\n","<i>Using the code without reading the book may lead to confusion or errors.</i>"],"metadata":{"id":"py_eibYAH3Q-"}},{"cell_type":"code","source":[],"metadata":{"id":"R5SI-Iyy4dtm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from sklearn.manifold import TSNE\n","\n","import torch\n","import torch.nn.functional as F\n","\n","from transformers import AutoModelForCausalLM, AutoTokenizer"],"metadata":{"id":"rn8Fcyf87EXx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### matplotlib adjustments (commented lines are for dark mode)\n","\n","# svg plots (higher-res)\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n","\n","plt.rcParams.update({\n","    # 'figure.facecolor': '#282a2c',\n","    # 'figure.edgecolor': '#282a2c',\n","    # 'axes.facecolor':   '#282a2c',\n","    # 'axes.edgecolor':   '#DDE2F4',\n","    # 'axes.labelcolor':  '#DDE2F4',\n","    # 'xtick.color':      '#DDE2F4',\n","    # 'ytick.color':      '#DDE2F4',\n","    # 'text.color':       '#DDE2F4',\n","    'axes.spines.right': False,\n","    'axes.spines.top':   False,\n","    'axes.titleweight': 'bold',\n","    'axes.labelweight': 'bold',\n","    'savefig.dpi':300\n","})"],"metadata":{"id":"dy4A-ah8kzZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OntBWCSZ02oT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Demo: GELU nonlinear activation function**"],"metadata":{"id":"2SADet-1UGya"}},{"cell_type":"code","source":["# simulate activation values\n","activations = torch.linspace(-4,4,51)\n","\n","# nonlinear transformation\n","gelued = F.gelu(activations)\n","\n","# calculate the change\n","diff = (activations-gelued)**2\n","\n","# and plot\n","plt.figure(figsize=(10,5))\n","plt.plot(activations,activations,'k')\n","h = plt.scatter(activations,gelued,60,marker='h',edgecolor='k',alpha=.7,\n","                c=diff,cmap='magma',vmin=0,vmax=10)\n","plt.colorbar(h,pad=.01)\n","plt.grid(linestyle='--',linewidth=.4)\n","plt.gca().set(xlabel='\"Raw\" activations',ylabel='Post-GELU activations',\n","              title='Impact of GELU nonlinear activation')\n","\n","plt.tight_layout()\n","plt.savefig('ch7_proj42_part0a.png')\n","plt.show()\n"],"metadata":{"id":"RcjDK5IwUGwA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nxqgPabM0FuN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RoNEIBjQ02rH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Demo: linear separation with dimensionality expansion**"],"metadata":{"id":"gh6JZcOUSiP-"}},{"cell_type":"code","source":["# angles\n","n = 100\n","theta = np.linspace(0,2*np.pi-1/n,n)\n","\n","# coordinates in 2D\n","x_inner = 1*np.cos(theta) + np.random.randn(n)/10\n","y_inner = 1*np.sin(theta) + np.random.randn(n)/10\n","x_outer = 2*np.cos(theta) + np.random.randn(n)/10\n","y_outer = 2*np.sin(theta) + np.random.randn(n)/10\n","\n","# dimensionality-expansion via nonlinear transform\n","z_inner = np.sqrt(x_inner**2 + y_inner**2)\n","z_outer = np.sqrt(x_outer**2 + y_outer**2)\n","\n","\n","\n","### 2D scatter plot\n","fig = plt.figure(figsize=(12,5))\n","ax0 = fig.add_subplot(121)\n","\n","ax0.plot(x_inner,y_inner,'ko',markerfacecolor=[.7,.9,.7],markersize=9)\n","ax0.plot(x_outer,y_outer,'ks',markerfacecolor=[.9,.7,.7],markersize=9)\n","ax0.axis('square')\n","ax0.set(title='A) Non-linearly separable in 2D',xlabel='x',ylabel='y',\n","        xticklabels=[],yticklabels=[])\n","\n","### 3D scatter plot\n","ax1 = fig.add_subplot(122, projection='3d')\n","ax1.plot(x_inner,y_inner,z_inner,'ko',markerfacecolor=[.7,.9,.7],markersize=9)\n","ax1.plot(x_outer,y_outer,z_outer,'ks',markerfacecolor=[.9,.7,.7],markersize=9)\n","ax1.set(title='B) Linearly separable in 3D',xlabel='x',ylabel='y',zlabel='Radius',\n","        xticklabels=[],yticklabels=[])\n","ax1.view_init(20,20)\n","\n","plt.savefig('ch7_proj42_part0b.png')\n","plt.show()"],"metadata":{"id":"zIWdbUyvOp-D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ftS1UXcpUG05"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 1: Distributions of MLP weights**"],"metadata":{"id":"Rn2mWJeUUuxD"}},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained('gpt2')\n","model = AutoModelForCausalLM.from_pretrained('gpt2')\n","model.eval()"],"metadata":{"id":"v-DJGMfhlIiu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_layers ="],"metadata":{"id":"2_w45RdYporn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# extract the weights matrices\n","W1 = model.transformer.h[5].mlp.\n","W2 = model.transformer.h[5].mlp.\n","\n","# extract the bias vectors\n","b1 = model.transformer.h[5].mlp.\n","b2 = model.transformer.h[5].mlp.\n","\n","# counts\n","W1_n = W1.numel()\n","W2_n =\n","b1_n =\n","b2_n =\n","\n","total_n =\n","\n","print(' Type |     Size     |   Count   | % total')\n","print('------+--------------+-----------+---------')\n","print(f'  W1  |  {} | {W1_n:9,} | {}')\n","print(f'  b1  |  {} | {b1_n:9,} | {}')\n","print(f'  W2  |  {} | {W2_n:9,} | {}')\n","print(f'  b2  |  {} | {b2_n:9,} | {}')"],"metadata":{"id":"4jRTs-HTSIXf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# FYI, W1 and W2 are not inverses of each other\n","# their product is not the identity matrix\n","# (This figure is mentioned but not shown in the text.)\n","plt.imshow((W1@W2)**2,vmin=0,vmax=1) # squared to accentuate visualization\n","plt.show()"],"metadata":{"id":"wrsEqY93MuAr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["binedges = torch.linspace(-.8,.8,201)\n","y1,_ = torch.histogram(\n","y2,_ = torch.histogram(\n","\n","plt.figure(figsize=(8,3))\n","plt.plot(,label=r'$\\mathbf{W_1}$')\n","plt.plot(,label=r'$\\mathbf{W_2}$')\n","plt.legend()\n","\n","plt.gca().set(xlabel='Weight value',ylabel='Density',xlim=binedges[[0,-1]],ylim=[0,None])\n","\n","plt.tight_layout()\n","plt.savefig('ch7_proj42_part1a.png')\n","plt.show()"],"metadata":{"id":"gVFdRxs4SIRC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["weights_hists = torch.zeros((,,))\n","\n","for layeri in range(n_layers):\n","\n","  # get the matrices\n","  W1 = model.transformer.h\n","  W2 = model.transformer.h\n","\n","  # get and store the histograms\n","  weights_hists[0,layeri,:],_ =\n","  weights_hists[1,layeri,:],_ =\n","\n","\n","_,axs = plt.subplots(1,2,figsize=(10,3.5))\n","for i in range(2):\n","  axs[i].imshow()\n","\n","axs[0].set(xlabel='Weight value',ylabel='Layer',title='W1 (expansion)')\n","axs[1].set(xlabel='Weight value',ylabel='Layer',title='W2 (contraction)')\n","\n","plt.tight_layout()\n","plt.savefig('ch7_proj42_part1b.png')\n","plt.show()"],"metadata":{"id":"nuwNyCYSTpS_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DCOguHHNSIKA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 2: Hooks and single-layer activation distributions**"],"metadata":{"id":"DA3zcyDTHsH7"}},{"cell_type":"code","source":["# initialize the dictionary containing data\n","mlp_acts = {}\n","\n","# the hook function\n","def hook(module, input, output):\n","\n","  # calculate the MLP progression\n","  X1 = input[0]\n","  X2 = module.c_fc\n","  X3 = module.\n","  X4 = module.\n","\n","  # store the results\n","  mlp_acts['input'] =\n","  mlp_acts['expansion'] =\n","  mlp_acts['gelu'] =\n","  mlp_acts['projection'] =\n","\n","# implant the hook\n","handle = model.transformer.h[5].mlp.register_forward_hook(hook)"],"metadata":{"id":"-WRep4v2jqu4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text = 'Would you prefer a strawberry-flavored peanut or a peanut-flavored strawberry?'\n","tokens = tokenizer.encode(text,return_tensors='pt')\n","ntokens =\n","\n","# forward pass to trigger the hook\n","\n","\n","# remove the hook\n"],"metadata":{"id":"hVgUv_F8luyl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for key,val in mlp_acts.items():\n","  print(f'{list(val.shape)} in stage \"{key}\"')"],"metadata":{"id":"N-zIqJsmI2lZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# extract for convenience\n","ip = mlp_acts['input'].flatten()\n","ex = mlp_acts['\n","ge = mlp_acts\n","co = mlp_acts\n","\n","# redefine bin boundaries\n","binedges = torch.linspace(,,)\n","\n","# histograms\n","yIp,_ = torch.histogram(\n","yEx,_ = torch.histogram(\n","yGe,_ = torch.histogram(\n","yCo,_ = torch.histogram(\n","\n","# and plot\n","plt.figure(figsize=(7,4))\n","plt.plot(,label=f'Input (N = {len(ip):,})')\n","plt.plot(,label=f'Expansion (N = {len(ex):,})')\n","plt.plot(,label=f'GELU (N = {len(ge):,})')\n","plt.plot(,label=f'Projection (N = {len(co):,})')\n","plt.axvline(0,linestyle='--',color='k',linewidth=.5)\n","\n","plt.gca().set(xlabel='Activation value',ylabel='Density',xlim=binedges[[0,-1]],ylim=[0,None])\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.savefig('ch7_proj42_part2.png')\n","plt.show()"],"metadata":{"id":"Nze8b2U4mPzc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Qo5ioqi0Ve6w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 3: Distribution by token position**"],"metadata":{"id":"aIoUWzDWVeSW"}},{"cell_type":"code","source":["# initialize\n","token_hists = torch.zeros((4,ntokens,len(binedges)-1))\n","\n","# loop over layers\n","for i in range(ntokens):\n","  token_hists[0,i,:],_ = torch.histogram(mlp_acts['input'][,,],bins=binedges,density=True)\n","  token_hists[1,i,:],_ = torch.histogram(mlp_acts['expansion']\n","  token_hists[2,i,:],_ = torch.histogram(mlp_acts\n","  token_hists[3,i,:],_ =\n","\n","\n","_,axs = plt.subplots(1,4,figsize=(12,3.5))\n","for i in range(4):\n","  axs[i].imshow(,origin='lower',aspect='auto',cmap='magma',\n","              extent=[binedges[0],binedges[-1],0,ntokens-1],vmin=0,vmax=.5)\n","\n","axs[0].set(xlabel='Activation value',ylabel='Token position',title='A) Input')\n","axs[1].set(xlabel='Activation value',ylabel='Token position',title='B) Expansion')\n","axs[2].set(xlabel='Activation value',ylabel='Token position',title='C) GELU')\n","axs[3].set(xlabel='Activation value',ylabel='Token position',title='D) Projection')\n","\n","plt.tight_layout()\n","plt.savefig('ch7_proj42_part3.png')\n","plt.show()"],"metadata":{"id":"aMh4wQ5WObDI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-3xZYRvPlxac"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 4: Laminar profiles of MLP distributions**"],"metadata":{"id":"C-NRd_RAoE63"}},{"cell_type":"code","source":["# re-initialize\n","mlp_acts = {}\n","\n","def outerHook(layeri):\n","  def hook(module,input,output):\n","\n","    # calculate the MLP progression\n","    X1 = input[0]\n","    X2 = module.\n","    X3 =\n","\n","    # store the results\n","    mlp_acts[f'L{layeri}_input'] = X1.detach()\n","    mlp_acts[f'L{layeri}_expansion'] = X2.detach()\n","    mlp_acts[f'L{layeri}_gelu'] = X3.detach()\n","    mlp_acts[f'L{layeri}_projection'] =\n","\n","  return hook\n","\n","handles = []\n","for layeri in range(model.config.n_layer):\n","  modname = model.transformer.h[layeri].mlp\n","  h = modname.register_forward_hook(outerHook(layeri))\n","  handles.append(h)"],"metadata":{"id":"nUdvwlm2oGy3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# forward pass to trigger the hook\n","with torch.no_grad():\n","  model(tokens)\n","\n","# remove the hooks\n","for h in handles:\n","  h.remove()"],"metadata":{"id":"GMeoTRTDoE3U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for k,v in mlp_acts.items():\n","  print(f'{k:>15} has size {list(v.shape)}')"],"metadata":{"id":"hnsWJfsdfW1s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# initialize\n","input_hists = torch.zeros(())\n","expansion_hists = torch.zeros(())\n","gelu_hists = torch.zeros(())\n","projection_hists = torch.zeros(())\n","\n","# loop over layers\n","for i in range(n_layers):\n","  input_hists[i,:],_ = torch.histogram(mlp_acts[f'L{i}_input'][],bins=,density=)\n","  expansion_hists[i,:],_ = torch.histogram(mlp_acts[f'L{i}_expansion']\n","  gelu_hists[i,:],_ = torch.histogram(\n","  projection_hists[i,:],_ =\n","\n","\n","\n","\n","_,axs = plt.subplots(1,4,figsize=(12,3.5))\n","axs[0].imshow()\n","axs[1].imshow()\n","axs[2].imshow()\n","axs[3].imshow()\n","\n","axs[0].set(xlabel='Activation value',ylabel='Layer',title='A) Input')\n","axs[1].set(xlabel='Activation value',ylabel='Layer',title='B) Expansion')\n","axs[2].set(xlabel='Activation value',ylabel='Layer',title='C) GELU')\n","axs[3].set(xlabel='Activation value',ylabel='Layer',title='D) Projection')\n","\n","plt.tight_layout()\n","plt.savefig('ch7_proj42_part4.png')\n","plt.show()"],"metadata":{"id":"5ntys_1IoE0L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nvdI--fVzGsN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 5: Dimension-reduction with T-SNE**"],"metadata":{"id":"FZeSEEj8a5mu"}},{"cell_type":"code","source":["layeri = 10\n","parts = ['input','projection']\n","\n","# setup the figure\n","fig,axs = plt.subplots(1,3,figsize=(13,3.5))\n","\n","# loop over the two MLP parts\n","for parti,name in enumerate(parts):\n","\n","  # reduce to 2D with t-SNE\n","  tsne = TSNE(,\n","  tsne_result = tsne.fit_transform()\n","\n","  # draw the projections\n","  h = axs[parti].scatter(,,100,marker='h',edgecolor='k',\n","                  c=np.linspace(0,1,ntokens),cmap=plt.cm.plasma)\n","\n","  # label the tokens\n","  yoffset = .03 * np.diff(axs[parti].get_ylim()) # shift words up by x% of the y-axis\n","  for i in range(\n","    axs[parti].text(tsne_result[i,0],tsne_result[i,1]+yoffset,\n","                    tokenizer.decode(),ha='center',fontsize=9)\n","\n","  # finalize\n","  axs[parti].set(xlabel='TSNE dim 1',ylabel='TSNE dim 2',title=f'{')\n","  fig.colorbar(h,ax=axs[parti],pad=.02,label='Token index',ticks=[])\n","\n","\n","# create the scatter plot\n","# extract the data for convenience\n","inp = mlp_acts[f'L{layeri}_input']\n","con = mlp_acts[f'L{layeri}_projection']\n","\n","axs[2].plot(inp,con,'ko',markerfacecolor=[.7,.9,.9,.5])\n","axs[2].set(xlabel='Stage 1 (input)',ylabel='Stage 4 (projection)',title=f'C) Scatter plot (r = {})')\n","\n","plt.tight_layout()\n","plt.savefig('ch7_proj42_part5.png')\n","plt.show()"],"metadata":{"id":"8BHxhavtnt41"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2SqlhxkVa5QO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 6: Repeat in GPT-2-large**"],"metadata":{"id":"ClZ5JG_AYGGt"}},{"cell_type":"code","source":[],"metadata":{"id":"rlbYfueuYGEB"},"execution_count":null,"outputs":[]}]}