{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"167ENw4jid1g4t7B2QLNu5FTxWBQ1g5Zg","timestamp":1765857447854}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Book:</h2>|<h1><a href=\"https://open.substack.com/pub/mikexcohen/p/llm-breakdown-16-tokenization-words\" target=\"_blank\">50 ML projects to understand LLMs</a></h1>|\n","|-|:-:|\n","|<h2>Project:</h2>|<h1><b>[45] Minkowski distance, mutual information, and token positions</b></h1>|\n","|<h2>Author:<h2>|<h1>Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h1>|\n","\n","<br>\n","\n","<i>Using the code without reading the book may lead to confusion or errors.</i>"],"metadata":{"id":"8UrqMO28-9ZL"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","!pip install wikipedia\n","import wikipedia\n","\n","# stats library for kendall correlation (when one variable is ordinal [sorted categorical])\n","import scipy.stats as stats\n","\n","from sklearn.feature_selection import mutual_info_regression\n","from scipy.spatial.distance import minkowski\n","\n","import torch\n","from transformers import AutoModelForCausalLM,GPT2Tokenizer"],"metadata":{"id":"aoocnKDi-2RN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### matplotlib adjustments (commented lines are for dark mode)\n","\n","# svg plots (higher-res)\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n","\n","plt.rcParams.update({\n","    # 'figure.facecolor': '#282a2c',\n","    # 'figure.edgecolor': '#282a2c',\n","    # 'axes.facecolor':   '#282a2c',\n","    # 'axes.edgecolor':   '#DDE2F4',\n","    # 'axes.labelcolor':  '#DDE2F4',\n","    # 'xtick.color':      '#DDE2F4',\n","    # 'ytick.color':      '#DDE2F4',\n","    # 'text.color':       '#DDE2F4',\n","    'axes.spines.right': False,\n","    'axes.spines.top':   False,\n","    'axes.titleweight': 'bold',\n","    'axes.labelweight': 'bold',\n","    'savefig.dpi':300\n","})"],"metadata":{"id":"U9F0prqyUFcE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BJR9NR3dr4pZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 1: Minkowski distances**"],"metadata":{"id":"jRk-vTlUejMk"}},{"cell_type":"code","source":["# generate some data\n","x = np.random.(100)\n","y = np.random.(100)\n","\n","# implement the distance measure\n","for p in range(1,3):\n","\n","  # manual calculation\n","  mink_man =\n","\n","  # via scipy\n","  mink_sp =\n","\n","  # show their equivalence\n","  print(f'p = {p}:\\n manual: {mink_man:.3f}\\n  scipy: {mink_sp:.3f}\\n')"],"metadata":{"id":"9agUs2LUdzqZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AVqa-xVdYWB9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 2: Mutual information: manual and scikit-learn**"],"metadata":{"id":"rOZ0nnjLYWKY"}},{"cell_type":"code","source":["# the data\n","N = 347\n","x = np.random.uniform(low=,high=,size=)\n","y =  + np.random.normal\n","\n","\n","# 2D histogram\n","Z,xx,yy = np.histogram2d()\n","\n","_,axs = plt.subplots(1,2,figsize=(12,4))\n","axs[0].plot(x,y,'ko',markersize=8,markerfacecolor=[.7,.7,.9,.3])\n","axs[0].set(xlabel='x',ylabel='y',title='A) Full resolution data')\n","\n","h = axs[1].imshow()\n","axs[1].set(xlabel='x',ylabel='y',title='B) Discretized (binned) data')\n","axs[1].plot(x,y,'ko',markerfacecolor=[.7,.7,.9,.5],markersize=8)\n","plt.colorbar(h,ax=axs[1],pad=.01,label='Count')\n","plt.suptitle('Z,xx,yy = np.histogram2d(x,y,bins=8)', fontfamily='monospace')\n","\n","plt.tight_layout()\n","plt.savefig('ch7_proj45_part2a.png')\n","plt.show()"],"metadata":{"id":"v-t7ZBuQy3i9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["eps = 1e-13\n","\n","# joint entropy from proportion\n","p_Z = Z /\n","entropy_Z = -np.sum(  * np.log2() )\n","\n","# single-variable entropies\n","p_x = np.sum(p_Z, axis=)\n","entropy_x =\n","p_y =\n","entropy_y =\n","\n","# mutual information via direct translation of the formula\n","miMan =\n","\n","print(f'Mutual information (manual) : {miMan:.2f}')"],"metadata":{"id":"QN1ozFUwB3uR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# via scikit-learn's MI function optimized for continuous variables\n","miSk = mutual_info_regression(\n","print(f'Mutual information (scikit-learn): {miSk:.2f}')"],"metadata":{"id":"uy-y2hy9MdlJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# impact of discretization\n","\n","bincounts = np.arange(4,25)\n","mi_by_bincount = np.zeros(len(bincounts))\n","\n","for i in range(len(mi_by_bincount)):\n","\n","  Z,xx,yy = np.histogram2d(x,y,bins=\n","\n","  # proportion via sum-scaling\n","  p_Z =\n","  p_x =\n","  p_y =\n","\n","  # calculate entropy\n","  entropy_x = -np.sum( p_x * np.log2(\n","  entropy_y = -np.sum(\n","\n","  # MI as difference of entropies\n","  entropy_Z = -np.sum( p_Z * np.log2(p_Z+eps) )\n","  mi_by_bincount[i] =\n","\n","\n","plt.figure(figsize=(8,4))\n","plt.axhline(miSk,color='r',linestyle='--',linewidth=2,label='scikit-learn')\n","plt.plot(bincounts,mi_by_bincount,'kh',markersize=12,markerfacecolor=[.7,.7,.9],label='Manual')\n","plt.gca().set(xticks=bincounts[::2],xlabel='Number of bins',ylabel='Mutual information')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.savefig('ch7_proj45_part2b.png')\n","plt.show()"],"metadata":{"id":"XtIQJ72y0ADD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# correlation coefficient\n","np.corrcoef(x,y)"],"metadata":{"id":"jPwPl0OGsVOk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mxFTicu3dzvW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 3: Model, hooks, tokens, and activations**"],"metadata":{"id":"ZRyQ1mlor4mm"}},{"cell_type":"code","source":["# load pretrained GPT-2 model and tokenizer\n","gpt2 = AutoModelForCausalLM.from_pretrained('gpt2-large')\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2-large')\n","\n","# variable for the number of transformer layers\n","nLayers = len(gpt2.\n","\n","gpt2.eval()"],"metadata":{"id":"bHKfbxSx-B5Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# hook function to store attention and MLP projections (see also part5_neuron_hookVsHiddenStates.ipynb)\n","activations =\n","\n","def implant_hook_attn(layer_number):\n","  def hook(module, input, output):\n","    activations[f'att_{layer_number}'] =\n","  return hook\n","\n","# and mlp layers\n","def implant_hook_mlp(layer_number):\n","  def hook(module, input, output):\n","    activations[f'mlp_\n","  return hook\n","\n","# implant hooks\n","handles = []\n","for layeri in range(nLayers):\n","  h1 = gpt2.transformer.h[layeri]....(implant_hook_attn(layeri))\n","  h2 = gpt2.transformer.h[layeri]....(implant_hook_mlp(layeri))\n","\n","  handles.append(h1)\n","  handles.append(h2)"],"metadata":{"id":"KcOSag-kHWH-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MIpgFqvuHWFH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from https://en.wikipedia.org/wiki/Turkish_coffee\n","text = wikipedia.page('Turkish_coffee').content\n","tokens = tokenizer.encode(text,return_tensors='pt')\n","print(f'There are {} tokens, {} of which are unique.')"],"metadata":{"id":"N3e7r-C_lpC5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# find all the \"coffee\" target indices\n","target =\n","target_idxs =\n","\n","# just the first 10\n","n_targets =\n","target_idxs =\n","target_idxs"],"metadata":{"id":"NsXA8Z9g6ezn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# forward pass to get activations\n","with torch.no_grad():\n","  gpt2(tokens[,])"],"metadata":{"id":"hp-mwh6u--MZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for k,v in activations.items():\n","  print(f'{k} has shape {v.shape}')"],"metadata":{"id":"7m1kp-CvIUnx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"K-a-LsggLofq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 4: Relationships between distance measures**"],"metadata":{"id":"0PFIoJ0UbsnO"}},{"cell_type":"code","source":["distances = np.zeros((,,3))\n","tokdists = np.zeros((,))\n","\n","# double-loop over the word pairs\n","for toki in range(n_targets):\n","  for tokj in range(\n","\n","    # extract the data\n","    x = activations['mlp_3'][0,target_idxs[\n","    y = activations['mlp_3'\n","\n","    # pairwise distance measures\n","    distances[toki,tokj,0] = mutual_info_regression(\n","    distances[toki,tokj,1] = minkowski\n","    distances[toki,tokj,2] = minkowski\n","\n","    tokdists[toki,tokj] ="],"metadata":{"id":"prYk4R9QtWLL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# indices of nonzero values\n","triu_idx = np.triu_indices(n_targets,k=1)\n","\n","_,axs = plt.subplots(1,2,figsize=(10,3.5))\n","\n","# without normalization\n","axs[0].plot(distances[triu_idx[0],triu_idx[1],0],\n","            distances[,,],'ro',\n","            markerfacecolor=[.9,.7,.7,.7],markersize=8,label='MI vs. $L_1$')\n","axs[0].plot(,label='MI vs. $L_2$')\n","axs[0].plot(,label='$L_1$ vs. $L_2$')\n","\n","\n","# with normalization\n","mi = distances[triu_idx[0],triu_idx[1],0]\n","mi /= max(mi)\n","L1 =\n","L1\n","L2 =\n","L2\n","\n","axs[1].plot(,label='MI vs. $L_1$')\n","axs[1].plot(,label='MI vs. $L_2$')\n","axs[1].plot(,label='$L_1$ vs. $L_2$')\n","\n","axs[0].set(xlabel='Measure',ylabel='Measure',title='A) Non-normalized')\n","axs[1].set(xlabel='Measure (norm.)',ylabel='Measure (norm.)',title='B) Max-value normalized')\n","axs[0].legend()\n","axs[1].legend()\n","\n","plt.tight_layout()\n","plt.savefig('ch7_proj45_part4.png')\n","plt.show()"],"metadata":{"id":"nXSTA6Oh0uEL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qb5uADQn8X8U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 5: Projection distances by position distances**"],"metadata":{"id":"yWA55iXx8X5K"}},{"cell_type":"code","source":["fig,axs = plt.subplots(2,4,figsize=(11,5))\n","\n","metric_labels = [ 'Mut. Info','Mink. $L_1$','Mink. $L_2$' ]\n","\n","for disti in range(3):\n","\n","  # this distance measure\n","  D = distances[:,:,]\n","\n","  # show the distance heatmap\n","  h = .imshow(D,)\n","  .set(xlabel='Target token index',ylabel='Target token index',title=f'{\"ABC\"[disti]}) {metric_labels[disti]}')\n","  fig.colorbar(h,ax=axs[0,disti],pad=.02,fraction=.047)\n","\n","  # correlate vector distance with token distance\n","  r = stats.\n","\n","  # scatter plot\n","  .plot(,,'ks',markersize=6,markerfacecolor=[.7,.7,.9,.7])\n","  .set(xlabel='Position distance',ylabel=f'{metric_labels[disti]}',\n","            title=f\"{'EFG'[disti]}) $\\\\mathbf{{\\\\tau}}={r.statistic:.2f}\\\\; (p={r.pvalue:.3f})$\")\n","\n","\n","# inter-token position differences\n","h = .imshow(tokdists,origin='lower',aspect='auto',vmin=0,vmax=tokdists.max()*.8,cmap='magma')\n",".set(xlabel='Target token index',ylabel='Target token index',title=f'D) Position dists.')\n","fig.colorbar(h,ax=axs[0,3],pad=.02,fraction=.047)\n","axs[1,3].axis('off')\n","\n","plt.tight_layout()\n","plt.savefig('ch7_proj45_part5.png')\n","plt.show()"],"metadata":{"id":"A-6XsKSh6BdX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZLTgqkbuVIfL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 6: Laminar sweep of correlations**"],"metadata":{"id":"Q8awOQ9MVIcc"}},{"cell_type":"code","source":["summary_results = np.zeros((2,nLayers,2,3))\n","\n","# initialize temp matrices (overwritten in each layer)\n","dists_A = np.zeros((n_targets,n_targets,3)) # attention\n","dists_M =  # MLP\n","\n","\n","# loop over layers\n","for layeri in range(nLayers):\n","\n","  # double-loop over the word pairs\n","  for toki in range(\n","    for tokj in range(\n","\n","      ### ATTENTION block\n","      # extract the data\n","      x = activations[f'att_{layeri}'][0,target_idxs[toki],:]\n","      y = activations[f'att_{layeri}'][0,target_idxs[tokj],:]\n","\n","      # pairwise distance measures\n","      dists_A[toki,tokj,0] = mutual_info_regression\n","      dists_A[toki,tokj,1] = minkowski\n","      dists_A[toki,tokj,2] =\n","\n","\n","      ### MLP block\n","      # extract the data\n","      x =\n","      y =\n","\n","      # pairwise distance measures\n","      dists_M[toki,tokj,0] =\n","      dists_M[toki,tokj,1] =\n","      dists_M[toki,tokj,2] =\n","\n","\n","  # inter-token distances (doesn't change for attn-vs-mlp)\n","  uDi =\n","\n","  # loop over distance measures\n","  for i in range(3):\n","\n","    # ATTENTION summary statistics\n","    vals = dists_A[triu_idx[0],triu_idx[1],i]\n","    summary_results[0,layeri,0,i] =\n","    summary_results[0,layeri,1,i] =\n","\n","    # MLP summary statistics\n","    vals = dists_M[triu_idx[0],triu_idx[1],i]\n","    summary_results[1,layeri,0,i] =\n","    summary_results[1,layeri,1,i] ="],"metadata":{"id":"YqHor3r_--Jb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_,axs = plt.subplots(2,2,figsize=(12,6))\n","\n","c = 'rgb'\n","s = 'osh'\n","\n","for i in range(3):\n","\n","  # Attention\n","  d = summary_results[0,:,0,i]\n","  axs[0,0].plot(,label=metric_labels[i])\n","  axs[0,1].plot(,label=metric_labels[i])\n","\n","  # MLP\n","  d = summary_results[1,:,0,i]\n","  axs[1,0].plot(,label=metric_labels[i])\n","  axs[1,1].plot(,label=metric_labels[i])\n","  # note: flip the sign of MI by scaling summary_results by [-1,1,1][i]\n","  #       or just plot abs(summary_results)\n","\n","# horizontal line at r=0\n","axs[0,1].axhline(0,color='k',linestyle='--',linewidth=.3)\n","axs[1,1].axhline(0,color='k',linestyle='--',linewidth=.3)\n","\n","\n","# adjustments\n","for a in axs.flatten(): a.legend()\n","axs[0,0].set(xlabel='Transformer layer',ylabel='Mean distance (max-norm)',title='A) ATTENTION: Average distances')\n","axs[0,1].set(xlabel='Transformer layer',ylabel='Correlation coefficient',title='B) ATTENTION: Correlations with position')\n","axs[1,0].set(xlabel='Transformer layer',ylabel='Mean distance (max-norm)',title='C) MLP: Average distances')\n","axs[1,1].set(xlabel='Transformer layer',ylabel='Correlation coefficient',title='D) MLP: Correlations with position')\n","\n","\n","plt.tight_layout()\n","plt.savefig('ch7_proj45_part6.png')\n","plt.show()"],"metadata":{"id":"znjhxXn6-zYF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lseEMT5WlpLV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 7: A standard application of mutual information**"],"metadata":{"id":"oa2lh7HGlpIh"}},{"cell_type":"code","source":["# batch size parameters\n","n_sequences = 100\n","n_context = 9 # actually this + 1 b/c context is before target\n","\n","# get the target indices again\n","target_idxs =\n","\n","# remove any that are too early to have a full context\n","target_idxs = target_idxs[\n","\n","n_targets =\n","n_targets"],"metadata":{"id":"KxKvmh1HlpAF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch = torch.zeros((,),dtype=torch.long)\n","\n","for i in range(n_sequences):\n","  start = target_idxs[i]-n_context\n","  stop  =\n","  batch[i,:] = tokens\n","\n","batch"],"metadata":{"id":"lfv1HDlWlo9R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with torch.no_grad(): gpt2(batch)"],"metadata":{"id":"X_e5NRsHlo6d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for k,v in activations.items():\n","  print(f'key \"{k}\" has shape {v.shape}')"],"metadata":{"id":"vN6oGa0olo3h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mi = np.zeros((nLayers,nLayers,3))\n","\n","for i in range(nLayers):\n","  for j in range(i+1,nLayers):\n","\n","    # mutual information across attention projection vector norms\n","    normi = np.linalg.norm(activations[f'att_{i}'][,,],axis=)\n","    normj = np.linalg.norm(activations[f'att_{j}'\n","    mi[i,j,0] = mutual_info_regression(\n","\n","    # mutual information across MLP projection vector norms\n","    normi =\n","    normj =\n","    mi[i,j,1] =\n","\n","    # inter-layer distances\n","    mi[i,j,2] ="],"metadata":{"id":"6rf7uSFIlo0t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_,axs = plt.subplots(2,3,figsize=(12,7))\n","\n","# mutual information matrices\n","axs[0,0].imshow(,aspect='auto',vmin=0,vmax=.3,cmap='magma')\n","axs[0,1].imshow(,aspect='auto',vmin=0,vmax=.3,cmap='magma')\n","axs[0,2].imshow(,aspect='auto',cmap='magma')\n","\n","# scatter plots\n","axs[1,0].plot(mi[:,:,2][np.triu_indices_from(mi[:,:,2],k=1)],\n","              mi[:,:,0][np.triu_indices_from(mi[:,:,2],k=1)],'ro',markerfacecolor=[.9,.7,.7,.5])\n","axs[1,1].plot()\n","axs[1,2].plot()\n","\n","# plot adjustments\n","axs[0,0].set(xlabel='Layer index',ylabel='Layer index',title='A) Attention: Pairwise mutual info')\n","axs[0,1].set(xlabel='Layer index',ylabel='Layer index',title='B) MLP: Pairwise mutual info')\n","axs[0,2].set(xlabel='Layer index',ylabel='Layer index',title='C) Inter-layer distances')\n","\n","axs[1,0].set(xlabel='Inter-layer distance',ylabel='Mutual information',title='D) Attention: MI with distance')\n","axs[1,1].set(xlabel='Inter-layer distance',ylabel='Mutual information',title='E) MLP: MI with distance')\n","axs[1,2].set(xlabel='Attention mutual information',ylabel='MLP mutual information',title='F) MI: Attention vs. MLP')\n","\n","plt.tight_layout()\n","plt.savefig('ch7_proj45_part7.png')\n","plt.show()"],"metadata":{"id":"F7lb_xJlloyB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0RFWaprsSmz3"},"execution_count":null,"outputs":[]}]}