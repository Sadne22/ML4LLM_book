{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Book:</h2>|<h1><a href=\"https://open.substack.com/pub/mikexcohen/p/llm-breakdown-16-tokenization-words\" target=\"_blank\">50 ML projects to understand LLMs</a></h1>|\n","|-|:-:|\n","|<h2>Project:</h2>|<h1><b>[49] Successive median-replacement of MLP activations</b></h1>|\n","|<h2>Author:<h2>|<h1>Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h1>|\n","\n","<br>\n","\n","<i>Using the code without reading the book may lead to confusion or errors.</i>"],"metadata":{"id":"fXOrNMhxq2Ya"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5BvQj17hzqwM"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","\n","import torch\n","import torch.nn.functional as F\n","from transformers import AutoModelForCausalLM, AutoTokenizer"]},{"cell_type":"code","source":["### matplotlib adjustments (commented lines are for dark mode)\n","\n","# svg plots (higher-res)\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n","\n","plt.rcParams.update({\n","    # 'figure.facecolor': '#282a2c',\n","    # 'figure.edgecolor': '#282a2c',\n","    # 'axes.facecolor':   '#282a2c',\n","    # 'axes.edgecolor':   '#DDE2F4',\n","    # 'axes.labelcolor':  '#DDE2F4',\n","    # 'xtick.color':      '#DDE2F4',\n","    # 'ytick.color':      '#DDE2F4',\n","    # 'text.color':       '#DDE2F4',\n","    'axes.spines.right': False,\n","    'axes.spines.top':   False,\n","    'axes.titleweight': 'bold',\n","    'axes.labelweight': 'bold',\n","    'savefig.dpi':300\n","})"],"metadata":{"id":"BvREVw_VesPV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"saafwV3q9ocH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 1: Tokens and activations**"],"metadata":{"id":"CqifcaigyOOF"}},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = AutoModelForCausalLM.from_pretrained('gpt2-large').to(device)\n","tokenizer = AutoTokenizer.from_pretrained('gpt2-large')\n","model.eval()"],"metadata":{"id":"83A8PoVGRFj-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nlayers =\n","nneurons =\n","nneurons, nlayers"],"metadata":{"id":"UE9iGVUWGRQ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# dictionary to store the mlp activations\n","mlp_values = {}\n","\n","def hook(module,input,output):\n","  mlp_values[f'L{whichlayer}'] =\n","\n","# implantation surgery\n","whichlayer = 9\n","handle = model.transformer.h[whichlayer].mlp.c_fc.register_forward_hook(hook)"],"metadata":{"id":"pQ6zFv8PY4B4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text = 'It was a dark and stormy'\n","target_idx =\n","\n","tokens = tokenizer.\n","\n","tokens.shape, tokens, target_idx"],"metadata":{"id":"fYPkVigeOv47"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with torch.no_grad():\n","  out_clean = model()\n","handle.remove()\n","\n","# calculate softmax probability in percent\n","logsm_clean = F.log_softmax().detach().cpu().numpy()\n","\n","# check some sizes\n","print(f\"mlp_values['L9'] has shape {mlp_values['L9'].shape}\")\n","print(f'Output logits have shape {out_clean.logits.shape}')"],"metadata":{"id":"YAMzPriHL7SD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10,4))\n","\n","# all the log-sm values\n","plt.plot(logsm_clean,'k.',markersize=2,alpha=.3)\n","\n","# the target and nontarget values\n","plt.plot(,,'gs',label=tokenizer.decode(target_idx))\n","\n","# make the graph look pretty :D\n","plt.gca().set(xlabel='Vocab elements',ylabel='Log softmax',xlim=[0,model.config.vocab_size])\n","plt.title(f'Predicted next token is \"{}\"',fontweight='bold')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.savefig('ch7_proj49_part1.png')\n","plt.show()"],"metadata":{"id":"kac1tOloFKKd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CoOqL_1aOSkL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 2: Exploring median-based replacement**"],"metadata":{"id":"XM3vQP4sOShP"}},{"cell_type":"code","source":["# copy of the data to manipulate\n","acts_replace = .clone()\n","\n","# find the median and mean\n","med = torch.median()\n","mean = torch.\n","\n","# find the top 10% and replace with median\n","idx = torch.topk().indices\n","acts_replace[idx] = med\n","\n","# show the two histograms\n","plt.figure(figsize=(10,4))\n","binedges = np.linspace(-5,2,41)\n","\n","# pre-replace histogram\n","y,x = np.histogram(mlp_values[f'L{whichlayer}'][0,-1,:],binedges)\n","plt.plot(x[:-1]-.02,y,'gs-',linewidth=.5,markerfacecolor=[.7,.9,.7,.7],label='Original')\n","\n","# post-replace histogram\n","y,x = np.histogram(,)\n","plt.plot(,label='Replaced')\n","plt.axvline(med,linestyle='--',color='m',label='Median')\n","plt.axvline(mean,linestyle=':',color='k',label='Mean')\n","\n","\n","plt.gca().set(xlabel='Data value',ylabel='Count',xlim=binedges[[0,-1]],title='Impact of replacement')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.savefig('ch7_proj49_part2.png')\n","plt.show()"],"metadata":{"id":"U3qoh11mFKNq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dbO7kYSDFKHT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 3: Impact of replacement on hidden states and logits**"],"metadata":{"id":"MQEiF2fuUfLZ"}},{"cell_type":"code","source":["# this vector is used for the rest of the project\n","pcts_to_replace = np.linspace(\n","\n","# initialize results matrices\n","log_sm_targ_ex = np.zeros()\n","hs_diff_norms_ex = np.zeros((,))\n","\n","\n","for repli in range(\n","\n","\n","  ### ------ hook ------ ###\n","  def replace_hook(module,input,output):\n","\n","    # find the median\n","    vals = output[0,-1,:]\n","    med =\n","\n","    # replace top p% magnitude\n","    idx = torch.topk(\n","    output[0,-1,idx] = med\n","    return output\n","\n","  # put hooks in all layers\n","  handles = []\n","  for layeri in range(0,nlayers):\n","    h = model.transformer.h[layeri].mlp.)\n","    handles.append(h)\n","  ### ------ end of hook ------ ###\n","\n","\n","  # forward pass to get output logits, and remove hook\n","  with torch.no_grad():\n","    out = model(tokens,output_hidden_states=True)\n","  # remove hooks\n","\n","  # log-softmax of target\n","  log_sm_targ_ex[repli] = F.log_softmax()[target_idx]\n","\n","  # norm of hidden-states differences\n","  for i in range(nlayers+1):\n","    hs = out.hidden_states[i].cpu().squeeze()[,]\n","    hs_clean = out_clean.hidden_states\n","    hs_diff_norms_ex[repli,i] =\n"],"metadata":{"id":"hkqlnkhzbBg5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig,axs = plt.subplots(1,3,figsize=(12,3))\n","\n","# heatmap of hidden-states changes\n","h = axs[0].imshow()\n","fig.colorbar(h,ax=axs[0],pad=.01)\n","axs[0].set(xlabel='Hidden states layer',ylabel='Percent neurons replaced',title='A) Impact on hidden states')\n","\n","# accumulation of hidden-states impacts\n","axs[1].plot(np.mean(,axis=),'kh',markerfacecolor=[.7,.9,.7,.7],markersize=10)\n","axs[1].set(xlabel='Hidden state layer',ylabel='Vector norm difference',title='B) Averaging over replacement %')\n","\n","# impact on output logits (log-softmax-transformed)\n","axs[2].plot(,,'kh',markerfacecolor=[.7,.7,.9,.7],markersize=10)\n","axs[2].axhline(logsm_clean[target_idx],color='k',linestyle='--')\n","axs[2].set(xlabel='Percent neurons replaced',ylabel='Log softmax to target',title='C) Impact on output logits')\n","\n","plt.tight_layout()\n","plt.savefig('ch7_proj49_part3.png')\n","plt.show()"],"metadata":{"id":"-l3wNxBucG8t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"O840RHjdOrjU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 4: Comparison with post-GELU expansion**"],"metadata":{"id":"3LygETHk0Y59"}},{"cell_type":"code","source":["log_sm_targ_ge = np.zeros(len(pcts_to_replace))\n","hs_diff_norms_ge = np.zeros((len(pcts_to_replace),nlayers+1))\n","\n","\n","for repli in range(len(pcts_to_replace)):\n","\n","\n","  ### ------ hook ------ ###\n","  def replace_hook(module,input,output):\n","\n","    # find the median\n","    vals = output[0,-1,:]\n","    med =\n","\n","    # replace top p%\n","    idx =\n","    output[0,-1,idx] =\n","    return output\n","\n","  # put hooks in all layers\n","  handles = []\n","  for layeri in range(0,nlayers):\n","    h = model.transformer.h[layeri].\n","    handles.append(h)\n","  ### ------ end of hook ------ ###\n","\n","\n","  # forward pass to get output logits, and remove hook\n","  with torch.no_grad():\n","    out = model(tokens,output_hidden_states=True)\n","  for h in handles: h.remove()\n","\n","  # log-softmax of target\n","  log_sm_targ_ge[repli] = F.log_softmax(out.logits[0,-1,:].detach(),dim=-1)[target_idx]\n","\n","  # norm of hidden-states differences\n","  for i in range(nlayers+1):\n","    hs = out.hidden_states[i].cpu().squeeze()[-1,:]\n","    hs_clean = out_clean.hidden_states[i].cpu().squeeze()[-1,:]\n","    hs_diff_norms_ge[repli,i] = torch.norm(hs-hs_clean)\n"],"metadata":{"id":"FnzBRBR70Y23"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig,axs = plt.subplots(2,2,figsize=(10,6))\n","\n","h = axs[0,0].imshow()\n","fig.colorbar(h,ax=axs[0,0],pad=.01)\n","axs[0,0].set(xlabel='Hidden states layer',ylabel='Percent neurons replaced',title='A) Replacing pre-GELU neurons')\n","\n","h = axs[1,0].imshow()\n","fig.colorbar(h,ax=axs[1,0],pad=.01)\n","axs[1,0].set(xlabel='Hidden states layer',ylabel='Percent neurons replaced',title='B) Replacing post-GELU neurons')\n","\n","\n","\n","axs[0,1].plot(,label='Pre-GELU')\n","axs[0,1].plot(,label='Post-GELU')\n","axs[0,1].set(xlabel='Hidden state layer',ylabel='Vector norm difference',title='C) Impact on hidden states')\n","axs[0,1].legend()\n","\n","axs[1,1].plot(,label='pre-GELU')\n","axs[1,1].plot(,label='Post-GELU')\n","axs[1,1].axhline(logsm_clean[target_idx],color='k',linestyle='--',label='Clean model')\n","axs[1,1].set(xlabel='Percent neurons replaced',ylabel='Log softmax to target',title='D) Impact on output logits')\n","axs[1,1].legend(fontsize=8)\n","\n","\n","plt.tight_layout()\n","plt.savefig('ch7_proj49_part4.png')\n","plt.show()"],"metadata":{"id":"TlG8APfS0YvB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZkqKvulK0YsN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 5: Comparison with MLP projections**"],"metadata":{"id":"ZeNig_mo9Xcz"}},{"cell_type":"code","source":["log_sm_targ_pr = np.zeros(len(pcts_to_replace))\n","hs_diff_norms_pr = np.zeros((len(pcts_to_replace),nlayers+1))\n","\n","\n","for repli in range(len(pcts_to_replace)):\n","\n","\n","  ### ------ hook ------ ###\n","  def replace_hook(module,input,output):\n","\n","    # find the median\n","    vals =\n","    med =\n","\n","    # replace top-magnitude p%\n","    idx = torch.topk\n","    output[0,-1,idx] = med\n","    return output\n","\n","  # put hooks in all layers\n","  handles = []\n","  for layeri in range(0,nlayers):\n","    h = model.transformer.h[layeri].mlp.\n","    handles.append(h)\n","  ### ------ end of hook ------ ###\n","\n","\n","  # forward pass to get output logits, and remove hook\n","  with torch.no_grad():\n","    out = model(tokens,output_hidden_states=True)\n","  for h in handles: h.remove()\n","\n","  # log-softmax of target\n","  log_sm_targ_pr[repli] = F.log_softmax(out.logits[0,-1,:].detach(),dim=-1)[target_idx]\n","\n","  # norm of hidden-states differences\n","  for i in range(nlayers+1):\n","    hs = out.hidden_states[i].cpu().squeeze()[-1,:]\n","    hs_clean = out_clean.hidden_states[i].cpu().squeeze()[-1,:]\n","    hs_diff_norms_pr[repli,i] = torch.norm(hs-hs_clean)"],"metadata":{"id":"hbxxVlHKNG0A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig,axs = plt.subplots(2,2,figsize=(10,6))\n","\n","combi_exp = (hs_diff_norms_ex+hs_diff_norms_ge)/2\n","h = axs[0,0].imshow(combi_exp,aspect='auto',cmap='magma',origin='lower',vmax=combi_exp.max()*.8,\n","              extent=[0,nlayers,100*pcts_to_replace[0],100*pcts_to_replace[-1]])\n","fig.colorbar(h,ax=axs[0,0],pad=.01)\n","axs[0,0].set(xlabel='Hidden states layer',ylabel='Percent neurons replaced',title='A) Average of pre- and post-GELU')\n","\n","h = axs[1,0].imshow(hs_diff_norms_pr,aspect='auto',cmap='magma',origin='lower',vmax=hs_diff_norms_pr.max()*.8,\n","              extent=[0,nlayers,100*pcts_to_replace[0],100*pcts_to_replace[-1]])\n","fig.colorbar(h,ax=axs[1,0],pad=.01)\n","axs[1,0].set(xlabel='Hidden states layer',ylabel='Percent projections replaced',title='B) Replacing projection dimensions')\n","\n","\n","\n","axs[0,1].plot(np.mean(hs_diff_norms_ex,axis=0),'go-',linewidth=.5,markerfacecolor=[.7,.9,.7,.7],markersize=10,label='Expansion')\n","axs[0,1].plot(np.mean(hs_diff_norms_ge,axis=0),'rs-',linewidth=.5,markerfacecolor=[.9,.7,.7,.7],markersize=10,label='Post-GELU')\n","axs[0,1].plot(np.mean(hs_diff_norms_pr,axis=0),'b^-',linewidth=.5,markerfacecolor=[.7,.7,.9,.7],markersize=10,label='Projection')\n","axs[0,1].set(xlabel='Hidden state layer',ylabel='Vector norm difference',title='C) Impact on hidden states')\n","axs[0,1].legend()\n","\n","axs[1,1].plot(100*pcts_to_replace,log_sm_targ_ex,'go-',linewidth=.5,markerfacecolor=[.7,.9,.7,.7],markersize=10,label='Expansion')\n","axs[1,1].plot(100*pcts_to_replace,log_sm_targ_ge,'rs-',linewidth=.5,markerfacecolor=[.9,.7,.7,.7],markersize=10,label='Post-GELU')\n","axs[1,1].plot(100*pcts_to_replace,log_sm_targ_pr,'b^-',linewidth=.5,markerfacecolor=[.7,.7,.9,.7],markersize=10,label='Projection')\n","axs[1,1].axhline(logsm_clean[target_idx],color='k',linestyle='--',label='Clean model')\n","axs[1,1].set(xlabel='Percent replaced',ylabel='Log softmax to target',title='D) Impact on output logits')\n","axs[1,1].legend(fontsize=9)\n","\n","\n","plt.tight_layout()\n","plt.savefig('ch7_proj49_part5.png')\n","plt.show()"],"metadata":{"id":"JGNazf4qNG0B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WfAZBSCKNsBg"},"execution_count":null,"outputs":[]}]}