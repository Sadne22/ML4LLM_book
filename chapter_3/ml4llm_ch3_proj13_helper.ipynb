{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Book:</h2>|<h1><a href=\"https://open.substack.com/pub/mikexcohen/p/llm-breakdown-16-tokenization-words\" target=\"_blank\">50 ML projects to understand LLMs</a></h1>|\n","|-|:-:|\n","|<h2>Project:</h2>|<h1><b>[12] Word similarity via distance and cosine</b></h1>|\n","|<h2>Author:<h2>|<h1>Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h1>|\n","\n","<br>\n","\n","<i>Using the code without reading the book may lead to confusion or errors.</i>"],"metadata":{"id":"py_eibYAH3Q-"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import torch"],"metadata":{"id":"R5SI-Iyy4dtm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### matplotlib adjustments (commented lines are for dark mode)\n","\n","# svg plots (higher-res)\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n","\n","plt.rcParams.update({\n","    # 'figure.facecolor': '#282a2c',\n","    # 'figure.edgecolor': '#282a2c',\n","    # 'axes.facecolor':   '#282a2c',\n","    # 'axes.edgecolor':   '#DDE2F4',\n","    # 'axes.labelcolor':  '#DDE2F4',\n","    # 'xtick.color':      '#DDE2F4',\n","    # 'ytick.color':      '#DDE2F4',\n","    # 'text.color':       '#DDE2F4',\n","    'axes.spines.right': False,\n","    'axes.spines.top':   False,\n","    'axes.titleweight': 'bold',\n","    'axes.labelweight': 'bold',\n","    'savefig.dpi':300,\n","})"],"metadata":{"id":"9sMNotjcbD2c"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oB3yKCAhaWhX"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["# **Part 1: Cosine similarity vs. Euclidean distance**"],"metadata":{"id":"V_LjfGSI4CBq"}},{"cell_type":"code","source":["# simulation parameters\n","M = 768\n","k = 1000\n","\n","# initializations\n","cs = np.zeros((k,3))\n","dist = np.zeros((k,3))\n","\n","# loop over simulation iterations\n","for i in range(k):\n","\n","  # create the data\n","  x = np.random.normal\n","  y =\n","\n","  # case 1: normal random\n","  dist[i,0] =\n","  cs[i,0] =\n","\n","  # case 2: different variances\n","  x\n","  dist[i,1] =\n","  cs[i,1] =\n","\n","  # case 3: normalized\n","  dist[i,2] =\n","  cs[i,2] =\n","\n","\n","# the first plot\n","plt.plot(,,'rh',markerfacecolor=[.9,.7,.7,.5],label='Case 1: randn')\n","plt.plot(,,'go',markerfacecolor=[.7,.9,.7,.5],label='Case 2: Unequal var.')\n","plt.plot(,,'bs',markerfacecolor=[.7,.7,.9,.5],label='Case 3: Normed')\n","\n","plt.gca().set(xlabel='Euclidean distance',ylabel='Cosine similarity')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.savefig('ch3_proj13_part1a.png')\n","plt.show()"],"metadata":{"id":"8tEs3Oaau9kY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# the second plot\n","_,axs = plt.subplots(1,3,figsize=(10,3))\n","\n","axs[0].plot(,,'rh',markerfacecolor=[.9,.7,.7,.7])\n","axs[0].set(xlabel='Euclidean distance',ylabel='Cosine similarity',title='A) Case 1: randn')\n","\n","axs[1].plot(,,'go',markerfacecolor=[.7,.9,.7,.7])\n","axs[1].set(xlabel='Euclidean distance',ylabel='Cosine similarity',title='B) Case 2: Unequal var.')\n","\n","axs[2].plot(,,'bs',markerfacecolor=[.7,.7,.9,.7])\n","axs[2].set(xlabel='Euclidean distance',ylabel='Cosine similarity',title='C) Case 3: Normed')\n","\n","plt.tight_layout()\n","plt.savefig('ch3_proj13_part1b.png')\n","plt.show()"],"metadata":{"id":"Uw2kIcZz3jHZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9IMawnr2zwQ-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 2: Relationship between similarity and distance**"],"metadata":{"id":"UJugBzLrzwMh"}},{"cell_type":"code","source":["# apply equation 1.13 to Case 3 (both vectors normed)\n","eq13 =\n","\n","plt.figure(figsize=(8,4))\n","plt.plot(eq13,'k.')\n","\n","# note the y-axis, then use the same y-axis as in Part 1\n","# plt.ylim([-.1,.1])\n","\n","plt.tight_layout()\n","plt.savefig('ch3_proj13_part2a.png')\n","plt.show()"],"metadata":{"id":"w5Jmj1t8u9gh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# errors (difference between RHS and LHS)\n","e = np.zeros(k)\n","\n","# loop over simulation iterations\n","for i in range(k):\n","\n","  # create the data\n","  x = np.random.normal(0,1,M)\n","  y = np.random.normal(0,1,M)\n","\n","  # case 1: normal random\n","  d =\n","  s =\n","\n","  xtx =\n","  yty =\n","\n","  # Equation 1.14\n","  e[i] =\n","\n","  # Equation 1.15 (comment out to run 1.14)\n","  e[i] =\n","\n","\n","# and plot\n","plt.figure(figsize=(8,4))\n","plt.plot(e,'k.')\n","plt.gca().set(xlabel='Simulation number',ylabel='Error')\n","\n","plt.tight_layout()\n","plt.savefig('ch3_proj13_part2b.png')\n","plt.show()"],"metadata":{"id":"0wFi3jqKGP5_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SsLJGB9gzL3K"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 3: Word synonyms via distance and similarity**"],"metadata":{"id":"IYa6IRn8NZQK"}},{"cell_type":"code","source":["from transformers import BertTokenizer, BertModel\n","\n","# load BERT tokenizer and model\n","tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n","model = BertModel.from_pretrained('bert-large-uncased')\n","\n","# extract embeddings\n","embeddings = model.embeddings.word_embeddings.weight.detach()\n","\n","# vocab size\n","n_vocab ="],"metadata":{"id":"IlLTVTpTBS75"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pick a \"seed\" vector\n","seedword = 'beauty'\n","seedtoken = tokenizer.encode()\n","\n","print(f'The token \"{}\" comprises these token indices: {}')"],"metadata":{"id":"38dhFl7YNc8G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seedvect = [seedtoken,:]\n","\n","# Euclidean distance to all other vectors\n","eucDist =\n","\n","# cosine similarity to all other vectors\n","cossim =\n","\n","# remove trivial values\n","\n","# min-max scaling for coloring the scatter plot\n","eucDist_minmax =\n","cossim_minmax ="],"metadata":{"id":"ytq8TdhqPZ_g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualizations\n","_,axs = plt.subplots(1,3,figsize=(15,4))\n","\n","# plot the Euclidean distances\n","axs[0].scatter(,,s=20,c=cossim_minmax,cmap=plt.cm.plasma,alpha=.4)\n","axs[0].set(xlim=[-20,n_vocab+20],xlabel='Token index',ylabel='Euclidean distance',\n","           title=f'Distance to \"{seedword}\",\\ncolored by cosine similarity')\n","\n","# plot the cosine similarities\n","axs[1].scatter(,,s=20,c=eucDist_minmax,cmap=plt.cm.magma,alpha=.4)\n","\n","# and their relationship\n","axs[2].plot(,,'ko',markerfacecolor=[.7,.7,.9,.2])\n","axs[2].set(xlabel='Euclidean distance',ylabel='Cosine similarity',\n","           title='Relation between\\nS$_C$ and Euclidean distance')\n","\n","plt.tight_layout()\n","plt.savefig('ch3_proj13_part3.png')\n","plt.show()"],"metadata":{"id":"1ujtyROLdKjN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"poyFTXWDcGBn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 4: Top-k closest and most similar**"],"metadata":{"id":"h6KjeZ-j4a0Q"}},{"cell_type":"code","source":["# now for the top-k closest tokens\n","k = 10\n","topKidx = torch.argsort(\n","\n","print(f'Minimum distance {k} words to \"{seedword}\":')\n","for i in topKidx:\n","  print(f'  Distance of {"],"metadata":{"id":"f7YhIKAmNZNP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# now for the top-k most similar tokens\n","topKidx =\n","\n","print(f'Most similar {k} words to \"{seedword}\":')\n","for i in topKidx:\n","  print(f'  Similarity of {"],"metadata":{"id":"fSOsvT4Nar7g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uHh0aBdeW857"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 5: Normalized distance**"],"metadata":{"id":"9pCIFv_Ct06S"}},{"cell_type":"code","source":["### run this cell then repeat Parts 3 and 4\n","\n","# normalize the embeddings matrix\n","E_norm = torch.nn.functional.normalize\n","\n","# Euclidean distance to all other vectors\n","eucDist =\n","eucDist[eucDist==0] =\n","\n","# min-max scaling for coloring the scatter plot\n","eucDist_minmax ="],"metadata":{"id":"-3kBjd3xfY7t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6vHSrKbst71u"},"execution_count":null,"outputs":[]}]}