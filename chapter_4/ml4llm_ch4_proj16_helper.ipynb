{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyMGqd+vY2O7GySOadQ78Wzl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Book:</h2>|<h1><a href=\"https://open.substack.com/pub/mikexcohen/p/llm-breakdown-16-tokenization-words\" target=\"_blank\">50 ML projects to understand LLMs</a></h1>|\n","|-|:-:|\n","|<h2>Project:</h2>|<h1><b>[16] Softmax probability distributions</b></h1>|\n","|<h2>Author:<h2>|<h1>Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h1>|\n","\n","<br>\n","\n","<i>Using the code without reading the book may lead to confusion or errors.</i>"],"metadata":{"id":"py_eibYAH3Q-"}},{"cell_type":"code","source":[],"metadata":{"id":"R5SI-Iyy4dtm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn.functional as F\n","\n","from transformers import AutoModelForCausalLM, GPT2Tokenizer"],"metadata":{"id":"rn8Fcyf87EXx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### matplotlib adjustments (commented lines are for dark mode)\n","\n","# svg plots (higher-res)\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n","\n","plt.rcParams.update({\n","    # 'figure.facecolor': '#282a2c',\n","    # 'figure.edgecolor': '#282a2c',\n","    # 'axes.facecolor':   '#282a2c',\n","    # 'axes.edgecolor':   '#DDE2F4',\n","    # 'axes.labelcolor':  '#DDE2F4',\n","    # 'xtick.color':      '#DDE2F4',\n","    # 'ytick.color':      '#DDE2F4',\n","    # 'text.color':       '#DDE2F4',\n","    'axes.spines.right': False,\n","    'axes.spines.top':   False,\n","    'axes.titleweight': 'bold',\n","    'axes.labelweight': 'bold',\n","    'savefig.dpi':300,\n","})"],"metadata":{"id":"dy4A-ah8kzZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nxqgPabM0FuN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 1: Softmax in numpy and PyTorch**"],"metadata":{"id":"xg66_Mew0Frx"}},{"cell_type":"code","metadata":{"id":"vmjUxlEqGbDu"},"source":["# the list of numbers\n","z = [1,1.1,2,3,5,6,6.1]\n","\n","# compute the softmax result\n","num =\n","den =\n","sm =\n","\n","print(sm)\n","print(np.sum(sm))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["zTorch = torch.tensor(\n","\n","# using a function\n","zTorch_sm =\n","zTorch_sm"],"metadata":{"id":"nMluoPkty8LC"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sOug_tPzHY1y"},"source":["# compare\n","plt.figure(figsize=(10,5))\n","\n","plt.plot(,,'ks-',markerfacecolor=[.9,.7,.7],markersize=10,label='Manual')\n","plt.plot(,,'bx:',markersize=8,label='PyTorch')\n","plt.legend()\n","\n","plt.gca().set(xlabel='Original number (z)',ylabel='Softmax probability $\\\\sigma (z)$')\n","\n","plt.tight_layout()\n","plt.savefig('ch4_proj16_part1.png')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xQGpJZXR0FmS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 2: Temperature**"],"metadata":{"id":"5FI0HF4C0FpD"}},{"cell_type":"code","source":["x = torch.linspace(-5,5,55)\n","\n","shapes = 'soh^'\n","\n","plt.figure(figsize=(10,5))\n","for i,temp in enumerate([.3,.6,1,1.4]):\n","  sm =\n","  plt.plot(x,sm,shapes[i]+'-',linewidth=2)\n","\n","plt.gca().set(xlabel='Original number',ylabel='Softmax probability')\n","# plt.yscale('log') # FYI\n","\n","plt.tight_layout()\n","plt.savefig('ch4_proj16_part2.png')\n","plt.show()"],"metadata":{"id":"DEqcFxC50Fju"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VWOmGVIrGvM4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 3: Softmax of LLM output logits**"],"metadata":{"id":"PtnG5KKjGvJ9"}},{"cell_type":"code","source":["# load pretrained GPT-2 model and tokenizer\n","gpt2_small = AutoModelForCausalLM.from_pretrained('gpt2')\n","gpt2_large = AutoModelForCausalLM.from_pretrained('gpt2-large')\n","\n","# set to eval mode\n","\n","\n","# and the tokenizer\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"],"metadata":{"id":"4m885jVKGvHB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'GPT-2-small has {} parameters.')\n","print(f'GPT-2-large has {} parameters.')"],"metadata":{"id":"PiitTpg20Il3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["txt = 'It was a dark and stormy'\n","tokens = tokenizer\n","tokens"],"metadata":{"id":"tJSJ7xWWgsJI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'The text comprises {} tokens.\\n')\n","\n","for t in tokens[0]:\n","  print(f'{} is \"{}\"')"],"metadata":{"id":"UmrTUlsfhC3v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# forward pass through the model\n","outputs = gpt2_small(tokens)\n","outputs"],"metadata":{"id":"jFPKdkvuiB2E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outputs.logits.shape"],"metadata":{"id":"_W-rnqMSiBzP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["logits = outputs.\n","logits_sm = F.\n","logits.shape"],"metadata":{"id":"4saM--Ikicvb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'The sum of the raw logits is\n","print(f'The sum of the softmax logits is"],"metadata":{"id":"pWyqVnDXjC21"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot the raw and softmax logits\n","_,axs = plt.subplots(1,3,figsize=(12,3))\n","\n","axs[0].plot(,'ks',markerfacecolor=[.9,.7,.7,.3])\n","axs[0].set(title='A) All final token logits')\n","\n","axs[1].plot(,'o',markerfacecolor=[.7,.9,.7,.3])\n","axs[1].set(title='B) Softmax probabilities')\n","\n","axs[2].plot(,,'^',markerfacecolor=[.7,.7,.9,.7])\n","axs[2].set(title='C) Logits by probabilities')\n","\n","plt.tight_layout()\n","plt.savefig('ch4_proj16_part3.png')\n","plt.show()"],"metadata":{"id":"w6IB8lw0ikvU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# find the maximum\n","max_logit =\n","print(f'The maximum softmax logit is #{} with a value of {}')\n","print(f'The max word is \"{}\"')"],"metadata":{"id":"yqH00PEWiLoj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"o0KdHu6cGvEH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 4: Top 10 probabilities and temperature**"],"metadata":{"id":"h0KKyyHVGvA7"}},{"cell_type":"code","source":["k = 10\n","top_k =\n","\n","print(txt,'___\\n')\n","\n","for i in range(k):\n","  val =\n","  tok =\n","  print(f'{} ({}%) is \"{}\"')"],"metadata":{"id":"JRqheArIGu9p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["temps = [ .5,1,1.5 ]\n","\n","plt.figure(figsize=(10,5))\n","\n","shapes = 'so^'\n","\n","for i,T in enumerate(temps):\n","\n","  # calculate softmax and find the top 10\n","  sm = F.softmax(logits/T\n","  top_k =\n","\n","  # plot\n","  color = [.7,.7,.7]\n","  color[i] = .9\n","  plt.plot(label=f'T = {T}')\n","\n","\n","plt.legend()\n","plt.gca().set(xlabel=f'Top-{k} indices',ylabel='Softmax probabilities (log)',yscale='log')\n","\n","plt.tight_layout()\n","plt.savefig('ch4_proj16_part4.png')\n","plt.show()"],"metadata":{"id":"6ImK880lGu6m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UgfuJihDIb0O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 5: Numerical instabilities and normalization**"],"metadata":{"id":"nQWQlIn3IbuX"}},{"cell_type":"code","source":["# get the outputs of the models\n","tokens = tokenizer.encode('A plethora of platypuses.',return_tensors='pt')\n","outputs_small =\n","outputs_large ="],"metadata":{"id":"vVFv6bJG7PhM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# grab the final token logit outputs\n","logits_small =\n","logits_large =\n","\n","_,axs = plt.subplots(1,3,figsize=(12,3.5))\n","\n","# gpt2 small\n","axs[0].plot(,'k.',alpha=.2)\n","axs[0].set(title='A) GPT-2 SMALL')\n","\n","# gpt2 large\n","axs[1].plot(\n","axs[1].set(title='B) GPT-2 LARGE')\n","\n","# against each other\n","axs[2].plot(\n","axs[2].set(title='C) Comparison of both models')\n","\n","plt.tight_layout()\n","plt.savefig('ch4_proj16_part5a.png')\n","plt.show()"],"metadata":{"id":"HuxTwOnR7Pem"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# manual softmax\n","sm_manual_small =\n","sm_manual_large =\n","\n","_,axs = plt.subplots(1,3,figsize=(12,3.5))\n","\n","# gpt2 small\n","axs[0].plot(\n","axs[0].set(xlim=[-10,tokenizer.vocab_size+9],xlabel='Token index',ylabel='Softmax probabilities',title='A) GPT-2 SMALL')\n","\n","# gpt2 large\n","axs[1].plot(\n","axs[1].set(xlim=[-10,tokenizer.vocab_size+9],xlabel='Token index',ylabel='Softmax probabilities',title='B) GPT-2 LARGE')\n","\n","# against each other\n","axs[2].plot(\n","axs[2].set(xlabel='GPT-2 SMALL',ylabel='GPT-2 LARGE',title='C) Comparison of both models')\n","\n","plt.tight_layout()\n","plt.savefig('ch4_proj16_part5b.png')\n","plt.show()"],"metadata":{"id":"ENUE4s5B7Pbw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["logits_small[3000],sm_manual_small[1000]"],"metadata":{"id":"1pLnVPc0tvKy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# simple normalization (subtract max value)\n","logits_small_norm =\n","logits_large_norm =\n","\n","# visualize\n","_,axs = plt.subplots(1,3,figsize=(12,3.5))\n","\n","# gpt2 small\n","axs[0].plot(logits_small_norm,'k.',alpha=.2)\n","axs[0].set(xlim=[-10,tokenizer.vocab_size+9],xlabel='Token index',ylabel='Softmax probabilities',title='A) GPT-2 SMALL')\n","\n","# gpt2 large\n","axs[1].plot(logits_large_norm,'k.',alpha=.2)\n","axs[1].set(xlim=[-10,tokenizer.vocab_size+9],xlabel='Token index',ylabel='Softmax probabilities',title='B) GPT-2 LARGE')\n","\n","# against each other\n","axs[2].plot(logits_small_norm,logits_large_norm,'m.',alpha=.2)\n","axs[2].set(xlabel='GPT-2 SMALL',ylabel='GPT-2 LARGE',title='C) Comparison of both models')\n","\n","plt.tight_layout()\n","plt.savefig('ch4_proj16_part5c.png')\n","plt.show()"],"metadata":{"id":"5f1s4XI47PY-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# now repeat the manual softmax\n","sm_manual_smallN =\n","sm_manual_largeN =\n","\n","_,axs = plt.subplots(1,3,figsize=(12,3.5))\n","\n","# gpt2 small\n","axs[0].plot(sm_manual_smallN,'k.',alpha=.2)\n","axs[0].set(xlim=[-10,tokenizer.vocab_size+9],xlabel='Token index',ylabel='Softmax probabilities',title='A) GPT-2 SMALL')\n","\n","# gpt2 large\n","axs[1].plot(sm_manual_largeN,'k.',alpha=.2)\n","axs[1].set(xlim=[-10,tokenizer.vocab_size+9],xlabel='Token index',ylabel='Softmax probabilities',title='B) GPT-2 LARGE')\n","\n","# against each other\n","axs[2].plot(sm_manual_smallN,sm_manual_largeN,'m.',alpha=.2)\n","axs[2].set(xlabel='GPT-2 SMALL',ylabel='GPT-2 LARGE',title='C) Comparison of both models')\n","\n","plt.tight_layout()\n","plt.savefig('ch4_proj16_part5d.png')\n","plt.show()"],"metadata":{"id":"kJIyRzvPAQVP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pytorch softmax\n","sm_torch_small =\n","sm_torch_large =\n","\n","_,axs = plt.subplots(1,3,figsize=(12,3.5))\n","\n","# gpt2 small\n","axs[0].plot(sm_torch_small,'k.',alpha=.2)\n","axs[0].set(xlim=[-10,tokenizer.vocab_size+9],xlabel='Token index',ylabel='Softmax probabilities',title='GPT-2 SMALL')\n","\n","# gpt2 large\n","axs[1].plot(sm_torch_large,'k.',alpha=.2)\n","axs[1].set(xlim=[-10,tokenizer.vocab_size+9],xlabel='Token index',ylabel='Softmax probabilities',title='GPT-2 LARGE')\n","\n","# against each other\n","axs[2].plot(sm_torch_small,sm_torch_large,'m.',alpha=.2)\n","axs[2].set(xlabel='GPT-2 SMALL',ylabel='GPT-2 LARGE',title='Comparison of both models')\n","\n","plt.tight_layout()\n","plt.savefig('ch4_proj16_part5e.png')\n","plt.show()"],"metadata":{"id":"6puCsem-7PWU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wi_BGQGXAVVW"},"execution_count":null,"outputs":[]}]}