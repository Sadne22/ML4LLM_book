{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Book:</h2>|<h1><a href=\"https://open.substack.com/pub/mikexcohen/p/llm-breakdown-16-tokenization-words\" target=\"_blank\">50 ML projects to understand LLMs</a></h1>|\n","|-|:-:|\n","|<h2>Project:</h2>|<h1><b>[18] Token prediction accuracy</b></h1>|\n","|<h2>Author:<h2>|<h1>Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h1>|\n","\n","<br>\n","\n","<i>Using the code without reading the book may lead to confusion or errors.</i>"],"metadata":{"id":"py_eibYAH3Q-"}},{"cell_type":"code","source":[],"metadata":{"id":"R5SI-Iyy4dtm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn.functional as F\n","\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","# to get wikitext dataset\n","from datasets import load_dataset"],"metadata":{"id":"rn8Fcyf87EXx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### matplotlib adjustments (commented lines are for dark mode)\n","\n","# svg plots (higher-res)\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n","\n","plt.rcParams.update({\n","    # 'figure.facecolor': '#282a2c',\n","    # 'figure.edgecolor': '#282a2c',\n","    # 'axes.facecolor':   '#282a2c',\n","    # 'axes.edgecolor':   '#DDE2F4',\n","    # 'axes.labelcolor':  '#DDE2F4',\n","    # 'xtick.color':      '#DDE2F4',\n","    # 'ytick.color':      '#DDE2F4',\n","    # 'text.color':       '#DDE2F4',\n","    'axes.spines.right': False,\n","    'axes.spines.top':   False,\n","    'axes.titleweight': 'bold',\n","    'axes.labelweight': 'bold',\n","    'savefig.dpi':300,\n","})"],"metadata":{"id":"dy4A-ah8kzZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nxqgPabM0FuN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 1: Token prediction**"],"metadata":{"id":"DA3zcyDTHsH7"}},{"cell_type":"code","source":["# load pretrained GPT-2 model and tokenizer\n","tokenizer = AutoTokenizer.from_pretrained('gpt2')\n","model = AutoModelForCausalLM.from_pretrained('gpt2')\n","model.eval()"],"metadata":{"id":"dkGRkHsbHsKv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# text is paraphrased from https://en.wikipedia.org/wiki/Cubism\n","text = 'Cubism is an art movement that sparked innovations in music and architecture'\n","tokens = tokenizer.encode(text, return_tensors='pt')\n","\n","for t in tokens[0]:\n","  print(f'Token {t:5} is \"{tokenizer.decode(t)}\"')"],"metadata":{"id":"8y8iC98iCgG3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# forward pass\n","with torch.no_grad():\n","  outputs = model(tokens)\n","\n","# find max-logit prediction for one token\n","whichToken = 5\n","\n","# token logits are predictions for the subsequent token\n","token_logits = outputs.logits[0,whichToken,:]\n","maxlogit = torch.argmax(token_logits)\n","\n","# visualize the logits and mark the predicted next-token\n","plt.figure(figsize=(12,4))\n","plt.plot(maxlogit,token_logits[maxlogit],'go',markersize=10)\n","plt.plot(token_logits,'.',markerfacecolor=[.9,.7,.7,.3])\n","\n","plt.gca().set(title=f'Model prediction is \"{tokenizer.decode(maxlogit)}\" (target is \"{tokenizer.decode(tokens[0,whichToken+1])}\")',\n","              xlabel='Token index',ylabel='Model output logit',xlim=[-50,tokenizer.vocab_size+49])\n","\n","plt.tight_layout()\n","plt.savefig('ch4_proj18_part1.png')\n","plt.show()"],"metadata":{"id":"VFn17-DXOdVi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gvxuMLY5QzBs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 2: Per-token predictions**"],"metadata":{"id":"SIDYU3KrQaqP"}},{"cell_type":"code","source":["# find the token associated with a quote to insert into the sentences\n","quotetok = tokenizer.encode('\"',return_tensors='pt')[0]\n","\n","# initialize\n","accuracy = np.zeros(len(tokens[0]-1),dtype=int)\n","\n","# loop over tokens\n","for idx in range(len(tokens[0])-1):\n","\n","  # get max logit\n","  max_logit = torch.argmax( outputs.logits[0,idx,:] ,dim=-1).unsqueeze(0)\n","\n","  # get the max prediction\n","  accuracy[idx] = max_logit[0] == tokens[0][idx+1]\n","\n","  # reconstruct the sentence tokens\n","  sentence = torch.cat(\n","      (tokens[0][:idx+1],              # original first few tokens\n","       quotetok, max_logit, quotetok), # predicted token, padded by quotes\n","      dim=-1)\n","\n","  # decode and print\n","  print(f\"{'Xâœ“'[accuracy[idx]]}: {tokenizer.decode(sentence)}\")\n","\n","print(f'\\nModel correctly predicted {accuracy.sum()}/{len(accuracy)} tokens ({accuracy.mean():.2%})')"],"metadata":{"id":"UxLlSONpNmDd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"F868QQaDWiNZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 3: Top-k predicted tokens**"],"metadata":{"id":"rH9qMKDTJSR9"}},{"cell_type":"code","source":["k = 10\n","\n","topk = torch.topk(token_logits,k,dim=-1) # same token_logits variable (from whichToken) defined in Part 1\n","\n","print('Original text:\\n  ',text,'\\n\\nGPT2 predictions:')\n","\n","for t in topk.indices:\n","\n","  # reconstruct the sentence tokens\n","  sentence = torch.cat(\n","      (tokens[0][:whichToken+1],            # original first few tokens\n","       quotetok, t.unsqueeze(0), quotetok), # predicted token\n","      dim=-1)\n","\n","  # decode and print\n","  print('  ',tokenizer.decode(sentence))"],"metadata":{"id":"Ea3LYbSoHsFH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"d3v1WsdDJSU_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 4: Token prediction accuracy in wikitext**"],"metadata":{"id":"xxwEo1g9Hr6V"}},{"cell_type":"code","source":["wikitxt = load_dataset('wikitext', 'wikitext-2-raw-v1', split='test')\n","tokens = tokenizer.encode('\\n\\n'.join(wikitxt['text']), return_tensors='pt')\n","num_tokens = torch.numel(tokens)\n","\n","print(f'There are {num_tokens:,} tokens in the wikitext dataset')"],"metadata":{"id":"eg9FL625Hr3k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# here's what one sample looks like\n","wikitxt[1112]['text']"],"metadata":{"id":"gkI_dK3oWuKf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_seq_len = model.config.n_positions\n","print(f'The model can accept up to {max_seq_len} tokens per sequence per forward pass.')"],"metadata":{"id":"VqrzypbzXDDy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# initialize\n","accuracy = np.zeros(max_seq_len-1,dtype=int)\n","\n","# forward pass\n","with torch.no_grad():\n","  outputs = model(tokens[:,:max_seq_len])\n","\n","# loop over tokens\n","for idx in range(max_seq_len-1):\n","\n","  # get max logit\n","  max_logit = torch.argmax( outputs.logits[0,idx,:] ,dim=-1)\n","\n","  # get the max prediction\n","  accuracy[idx] = max_logit == tokens[0][idx+1]\n","\n","print(f'\\nModel correctly predicted {accuracy.sum()}/{len(accuracy)} tokens ({accuracy.mean():.2%})')"],"metadata":{"id":"SYsnD4jeWiTZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# the text that was assessed\n","print(tokenizer.decode(tokens[0,:max_seq_len]))"],"metadata":{"id":"kK9hllJcHr9J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualize\n","plt.figure(figsize=(10,3))\n","plt.plot(np.random.normal(0,.03,len(accuracy))+accuracy,'ko',markerfacecolor=[.7,.7,.9,.4])\n","plt.gca().set(xlabel='Token position',yticks=[0,1],yticklabels=['Incorrect','Correct'],\n","              title=f'Average categorical accuracy: ({accuracy.mean():.2%})')\n","\n","plt.tight_layout()\n","plt.savefig('ch4_proj18_part4.png')\n","plt.show()"],"metadata":{"id":"UjfpQyFsJZ0U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xHJdlpkBF_yE"},"execution_count":null,"outputs":[]}]}