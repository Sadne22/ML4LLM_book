{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Book:</h2>|<h1><a href=\"https://open.substack.com/pub/mikexcohen/p/llm-breakdown-16-tokenization-words\" target=\"_blank\">50 ML projects to understand LLMs</a></h1>|\n","|-|:-:|\n","|<h2>Project:</h2>|<h1><b>[19] LLM loss function</b></h1>|\n","|<h2>Author:<h2>|<h1>Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h1>|\n","\n","<br>\n","\n","<i>Using the code without reading the book may lead to confusion or errors.</i>"],"metadata":{"id":"py_eibYAH3Q-"}},{"cell_type":"code","source":[],"metadata":{"id":"R5SI-Iyy4dtm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from transformers import AutoModelForCausalLM, AutoTokenizer"],"metadata":{"id":"rn8Fcyf87EXx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### matplotlib adjustments (commented lines are for dark mode)\n","\n","# svg plots (higher-res)\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n","\n","plt.rcParams.update({\n","    # 'figure.facecolor': '#282a2c',\n","    # 'figure.edgecolor': '#282a2c',\n","    # 'axes.facecolor':   '#282a2c',\n","    # 'axes.edgecolor':   '#DDE2F4',\n","    # 'axes.labelcolor':  '#DDE2F4',\n","    # 'xtick.color':      '#DDE2F4',\n","    # 'ytick.color':      '#DDE2F4',\n","    # 'text.color':       '#DDE2F4',\n","    'axes.spines.right': False,\n","    'axes.spines.top':   False,\n","    'axes.titleweight': 'bold',\n","    'axes.labelweight': 'bold',\n","    'savefig.dpi':300,\n","})"],"metadata":{"id":"dy4A-ah8kzZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nxqgPabM0FuN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 1: Manual negative log likelihood loss**"],"metadata":{"id":"DA3zcyDTHsH7"}},{"cell_type":"code","source":["# start with three outputs (raw model outputs for three tokens in the vocab)\n","model_output = np.array([ -1, 2.3, .1 ])\n","print('Raw model outputs:\\n  ',model_output,'\\n')\n","\n","# NLLLoss expects log-softmax inputs!\n","softmax =\n","logsoftmax_output =\n","print('Log-softmax model outputs:\\n  ',logsoftmax_output,'\\n')\n","\n","\n","# check the loss for different targets\n","for target in range(len(model_output)):\n","\n","  # calculate the loss\n","  theloss =\n","\n","  # and print\n","  print(f'Loss is {theloss:.4f} when correct output is index \"{target}\"')"],"metadata":{"id":"VY7CzJLhlsrd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"HWRj_qJmpBCH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 2: NLLLoss in PyTorch**"],"metadata":{"id":"HHG6X1yEpA_M"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HU06kyWmre5Q"},"outputs":[],"source":["# create a loss function instance\n","loss_function = nn.NLLLoss()\n","dir(loss_function)"]},{"cell_type":"code","source":["# start with three outputs (raw model outputs for three tokens in the vocab)\n","model_output = torch.tensor\n","print('Raw model outputs:\\n  ',,'\\n')\n","\n","# NLLLoss expects log-softmax inputs!\n","logsoftmax_output =\n","print('Log-softmax model outputs:\\n  ',logsoftmax_output[0],'\\n')\n","\n","\n","# check the loss for different targets\n","for target in range(len(model_output[0])):\n","\n","  # which output is the target (correct response)?\n","  target =\n","\n","  # calculate the loss\n","  theloss = loss_function\n","\n","  # and print\n","  print(f'Loss is {} when correct output is index \"{}\"')"],"metadata":{"id":"0Uh9evVlsrP2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create some tensors\n","T1 = torch.tensor([3.4])\n","T2 = torch.tensor([3,4])\n","T3 = torch.tensor([ [3.1],[4] ])\n","\n","print(f'T1 is of type {type(T1)}, and T1.item() is of type {type(T1.item())}\\n')\n","# print(f'T2 is of type {type(T2)}, and T2.item() is of type {type(T2.item())}\\n')\n","# print(f'T3 is of type {type(T3)}, and T3.item() is of type {type(T3.item())}\\n')"],"metadata":{"id":"wH3C3uugVFeE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# otherwise:\n","T3.numpy()"],"metadata":{"id":"-QErbMUoYV0Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mYbtfZDGlsoq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 3: Cross-entropy loss for next-token prediction**"],"metadata":{"id":"txJd0RSKo8xD"}},{"cell_type":"code","source":["# load pretrained GPT-2 model and tokenizer\n","tokenizer = AutoTokenizer.from_pretrained('gpt2')\n","model = AutoModelForCausalLM.from_pretrained('gpt2')\n","model.eval()"],"metadata":{"id":"ROL219FwtKJw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from the Beatles :<)\n","text = 'There are places I remember all my life, though some have changed. Some forever, not for better, some have gone and some remain.'\n","\n","tokens =\n","print(f'There are {} tokens, {} of which are unique.')"],"metadata":{"id":"pvl77X52sACU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# targets are the next-tokens\n","targets =\n","\n","# print the input-target table\n","print(' Input | Target')\n","print('-------+--------')\n","for i in range(len(tokens[0])-1):\n","  print(f' {}  |  {}')"],"metadata":{"id":"zK5v57Fft5qv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# forward pass and get logits\n","with torch.no_grad():\n","  outputs = model\n","logits =\n","\n","# NLLLoss expects log-softmax\n","logits_log_sm =\n","\n","print(f'Shape of logits: {list(logits.shape)}')\n","print(f'Shape of targets: {list(targets.shape)}')"],"metadata":{"id":"oETrtZRCpKoJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# losses\n","loss = loss_function\n","loss"],"metadata":{"id":"CahWrwbWjCQs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"O0HAea-Atsrb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 4: Manual loss calculation**"],"metadata":{"id":"jogJumzXuxRo"}},{"cell_type":"code","source":["losses = np.zeros(len(tokens[0])-1)\n","\n","for i in range(len(tokens[0])-1):\n","\n","  # get the log-softmax for this token\n","  log_sm =\n","\n","  # pick out the logsm for target\n","  losses[i] =\n","\n","losses.mean()"],"metadata":{"id":"jCTq4OG0vZDE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(12,4))\n","\n","loss_scale =\n","\n","plt.bar()\n","plt.gca().set(xticks=range(len(losses)),xlabel='Token',ylabel='Loss')\n","plt.xticks(rotation=90)\n","\n","plt.tight_layout()\n","plt.savefig('ch4_proj19_part4.png')\n","plt.show()"],"metadata":{"id":"1rk8Df7ixUQi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_pShjXRRvY9b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 5: Using the model's internal loss calculation**"],"metadata":{"id":"sSXcKNrfpKlO"}},{"cell_type":"code","source":["with torch.no_grad():\n","  outputs = model(tokens,\n","outputs.loss"],"metadata":{"id":"BJy05_5lo8uO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Lt6246RBjZDL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 6: Expected loss from random tokens**"],"metadata":{"id":"rSATFN4zjZAH"}},{"cell_type":"code","source":["# the expected loss of random tokens\n","expectedLoss =\n","print(f'Expected loss: {expectedLoss:.4f}')"],"metadata":{"id":"KVWZirPlUz_f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["losses = np.zeros(10)\n","for i in range(len(losses)):\n","\n","  # generate random tokens\n","  randtokens = torch.randint\n","\n","  # get the loss\n","  with torch.no_grad():\n","    outputs = model(\n","  losses[i] =\n","\n","  print(f'Finished iteration {i+1} of {len(losses)}')"],"metadata":{"id":"3I1MfGxHV4PO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# the text the model tried to predict :|\n","tokenizer.decode(randtokens[0])"],"metadata":{"id":"xvi-pwSIs0Lm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(8,3))\n","\n","plt.plot(,'kh',markerfacecolor=[.9,.7,.7],markersize=12,label='Empirical')\n","plt.axhline(,color=[.7,.7,.9],linestyle='--',label='Expected')\n","\n","plt.gca().set(xlabel='Iteration',ylabel='Loss')\n","\n","plt.tight_layout()\n","plt.savefig('ch4_proj19_part6.png')\n","plt.show()"],"metadata":{"id":"N_-XrKt2owUO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"m2GGHASZo8gT"},"execution_count":null,"outputs":[]}]}