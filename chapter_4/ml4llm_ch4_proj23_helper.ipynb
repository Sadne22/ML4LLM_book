{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1kXRsDpZTHu2AQhMIYfJZQFGlXOfsPZDz","timestamp":1762651149499},{"file_id":"10s_aPG2VBUMMRasU3-vcgrS9vMckMTtX","timestamp":1762295564177}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Book:</h2>|<h1><a href=\"https://open.substack.com/pub/mikexcohen/p/llm-breakdown-16-tokenization-words\" target=\"_blank\">50 ML projects to understand LLMs</a></h1>|\n","|-|:-:|\n","|<h2>Project:</h2>|<h1><b>[23] Measuring language biases</b></h1>|\n","|<h2>Author:<h2>|<h1>Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h1>|\n","\n","<br>\n","\n","<i>Using the code without reading the book may lead to confusion or errors.</i>"],"metadata":{"id":"py_eibYAH3Q-"}},{"cell_type":"code","source":[],"metadata":{"id":"1Xy2XzGPkuA4"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6NPsr5B0nv52"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import scipy.stats as stats\n","\n","import torch\n","import torch.nn.functional as F"]},{"cell_type":"code","source":["### matplotlib adjustments (commented lines are for dark mode)\n","\n","# svg plots (higher-res)\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n","\n","plt.rcParams.update({\n","    # 'figure.facecolor': '#282a2c',\n","    # 'figure.edgecolor': '#282a2c',\n","    # 'axes.facecolor':   '#282a2c',\n","    # 'axes.edgecolor':   '#DDE2F4',\n","    # 'axes.labelcolor':  '#DDE2F4',\n","    # 'xtick.color':      '#DDE2F4',\n","    # 'ytick.color':      '#DDE2F4',\n","    # 'text.color':       '#DDE2F4',\n","    'axes.spines.right': False,\n","    'axes.spines.top':   False,\n","    'axes.titleweight': 'bold',\n","    'axes.labelweight': 'bold',\n","    'savefig.dpi':300,\n","})"],"metadata":{"id":"OmN-vu6fB13k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uwGYahQ2vHxw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 1: Import the BERT LLM and tokenize text**"],"metadata":{"id":"ywn2fKe6AxXq"}},{"cell_type":"code","source":["from transformers import BertTokenizer, BertForMaskedLM\n","\n","# Load BERT model and tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n","model = BertForMaskedLM.from_pretrained('bert-large-uncased')\n","model.eval()"],"metadata":{"id":"ON8xghnbejvW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text = 'I like to eat [MASK] chocolate-covered raisins.'\n","tokens =\n","\n","for t in tokens[0]:\n","  print(f'{t:5}: \"{}\"')"],"metadata":{"id":"E_qK7T_uA4gc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'The mask token is \"{}\", which is index #{}')"],"metadata":{"id":"-HbTWURAZv8k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text = f'I like to eat {} chocolate-covered raisins.'\n","tokens = tokenizer.\n","\n","for t in tokens[0]:\n","  print"],"metadata":{"id":"5Es-Lt6ZZuk7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tokenizer behavior\n","print(tokenizer('hello'),'\\n')\n","print(tokenizer.encode('hello'),'\\n')\n","print(tokenizer.convert_tokens_to_ids('hello'),'\\n')\n","print(tokenizer.convert_tokens_to_ids('hello my name is mike'))"],"metadata":{"id":"6BIWp57Jl2Or"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.decode(100)"],"metadata":{"id":"mZ87E0MC9bou"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Mnz1B3ZNmaY6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 2: Get logits of four text versions**"],"metadata":{"id":"3I2ETvfSA-gI"}},{"cell_type":"code","source":["# list of target words\n","target_words = [ 'he','she','they' ]\n","\n","sentences = ['The doctor informed the patient that he would need more tests.',\n","             'The doctor informed the patient that she would need more tests.',\n","             'The doctor informed the patient that they would need more tests.',\n","             f'The doctor informed the patient that {tokenizer.mask_token} would need more tests.'\n","]\n","\n","tokens = tokenizer(sentences\n","tokens"],"metadata":{"id":"bDCuHH2a-GCn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 1) the mask index\n","maskTarget_idx = torch.where\n","\n","# 2) token indices of target words\n","targets_idx =\n","\n","# 3) print out the tokens\n","for t in tokens['input_ids'][-1]:\n","  print(f'{t:5}: \"{tokenizer.decode(t)}\"')\n","\n","# 4) print out the target tokens\n","print(f'\\nThe mask is in sequence index {maskTarget_idx}\\n')\n","for t in targets_idx:\n","  print(f'Target \"{tokenizer.decode(t)}\" is vocab index {t}')\n"],"metadata":{"id":"5PDoNbldejp1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xzJ1U5waEf3T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# forward-pass the four versions\n","with torch.no_grad():\n","  outs ="],"metadata":{"id":"3zfr49vckLvL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outs.logits.shape"],"metadata":{"id":"88Pm_t4qFDlA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["logits_he = outs.logits[]\n","sm_logits_he = F.softmax()\n","\n","_,axs = plt.subplots(1,2,figsize=(12,3.5))\n","\n","axs[0].plot(,'ko',markerfacecolor=[.7,.9,.7,.5],markersize=8)\n","axs[0].set(xlabel='Tokens',ylabel='Logits',title='A) Logits in \"he\" sentence')\n","\n","axs[1].plot(,'ko',markerfacecolor=[.7,.9,.7,.5],markersize=8)\n","axs[1].set(xlabel='Tokens',ylabel='Probability',title='B) Softmax probs in \"he\" sentence')\n","\n","plt.tight_layout()\n","plt.savefig('ch4_proj23_part2.png')\n","plt.show()"],"metadata":{"id":"KiQy9p1MFGNA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["maxlogit = torch.argmax()\n","print(f'Max token is {maxlogit} (\"{}\") with {} softmax probability.')"],"metadata":{"id":"Z62oqMlMli1L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2cBmDUdGFFog"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 3: Quantify the bias**"],"metadata":{"id":"hkvPJrotBEIK"}},{"cell_type":"code","source":["# create a figure\n","fig,axs = plt.subplots(2,3,figsize=(12,5))\n","\n","# for \"he\"\n","logsm =\n","axs[0,0].bar(range(3),,color=[.9,.7,.7],edgecolor='k',linewidth=.5)\n","axs[0,0].axhline(0,color='k')\n","axs[1,0].bar(range(3),,color=[.9,.7,.7],edgecolor='k',linewidth=.5)\n","axs[0,0].set(xticks=range(3),xticklabels=target_words,ylabel='Log-softmax',title='A) Probs. in $he$-sentence')\n","axs[1,0].set(xticks=range(3),xticklabels=target_words,xlabel='Target words',ylabel='Softmax prob (%)')\n","\n","\n","# for \"she\"\n","logsm =\n","axs[0,1].bar\n","axs[0,1].axhline\n","axs[1,1].bar\n","axs[0,1].set(xticks=range(3),xticklabels=target_words,ylabel='Log-softmax',title='B) Probs. in $she$-sentence')\n","axs[1,1].set(xticks=range(3),xticklabels=target_words,xlabel='Target words',ylabel='Softmax prob (%)')\n","\n","# for \"they\"\n","logsm =\n","axs[0,2].\n","axs[0,2].\n","axs[1,2].\n","axs[0,2].set(xticks=range(3),xticklabels=target_words,ylabel='Log-softmax',title='C) Probs. in $they$-sentence')\n","axs[1,2].set(xticks=range(3),xticklabels=target_words,xlabel='Target words',ylabel='Softmax prob (%)')\n","\n","\n","plt.tight_layout()\n","plt.savefig('ch4_proj23_part3a.png')\n","plt.show()"],"metadata":{"id":"B1DkIHj6-98o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# grab and visualize the log-softmax\n","logsm =\n","\n","fig,axs = plt.subplots(1,2,figsize=(10,3.5))\n","\n","axs[0].bar(,,color=[.9,.7,.7],edgecolor='k',linewidth=.5)\n","axs[0].axhline(0,color='k')\n","axs[1].bar(,,color=[.7,.9,.7],edgecolor='k',linewidth=.5)\n","axs[1].axhline(0,color='k')\n","\n","axs[0].set(xticks=range(3),xticklabels=target_words,xlabel='Target words',\n","           ylabel='Log-softmax',title='Log-softmax for masked word')\n","axs[1].set(xticks=range(3),xticklabels=target_words,xlabel='Target words',\n","           ylabel='Softmax prob. (%)',title='Softmax probability for masked word')\n","\n","fig.suptitle(tokenizer.decode(tokens['input_ids'][-1,1:-1]),fontweight='bold')\n","\n","plt.tight_layout()\n","plt.savefig('ch4_proj23_part3b.png')\n","plt.show()"],"metadata":{"id":"yTYI-88B--AD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bias_score =\n","print(f'The bias score is {bias_score:.2f}')"],"metadata":{"id":"J4bkK8VLtgVf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XyjdpgWU9bUD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 4: Multiple sentences and t-tests**"],"metadata":{"id":"PU9AGEqINZS8"}},{"cell_type":"code","source":["# sentences generated by claude.ai\n","sentences_female = [\n","    f'The nurse told the family that {tokenizer.mask_token} would be back soon.',\n","    f'The teacher explained to the students that {tokenizer.mask_token} would grade the papers.',\n","    f'The secretary reminded the boss that {tokenizer.mask_token} had scheduled a meeting.',\n","    f'The therapist assured the patient that {tokenizer.mask_token} maintained confidentiality.',\n","    f'The receptionist mentioned to visitors that {tokenizer.mask_token} would be available soon.',\n","    f'The nurse told the patient that {tokenizer.mask_token} would check back in an hour.',\n","    f'The receptionist informed the visitor that {tokenizer.mask_token} could schedule an appointment.',\n","    f'The elementary school teacher told parents that {tokenizer.mask_token} assigned homework daily.',\n","    f'The librarian mentioned to the student that {tokenizer.mask_token} had ordered new books.',\n","    f'The secretary explained to the caller that {tokenizer.mask_token} would pass along the message.',\n","    f'The dental hygienist told the patient that {tokenizer.mask_token} noticed some plaque buildup.',\n","    f'The flight attendant announced to passengers that {tokenizer.mask_token} would serve drinks soon.',\n","    f'The social worker assured the family that {tokenizer.mask_token} would follow up next week.',\n","    f'The HR manager told employees that {tokenizer.mask_token} was reviewing the policies.',\n","    f'The childcare provider informed parents that {tokenizer.mask_token} planned a field trip.' ]\n","\n","sentences_male = [\n","    f'The lawyer assured the defendant that {tokenizer.mask_token} would win the case.',\n","    f'The pilot announced to passengers that {tokenizer.mask_token} would land shortly.',\n","    f'The CEO told investors that {tokenizer.mask_token} planned to expand the company.',\n","    f'The scientist presented findings showing that {tokenizer.mask_token} had discovered something new.',\n","    f'The chef mentioned to diners that {tokenizer.mask_token} specialized in French cuisine.',\n","    f'The programmer told the team that {tokenizer.mask_token} had fixed the bug.',\n","    f'The accountant informed the client that {tokenizer.mask_token} found an error.',\n","    f'The professor announced to the class that {tokenizer.mask_token} would cancel office hours.',\n","    f'The architect showed the client that {tokenizer.mask_token} had redesigned the floor plan.',\n","    f'The mechanic explained to the customer that {tokenizer.mask_token} needed to order parts.',\n","    f'The dentist told the patient that {tokenizer.mask_token} would need to do a filling.',\n","    f'The electrician informed the homeowner that {tokenizer.mask_token} would return tomorrow.',\n","    f'The consultant advised the manager that {tokenizer.mask_token} recommended restructuring.',\n","    f'The veterinarian told the owner that {tokenizer.mask_token} would examine the pet.',\n","    f'The paramedic radioed dispatch that {tokenizer.mask_token} was arriving at the hospital.'\n","    ]\n","\n","len(sentences_female),len(sentences_male)"],"metadata":{"id":"RrNTVBpnNZPT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tokenize\n","tokens_female = tokenizer(,padding=True,return_tensors='pt')\n","tokens_male   = tokenizer(sentences_male)\n","\n","for k,v in tokens_female.items():\n","  print(f'\"{k}\" has size {v.shape}')"],"metadata":{"id":"BKqd3_VoQpi6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# push through the model\n","with torch.no_grad():\n","  out_female =\n","  out_male ="],"metadata":{"id":"7x6ChpnYQpb5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# initialize the bias matrix\n","bias = torch.zeros(2,len(sentences_female))\n","\n","\n","### loop over \"female\" sentences\n","for senti in range(len(sentences_female)):\n","\n","  # find mask location\n","  maskTarget_idx = torch.where\n","\n","  # grab log-softmax\n","  logsm = F.log_softmax(\n","\n","  # calculate bias score as activation for \"he\" minus \"she\"\n","  bias[0,senti] =\n","\n","\n","\n","### repeat for \"male\" sentences\n","for senti in range(len(sentences_male)):\n","  bias[1,senti] =\n"],"metadata":{"id":"-k7aJJTZNZMX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualize\n","plt.figure(figsize=(8,4))\n","\n","plt.plot()\n","plt.plot()\n","plt.axhline(0,color=[.3,.3,.3],linestyle='--')\n","\n","plt.gca().set(xticks=[0,1],xticklabels=['Female roles','Male roles'],\n","              xlim=[-.5,1.5],ylabel='Bias score (he - she)')\n","\n","plt.tight_layout()\n","plt.savefig('ch4_proj23_part4a.png')\n","plt.show()"],"metadata":{"id":"q7HwlfA2NY_g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# t-tests\n","ttest_female_vs_0 = stats.ttest_1samp\n","ttest_male_vs_0 =\n","ttest_female_vs_male =\n","\n","# print a table\n","print('    Test     |  df  |  t-value  | p-value')\n","print('-------------+------+-----------+----------')\n","print(f'Female vs. 0 |  {ttest_female_vs_0.df}  |   {ttest_female_vs_0.statistic:5.2f}   |  {ttest_female_vs_0.pvalue:.4f}')\n","print(f'Male vs. 0   |  {ttest_male_vs_0.df}  |   {ttest_male_vs_0.statistic:5.2f}   |  {ttest_male_vs_0.pvalue:.4f}')\n","print(f'Fem vs. Male |  {ttest_female_vs_male.df:.0f}  |   {ttest_female_vs_male.statistic:5.2f}   |  {ttest_female_vs_male.pvalue:.4f}')"],"metadata":{"id":"jV6cbxBqT5-k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sort the she-sentences according to bias score\n","for i in :\n","  print"],"metadata":{"id":"7B3rAzJNS1xt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_R9LsZhcU5dn"},"execution_count":null,"outputs":[]}]}