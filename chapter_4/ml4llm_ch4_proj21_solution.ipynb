{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Book:</h2>|<h1><a href=\"https://open.substack.com/pub/mikexcohen/p/llm-breakdown-16-tokenization-words\" target=\"_blank\">50 ML projects to understand LLMs</a></h1>|\n","|-|:-:|\n","|<h2>Project:</h2>|<h1><b>[21] Predict token position with linear and logistic regressions</b></h1>|\n","|<h2>Author:<h2>|<h1>Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h1>|\n","\n","<br>\n","\n","<i>Using the code without reading the book may lead to confusion or errors.</i>"],"metadata":{"id":"py_eibYAH3Q-"}},{"cell_type":"code","source":[],"metadata":{"id":"R5SI-Iyy4dtm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.gridspec import GridSpec\n","\n","from datasets import load_dataset\n","\n","from sklearn.linear_model import LinearRegression,LogisticRegression\n","from sklearn.metrics import confusion_matrix\n","import statsmodels.api as sm\n","import seaborn as sns\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from transformers import AutoModelForCausalLM, AutoTokenizer"],"metadata":{"id":"rn8Fcyf87EXx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### matplotlib adjustments (commented lines are for dark mode)\n","\n","# svg plots (higher-res)\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n","\n","plt.rcParams.update({\n","    # 'figure.facecolor': '#282a2c',\n","    # 'figure.edgecolor': '#282a2c',\n","    # 'axes.facecolor':   '#282a2c',\n","    # 'axes.edgecolor':   '#DDE2F4',\n","    # 'axes.labelcolor':  '#DDE2F4',\n","    # 'xtick.color':      '#DDE2F4',\n","    # 'ytick.color':      '#DDE2F4',\n","    # 'text.color':       '#DDE2F4',\n","    'axes.spines.right': False,\n","    'axes.spines.top':   False,\n","    'axes.titleweight': 'bold',\n","    'axes.labelweight': 'bold',\n","    'savefig.dpi':300,\n","})"],"metadata":{"id":"dy4A-ah8kzZQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"h1B6k3LhCH0k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 1: Create a dataset**"],"metadata":{"id":"8rVoCp0jD4yv"}},{"cell_type":"code","source":["# load pretrained GPT-2 model and tokenizer\n","tokenizer = AutoTokenizer.from_pretrained('gpt2')\n","model = AutoModelForCausalLM.from_pretrained('gpt2')\n","model.eval()"],"metadata":{"id":"Pked33G5CHx7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import the HellaSwag validation set\n","dataset = load_dataset('hellaswag',split='validation')\n","dataset"],"metadata":{"id":"bGqlMxcBCHu9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# batch parameters\n","seqlen = 6\n","nSamples = 500\n","\n","# initialize the batch\n","batch = torch.zeros((nSamples,seqlen),dtype=torch.long)\n","\n","# get the tokens for each sequence\n","for i in range(nSamples):\n","  firsttokens = tokenizer.encode(dataset[i]['ctx_a'])[:seqlen]\n","  batch[i,:] = torch.tensor(firsttokens)\n","\n","print(f'Shape of batch: {batch.shape}')\n","batch"],"metadata":{"id":"VjOMAN93Crf3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.decode(batch[13,:])"],"metadata":{"id":"e450iGVeix1z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# forward pass to get logits (16s on cpu)\n","with torch.no_grad():\n","  out = model(batch)\n","\n","out.logits.shape"],"metadata":{"id":"bVE1bZvaCrEz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# log-softmax to get losses\n","logits_logsm = F.log_softmax(out.logits,dim=-1)\n","\n","# initialize matrix of losses\n","losses = np.zeros((nSamples,seqlen-1))\n","\n","# loop over sequences and tokens\n","for seqi in range(nSamples):\n","  for tokeni in range(seqlen-1):\n","\n","    # single-token loss is -loglikelihood of target token\n","    target_idx = batch[seqi,tokeni+1]\n","    losses[seqi,tokeni] = -logits_logsm[seqi,tokeni,target_idx].item()"],"metadata":{"id":"u-LJRrr6CrBo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# matrix of ordinal positions\n","ord_position = np.tile(np.arange(seqlen-1),(nSamples,1))\n","ord_position"],"metadata":{"id":"L_Xs8j3nPYLp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# flatten (vectorize) the matrices\n","losses_flat = losses.flatten().reshape(-1,1)\n","ord_position_flat = ord_position.flatten().reshape(-1,1)\n","\n","print(f'           Shape of losses: {losses.shape}')\n","print(f'      Shape of losses_flat: {losses_flat.shape}\\n')\n","print(f'     Shape of ord_position: {ord_position.shape}')\n","print(f'Shape of ord_position_flat: {ord_position_flat.shape}')"],"metadata":{"id":"tf-Lo-B7OsbH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# setup the figure and axes\n","fig = plt.figure(figsize=(12,4))\n","gs = GridSpec(1,3,figure=fig)\n","ax1 = fig.add_subplot(gs[:-1])\n","ax2 = fig.add_subplot(gs[-1])\n","\n","# bar plot and scatter\n","ax1.bar(range(seqlen-1),losses.mean(axis=0),color=[.7,.7,.9],edgecolor='k',linewidth=.5)\n","ax1.plot(ord_position_flat+np.random.normal(0,.03,ord_position_flat.shape),\n","         losses_flat,'ko',markerfacecolor=[.9,.7,.7,.5])\n","\n","ax1.set(xlabel='Token position',ylabel='Loss',title='A) Next-token prediction loss')\n","\n","\n","# distributions\n","for i in range(seqlen-1):\n","  y,x = np.histogram(losses[:,i],bins=10,density=True)\n","  ax2.plot(x[:-1],y,linewidth=2,label=f'Token {i}')\n","\n","ax2.set(xlabel='Per-token loss',ylabel='Probability density',title='B) Distribution by token position')\n","ax2.legend()\n","\n","plt.tight_layout()\n","plt.savefig('ch4_proj21_part1.png')\n","plt.show()"],"metadata":{"id":"LEr1Pw5NVQnT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QtxCKC9FOmeT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 2: Linear regression in statsmodels and sklearn**"],"metadata":{"id":"92OyvxgXOmbX"}},{"cell_type":"code","source":["# create and fit the model\n","X = sm.add_constant(losses_flat) # design matrix with intercept term\n","smreg = sm.OLS(ord_position_flat,X).fit()\n","print( smreg.summary() )"],"metadata":{"id":"rdEAZM3ZFvvd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# repeat using sklearn's LinearRegression\n","# ordpos must be squeezed back\n","reg = LinearRegression().fit(losses_flat,ord_position_flat.squeeze())\n","print(f'const: {reg.intercept_:7.4f}')\n","print(f'x1   : {reg.coef_[0]:7.4f}')"],"metadata":{"id":"bNlgQ1-hMCbB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UtJq4hQ3MCge"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 3: Does linear regression reconstruct ordinal position?**"],"metadata":{"id":"rn_WpcKLMCdt"}},{"cell_type":"code","source":["# generate predictions\n","predictions = reg.predict(losses_flat)\n","\n","# visualize\n","plt.figure(figsize=(8,4))\n","plt.plot(ord_position_flat+np.random.normal(0,.03,ord_position_flat.shape),\n","         predictions,'ko',markerfacecolor=[.7,.7,.9,.5])\n","plt.gca().set(xlabel='True positions',ylabel='Predicted positions',xticks=range(seqlen-1),yticks=range(seqlen-1))\n","\n","plt.tight_layout()\n","plt.savefig('ch4_proj21_part3.png')\n","plt.show()"],"metadata":{"id":"XVMBkAzYLq2m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QRHSnPsel4nI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 4: Fit a multinomial logistic regression**"],"metadata":{"id":"yk0OW_NzwXSe"}},{"cell_type":"code","source":["# fit a logistic regression model\n","logreg = LogisticRegression(solver='lbfgs').fit(losses_flat,ord_position_flat.squeeze())\n","\n","print('Intercepts (beta_0):\\n',logreg.intercept_,'\\n')\n","print('Coefficients (beta_1):\\n',logreg.coef_.T)"],"metadata":{"id":"mQPpKDS_wXPx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualize the coefficients\n","_,axs = plt.subplots(1,2,figsize=(12,4))\n","\n","axs[0].axhline(y=0,color='k',linestyle='--',linewidth=.5)\n","axs[0].bar(range(len(logreg.coef_)),logreg.coef_.squeeze(),color=[.9,.7,.7],edgecolor='k',linewidth=.5)\n","axs[0].set(xlabel='Token position',ylabel='Coefficient value',xticks=range(seqlen-1),title='A) Relative slopes')\n","\n","axs[1].axhline(y=0,color='k',linestyle='--',linewidth=.5)\n","axs[1].bar(range(len(logreg.coef_)),logreg.intercept_.squeeze(),color=[.7,.7,.9],edgecolor='k',linewidth=.5)\n","axs[1].set(xlabel='Token position',ylabel='Coefficient value',xticks=range(seqlen-1),title='B) Relative intercepts')\n","\n","plt.tight_layout()\n","plt.savefig('ch4_proj21_part4.png')\n","plt.show()"],"metadata":{"id":"6zFMB_pO321I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9-UjgEkryzOA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 5: Categorical predictions**"],"metadata":{"id":"i2EoKXiPyzLE"}},{"cell_type":"code","source":["# prediction scores\n","predictions = logreg.predict_proba(losses_flat)\n","\n","print(f'Shape of predictions: {predictions.shape}\\n')\n","print(f'Sum of predictions for each token:\\n{predictions.sum(axis=1)}')"],"metadata":{"id":"en7HtcNvCl3V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get the class predictions (np.argmax selects the category with highest score)\n","predicted_categories = np.argmax(predictions,axis=1)\n","predicted_categories"],"metadata":{"id":"AlblJBj4JBoq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create the confusion matrix\n","cm = confusion_matrix(ord_position_flat.squeeze(),predicted_categories)\n","\n","# and normalize it by row sum\n","cm_norm = 100 * cm/cm.sum(axis=1,keepdims=True)"],"metadata":{"id":"2E-l6w7d9Dbn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualize per-category (token position) prediction accuracy\n","_,axs = plt.subplots(1,2,figsize=(10,4))\n","\n","for i in range(seqlen-1):\n","  idxs = ord_position_flat.squeeze()==i\n","  accs = predicted_categories[idxs]==ord_position_flat[idxs]\n","  axs[0].bar(i,100*accs.mean())\n","  axs[0].text(i,1+100*accs.mean(),f'{100*accs.mean():.1f}%',\n","              fontsize=12,fontweight='bold',ha='center',va='bottom')\n","\n","# chance-level performance\n","axs[0].axhline(100/(ord_position_flat.max()+1),linestyle='--',color='k',linewidth=.5,zorder=-10)\n","\n","axs[0].set(xlabel='Token position',ylabel='Prediction accuracy (%)',xticks=range(seqlen-1),\n","           title='A) Category-specific prediction accuracy')\n","\n","\n","# and the confusion matrix\n","sns.heatmap(cm_norm,annot=True,fmt='.1f',cmap='Reds',annot_kws={'size': 15},ax=axs[1])\n","axs[1].set(xlabel='Predicted position',ylabel='True position',\n","              title='B) Confusion matrix (% row-wise)')\n","plt.suptitle('TRAIN test performance',fontsize=16,fontweight='bold')\n","\n","plt.tight_layout()\n","plt.savefig('ch4_proj21_part5.png')\n","plt.show()"],"metadata":{"id":"b7KwwgldwXNU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"k3wts7H3737o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Part 6: Test on new (untrained) data**"],"metadata":{"id":"OWm18ZZM2kdg"}},{"cell_type":"code","source":["# get a new batch of data (parameters defined in Part 1)\n","\n","# get the tokens for each sample (note dataset indexing)\n","for i in range(nSamples):\n","  firsttokens = tokenizer.encode(dataset[1000+i]['ctx_a'])[:seqlen]\n","  batch[i,:] = torch.tensor(firsttokens)\n","\n","# forward pass to get logits (16s on cpu)\n","with torch.no_grad():\n","  out = model(batch)"],"metadata":{"id":"pKnT-eXNBjDC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# log-softmax to get losses\n","logits_logsm = F.log_softmax(out.logits,dim=-1)\n","\n","# initialize matrix of losses\n","losses_test = np.zeros((nSamples,seqlen-1))\n","\n","# loop over sequences and tokens\n","for seqi in range(nSamples):\n","  for tokeni in range(seqlen-1):\n","\n","    # single-token loss is -loglikelihood of target token\n","    target_idx = batch[seqi,tokeni+1]\n","    losses_test[seqi,tokeni] = -logits_logsm[seqi,tokeni,target_idx].item()\n","\n","losses_test_flat = losses_test.flatten().reshape(-1,1)"],"metadata":{"id":"aPK1HaipBjDD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prediction scores using logistic regression model from the first dataset\n","predictions = logreg.predict_proba(losses_test_flat)\n","predicted_categories = np.argmax(predictions,axis=1)"],"metadata":{"id":"Ss3M-hrECdfQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create the confusion matrix\n","cm = confusion_matrix(ord_position_flat.squeeze(),predicted_categories)\n","\n","# and normalize it by row sum\n","cm_norm = 100 * cm/cm.sum(axis=1,keepdims=True)"],"metadata":{"id":"nmxS3B5iCdfR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualize per-category (token position) prediction accuracy\n","_,axs = plt.subplots(1,2,figsize=(10,4))\n","\n","for i in range(seqlen-1):\n","  idxs = ord_position_flat.squeeze()==i\n","  accs = predicted_categories[idxs]==ord_position_flat[idxs]\n","  axs[0].bar(i,100*accs.mean())\n","  axs[0].text(i,1+100*accs.mean(),f'{100*accs.mean():.1f}%',\n","              fontsize=12,fontweight='bold',ha='center',va='bottom')\n","\n","# chance-level performance\n","axs[0].axhline(100/(1+ord_position_flat.max()),linestyle='--',color='k',linewidth=.5,zorder=-10)\n","\n","axs[0].set(xlabel='Token position',ylabel='Prediction accuracy (%)',xticks=range(seqlen-1),\n","           title='A) Category-specific prediction accuracy')\n","\n","\n","# and the confusion matrix\n","sns.heatmap(cm_norm,annot=True,fmt='.1f',cmap='Reds',annot_kws={'size': 15},ax=axs[1])\n","axs[1].set(xlabel='Predicted position',ylabel='True position',\n","              title='B) Confusion matrix (% row-wise)')\n","\n","plt.suptitle('TEST test performance',fontsize=16,fontweight='bold')\n","\n","plt.tight_layout()\n","plt.savefig('ch4_proj21_part6.png')\n","plt.show()"],"metadata":{"id":"5hAi610bCdfR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bC3E6-6RC1kA"},"execution_count":null,"outputs":[]}]}